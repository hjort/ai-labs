{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação dos pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar pacotes necessários\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir parâmetros extras\n",
    "pd.set_option('precision', 4)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixo_arquivos = 'titanic/'\n",
    "#prefixo_arquivos = '/kaggle/input/titanic/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregar arquivo de dados de treino\n",
    "train_data = pd.read_csv(prefixo_arquivos + 'train.csv', index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregar arquivo de dados de teste\n",
    "test_data = pd.read_csv(prefixo_arquivos + 'test.csv', index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age Cabin Embarked     Fare  \\\n",
       "PassengerId                                 \n",
       "1            22.0   NaN        S   7.2500   \n",
       "2            38.0   C85        C  71.2833   \n",
       "3            26.0   NaN        S   7.9250   \n",
       "4            35.0  C123        S  53.1000   \n",
       "5            35.0   NaN        S   8.0500   \n",
       "\n",
       "                                                          Name  Parch  Pclass  \\\n",
       "PassengerId                                                                     \n",
       "1                                      Braund, Mr. Owen Harris      0       3   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...      0       1   \n",
       "3                                       Heikkinen, Miss. Laina      0       3   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)      0       1   \n",
       "5                                     Allen, Mr. William Henry      0       3   \n",
       "\n",
       "                Sex  SibSp  Survived            Ticket  \n",
       "PassengerId                                             \n",
       "1              male      1       0.0         A/5 21171  \n",
       "2            female      1       1.0          PC 17599  \n",
       "3            female      0       1.0  STON/O2. 3101282  \n",
       "4            female      1       1.0            113803  \n",
       "5              male      0       0.0            373450  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unir ambos os dados de treino e teste\n",
    "data = pd.concat([train_data, test_data])\n",
    "\n",
    "# mostrar alguns exemplos de registros\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformações nos dados"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# transformar colunas textuais em categóricas\n",
    "data['Survived'] = data['Survived'].map({'yes': 1, 'no': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Title</th>\n",
       "      <th>Capt</th>\n",
       "      <th>Col</th>\n",
       "      <th>Countess</th>\n",
       "      <th>Don</th>\n",
       "      <th>Dona</th>\n",
       "      <th>Dr</th>\n",
       "      <th>Jonkheer</th>\n",
       "      <th>Lady</th>\n",
       "      <th>Major</th>\n",
       "      <th>Master</th>\n",
       "      <th>Miss</th>\n",
       "      <th>Mlle</th>\n",
       "      <th>Mme</th>\n",
       "      <th>Mr</th>\n",
       "      <th>Mrs</th>\n",
       "      <th>Ms</th>\n",
       "      <th>Rev</th>\n",
       "      <th>Sir</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>757</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Title   Capt  Col  Countess  Don  Dona  Dr  Jonkheer  Lady  Major  Master  \\\n",
       "Sex                                                                         \n",
       "female     0    0         1    0     1   1         0     1      0       0   \n",
       "male       1    4         0    1     0   7         1     0      2      61   \n",
       "\n",
       "Title   Miss  Mlle  Mme   Mr  Mrs  Ms  Rev  Sir  \n",
       "Sex                                              \n",
       "female   260     2    1    0  197   2    0    0  \n",
       "male       0     0    0  757    0   0    8    1  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extrair títulos das pessoas a partir do nome\n",
    "data['Title'] = data['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "# exibir relação entre título e sexo\n",
    "pd.crosstab(data['Title'], data['Sex']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Title</th>\n",
       "      <th>Master</th>\n",
       "      <th>Miss</th>\n",
       "      <th>Mr</th>\n",
       "      <th>Mrs</th>\n",
       "      <th>Rare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>757</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Title   Master  Miss   Mr  Mrs  Rare\n",
       "Sex                                 \n",
       "female       0   264    0  198     4\n",
       "male        61     0  757    0    25"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agregar títulos incomuns\n",
    "replacements = {\n",
    "    'Miss': ['Mlle', 'Ms'],\n",
    "    'Mrs': ['Mme'],\n",
    "    'Rare': ['Lady', 'Countess', 'Capt', 'Col', 'Don', \\\n",
    "             'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona']\n",
    "}\n",
    "for k, v in replacements.items():\n",
    "    data['Title'] = data['Title'].replace(v, k)\n",
    "    \n",
    "# exibir relação entre título e sexo\n",
    "pd.crosstab(data['Title'], data['Sex']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorizar os valores dos títulos\n",
    "title_mapping = {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Rare': 5}\n",
    "data['Title'] = data['Title'].map(title_mapping)\n",
    "data['Title'] = data['Title'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorizar os valores dos sexos\n",
    "data['Sex'] = data['Sex'].map({'female': 1, 'male': 0}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preencher e categorizar os valores dos portos de embarque\n",
    "data['Embarked'].fillna(data.Embarked.mode()[0], inplace=True)\n",
    "data['Embarked'] = data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preencher os valores da passagem\n",
    "data['Fare'].fillna(data.Fare.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar coluna com tamanho da família\n",
    "data['FSize'] = data['Parch'] + data['SibSp'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar coluna indicando se estava sozinho\n",
    "data['Alone'] = 0\n",
    "data.loc[data.FSize == 1, 'Alone'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar coluna contendo o deque\n",
    "data['Deck'] = data['Cabin'].str[:1]\n",
    "data['Deck'] = data['Deck'].fillna('N').astype('category')\n",
    "data['Deck'] = data['Deck'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar coluna contendo o número do quarto\n",
    "data['Room'] = data['Cabin'].str.extract(\"([0-9]+)\", expand=False)\n",
    "data['Room'] = data['Room'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Title</th>\n",
       "      <th>FSize</th>\n",
       "      <th>Alone</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Room</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>C123</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113803</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373450</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age Cabin  Embarked     Fare  \\\n",
       "PassengerId                                  \n",
       "1            22.0   NaN         0   7.2500   \n",
       "2            38.0   C85         1  71.2833   \n",
       "3            26.0   NaN         0   7.9250   \n",
       "4            35.0  C123         0  53.1000   \n",
       "5            35.0   NaN         0   8.0500   \n",
       "\n",
       "                                                          Name  Parch  Pclass  \\\n",
       "PassengerId                                                                     \n",
       "1                                      Braund, Mr. Owen Harris      0       3   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...      0       1   \n",
       "3                                       Heikkinen, Miss. Laina      0       3   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)      0       1   \n",
       "5                                     Allen, Mr. William Henry      0       3   \n",
       "\n",
       "             Sex  SibSp  Survived            Ticket  Title  FSize  Alone  \\\n",
       "PassengerId                                                                \n",
       "1              0      1       0.0         A/5 21171      1      2      0   \n",
       "2              1      1       1.0          PC 17599      3      2      0   \n",
       "3              1      0       1.0  STON/O2. 3101282      2      1      1   \n",
       "4              1      1       1.0            113803      3      2      0   \n",
       "5              0      0       0.0            373450      1      1      1   \n",
       "\n",
       "             Deck  Room  \n",
       "PassengerId              \n",
       "1               7     0  \n",
       "2               2    85  \n",
       "3               7     0  \n",
       "4               2   123  \n",
       "5               7     0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferir idades faltantes dos passageiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def evaluate_regression_model(model, X, y):\n",
    "    kfold = KFold(n_splits=10, random_state=42)\n",
    "    results = cross_val_score(model, X, y, cv=kfold, scoring='neg_mean_squared_error', verbose=1)\n",
    "    score = (-1) * results.mean()\n",
    "    stddev = results.std()\n",
    "    print(model, '\\nScore: %.2f (+/- %.2f)' % (score, stddev))\n",
    "    return score, stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "age_models = [\n",
    "#    ('LR', LinearRegression(n_jobs=-1, fit_intercept=True, normalize=True)),\n",
    "    ('GBR', GradientBoostingRegressor(random_state=42)),\n",
    "    ('RFR', RandomForestRegressor(random_state=42)),\n",
    "    ('XGB', XGBRegressor(random_state=42, objective='reg:squarederror')),\n",
    "#    ('MLP', MLPRegressor(random_state=42, max_iter=500, activation='tanh',\n",
    "#                         hidden_layer_sizes=(10,5,5), solver='lbfgs')),\n",
    "#    ('GPR', GaussianProcessRegressor(random_state=42, alpha=0.01, normalize_y=True))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Title</th>\n",
       "      <th>Age</th>\n",
       "      <th>Alone</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass  SibSp  Parch     Fare  Title   Age  Alone\n",
       "PassengerId                                                   \n",
       "1                 3      1      0   7.2500      1  22.0      0\n",
       "2                 1      1      0  71.2833      3  38.0      0\n",
       "3                 3      0      0   7.9250      2  26.0      1\n",
       "4                 1      1      0  53.1000      3  35.0      0\n",
       "5                 3      0      0   8.0500      1  35.0      1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecionar dados para o treino\n",
    "\n",
    "cols = ['Pclass', 'SibSp', 'Parch', 'Fare', 'Title', 'Age', 'Alone']\n",
    "\n",
    "data_age = data[cols].dropna()\n",
    "\n",
    "X_age = data_age.drop(['Age'], axis=1)\n",
    "y_age = data_age['Age']\n",
    "\n",
    "data_age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Title</th>\n",
       "      <th>Age</th>\n",
       "      <th>Alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>-0.5651</td>\n",
       "      <td>-0.1541</td>\n",
       "      <td>-0.4081</td>\n",
       "      <td>0.1595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>0.0472</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3745</td>\n",
       "      <td>0.1412</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>-0.2437</td>\n",
       "      <td>-0.6274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.3745</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>0.3151</td>\n",
       "      <td>-0.1509</td>\n",
       "      <td>-0.5701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>-0.5651</td>\n",
       "      <td>0.1412</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1484</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>-0.2598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <td>-0.1541</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>0.3151</td>\n",
       "      <td>0.1484</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.0926</td>\n",
       "      <td>-0.3973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.4081</td>\n",
       "      <td>-0.2437</td>\n",
       "      <td>-0.1509</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>-0.0926</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alone</th>\n",
       "      <td>0.1595</td>\n",
       "      <td>-0.6274</td>\n",
       "      <td>-0.5701</td>\n",
       "      <td>-0.2598</td>\n",
       "      <td>-0.3973</td>\n",
       "      <td>0.1288</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Pclass   SibSp   Parch    Fare   Title     Age   Alone\n",
       "Pclass  1.0000  0.0472  0.0172 -0.5651 -0.1541 -0.4081  0.1595\n",
       "SibSp   0.0472  1.0000  0.3745  0.1412  0.3080 -0.2437 -0.6274\n",
       "Parch   0.0172  0.3745  1.0000  0.2167  0.3151 -0.1509 -0.5701\n",
       "Fare   -0.5651  0.1412  0.2167  1.0000  0.1484  0.1782 -0.2598\n",
       "Title  -0.1541  0.3080  0.3151  0.1484  1.0000 -0.0926 -0.3973\n",
       "Age    -0.4081 -0.2437 -0.1509  0.1782 -0.0926  1.0000  0.1288\n",
       "Alone   0.1595 -0.6274 -0.5701 -0.2598 -0.3973  0.1288  1.0000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_age.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Score: 112.79 (+/- 14.49)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
      "                      n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                      warm_start=False) \n",
      "Score: 135.68 (+/- 24.32)\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
      "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "             n_jobs=1, nthread=None, objective='reg:squarederror',\n",
      "             random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "             seed=None, silent=None, subsample=1, verbosity=1) \n",
      "Score: 112.37 (+/- 15.11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.9s finished\n"
     ]
    }
   ],
   "source": [
    "names = []\n",
    "scores = []\n",
    "lowest = 999\n",
    "best_model = None\n",
    "\n",
    "for name, model in age_models:\n",
    "    \n",
    "    score, stddev = evaluate_regression_model(model, X_age, y_age)\n",
    "    names.append(name)\n",
    "    scores.append(score)\n",
    "    \n",
    "    if score < lowest:\n",
    "        best_model = model\n",
    "        lowest = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGB</td>\n",
       "      <td>112.3670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GBR</td>\n",
       "      <td>112.7919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RFR</td>\n",
       "      <td>135.6790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Age Model     Score\n",
       "2       XGB  112.3670\n",
       "0       GBR  112.7919\n",
       "1       RFR  135.6790"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'Age Model': names, 'Score': scores})\n",
    "results.sort_values(by='Score', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "             n_jobs=1, nthread=None, objective='reg:squarederror',\n",
       "             random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "             seed=None, silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_model = best_model\n",
    "age_model.fit(X_age, y_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Title</th>\n",
       "      <th>FSize</th>\n",
       "      <th>Alone</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Room</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>C123</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113803</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373450</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age Cabin  Embarked     Fare  \\\n",
       "PassengerId                                  \n",
       "1            22.0   NaN         0   7.2500   \n",
       "2            38.0   C85         1  71.2833   \n",
       "3            26.0   NaN         0   7.9250   \n",
       "4            35.0  C123         0  53.1000   \n",
       "5            35.0   NaN         0   8.0500   \n",
       "\n",
       "                                                          Name  Parch  Pclass  \\\n",
       "PassengerId                                                                     \n",
       "1                                      Braund, Mr. Owen Harris      0       3   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...      0       1   \n",
       "3                                       Heikkinen, Miss. Laina      0       3   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)      0       1   \n",
       "5                                     Allen, Mr. William Henry      0       3   \n",
       "\n",
       "             Sex  SibSp  Survived            Ticket  Title  FSize  Alone  \\\n",
       "PassengerId                                                                \n",
       "1              0      1       0.0         A/5 21171      1      2      0   \n",
       "2              1      1       1.0          PC 17599      3      2      0   \n",
       "3              1      0       1.0  STON/O2. 3101282      2      1      1   \n",
       "4              1      1       1.0            113803      3      2      0   \n",
       "5              0      0       0.0            373450      1      1      1   \n",
       "\n",
       "             Deck  Room  \n",
       "PassengerId              \n",
       "1               7     0  \n",
       "2               2    85  \n",
       "3               7     0  \n",
       "4               2   123  \n",
       "5               7     0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preencher dados faltantes de idade a partir de uma regressão\n",
    "data['AgePred'] = age_model.predict(data[cols].drop('Age', axis=1))\n",
    "data.loc[data.Age.isnull(), 'Age'] = data['AgePred']\n",
    "data.drop('AgePred', axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin       1014\n",
       "Survived     418\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# existem colunas com dados nulos?\n",
    "data[data.columns[data.isnull().any()]].isnull().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# criar colunas adicionais\n",
    "data['ageclass'] = data['age'] * data['pclass']\n",
    "data['pfare'] = data['fare'] / data['fsize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Title</th>\n",
       "      <th>FSize</th>\n",
       "      <th>Alone</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Room</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>C123</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113803</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373450</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age Cabin  Embarked     Fare  \\\n",
       "PassengerId                                  \n",
       "1            22.0   NaN         0   7.2500   \n",
       "2            38.0   C85         1  71.2833   \n",
       "3            26.0   NaN         0   7.9250   \n",
       "4            35.0  C123         0  53.1000   \n",
       "5            35.0   NaN         0   8.0500   \n",
       "\n",
       "                                                          Name  Parch  Pclass  \\\n",
       "PassengerId                                                                     \n",
       "1                                      Braund, Mr. Owen Harris      0       3   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...      0       1   \n",
       "3                                       Heikkinen, Miss. Laina      0       3   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)      0       1   \n",
       "5                                     Allen, Mr. William Henry      0       3   \n",
       "\n",
       "             Sex  SibSp  Survived            Ticket  Title  FSize  Alone  \\\n",
       "PassengerId                                                                \n",
       "1              0      1       0.0         A/5 21171      1      2      0   \n",
       "2              1      1       1.0          PC 17599      3      2      0   \n",
       "3              1      0       1.0  STON/O2. 3101282      2      1      1   \n",
       "4              1      1       1.0            113803      3      2      0   \n",
       "5              0      0       0.0            373450      1      1      1   \n",
       "\n",
       "             Deck  Room  \n",
       "PassengerId              \n",
       "1               7     0  \n",
       "2               2    85  \n",
       "3               7     0  \n",
       "4               2   123  \n",
       "5               7     0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# gerar \"one hot encoding\" em atributos categóricos\n",
    "#cols = ['pclass', 'sex', 'embarked']\n",
    "cols = ['embarked', 'pclass', 'title', 'deck']\n",
    "data = pd.get_dummies(data, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realizar normalização nos dados numéricos contínuos\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "cols = ['Age', 'Fare', 'Parch', 'Pclass', 'SibSp', 'FSize']\n",
    "\n",
    "data.loc[:,cols] = scaler.fit_transform(data.loc[:,cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Title</th>\n",
       "      <th>FSize</th>\n",
       "      <th>Alone</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Room</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4739</td>\n",
       "      <td>C85</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1391</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4363</td>\n",
       "      <td>C123</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1036</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113803</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373450</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age Cabin  Embarked    Fare  \\\n",
       "PassengerId                                   \n",
       "1            0.2735   NaN         0  0.0142   \n",
       "2            0.4739   C85         1  0.1391   \n",
       "3            0.3236   NaN         0  0.0155   \n",
       "4            0.4363  C123         0  0.1036   \n",
       "5            0.4363   NaN         0  0.0157   \n",
       "\n",
       "                                                          Name  Parch  Pclass  \\\n",
       "PassengerId                                                                     \n",
       "1                                      Braund, Mr. Owen Harris    0.0     1.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...    0.0     0.0   \n",
       "3                                       Heikkinen, Miss. Laina    0.0     1.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)    0.0     0.0   \n",
       "5                                     Allen, Mr. William Henry    0.0     1.0   \n",
       "\n",
       "             Sex  SibSp  Survived            Ticket  Title  FSize  Alone  \\\n",
       "PassengerId                                                                \n",
       "1              0  0.125       0.0         A/5 21171      1    0.1      0   \n",
       "2              1  0.125       1.0          PC 17599      3    0.1      0   \n",
       "3              1  0.000       1.0  STON/O2. 3101282      2    0.0      1   \n",
       "4              1  0.125       1.0            113803      3    0.1      0   \n",
       "5              0  0.000       0.0            373450      1    0.0      1   \n",
       "\n",
       "             Deck  Room  \n",
       "PassengerId              \n",
       "1               7     0  \n",
       "2               2    85  \n",
       "3               7     0  \n",
       "4               2   123  \n",
       "5               7     0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem preditiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar os pacotes necessários para os algoritmos de classificação\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# avalia o desempenho do modelo, retornando o valor da precisão\n",
    "def evaluate_classification_model(model, X, y):\n",
    "    start = datetime.now()\n",
    "    kfold = KFold(n_splits=10, random_state=42)\n",
    "    results = cross_val_score(model, X, y, cv=kfold, scoring='accuracy', verbose=1)\n",
    "    end = datetime.now()\n",
    "    elapsed = int((end - start).total_seconds() * 1000)\n",
    "    score = 100.0 * results.mean()\n",
    "    stddev = 100.0 * results.std()\n",
    "    print(model, '\\nScore: %.2f (+/- %.2f) [%5s ms]' % (score, stddev, elapsed))\n",
    "    return score, stddev, elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# faz o ajuste fino do modelo, calculando os melhores hiperparâmetros\n",
    "def fine_tune_model(model, params, X, y):\n",
    "    print('\\nFine Tuning Model:')\n",
    "    print(model, \"\\nparams:\", params)\n",
    "    kfold = KFold(n_splits=10, random_state=42)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=params, scoring='accuracy', cv=kfold, verbose=1)\n",
    "    grid.fit(X, y)\n",
    "    print('\\nGrid Best Score: %.2f' % (grid.best_score_ * 100.0))\n",
    "    print('Best Params:', grid.best_params_)\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma dos dados de treino: (891, 11) (891,)\n"
     ]
    }
   ],
   "source": [
    "# definir dados de treino\n",
    "train_data = data[data.Survived.isnull() == False]\n",
    "\n",
    "# selecionar atributos para o modelo\n",
    "cols = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Title', 'FSize', 'Alone', 'Deck']\n",
    "\n",
    "X_train = train_data[cols]\n",
    "y_train = train_data['Survived']\n",
    "\n",
    "print('Forma dos dados de treino:', X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Title</th>\n",
       "      <th>FSize</th>\n",
       "      <th>Alone</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Room</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.0186</td>\n",
       "      <td>0.1048</td>\n",
       "      <td>-0.2110</td>\n",
       "      <td>-0.4031</td>\n",
       "      <td>-0.1125</td>\n",
       "      <td>-0.3128</td>\n",
       "      <td>-0.0619</td>\n",
       "      <td>-0.1123</td>\n",
       "      <td>-0.3192</td>\n",
       "      <td>0.2113</td>\n",
       "      <td>-0.2868</td>\n",
       "      <td>0.2312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>-0.0186</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0621</td>\n",
       "      <td>-0.0787</td>\n",
       "      <td>0.0457</td>\n",
       "      <td>0.1166</td>\n",
       "      <td>-0.0600</td>\n",
       "      <td>0.1068</td>\n",
       "      <td>0.0454</td>\n",
       "      <td>-0.0803</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>-0.0391</td>\n",
       "      <td>0.0238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.1048</td>\n",
       "      <td>0.0621</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2162</td>\n",
       "      <td>-0.5495</td>\n",
       "      <td>0.1823</td>\n",
       "      <td>0.1597</td>\n",
       "      <td>0.2573</td>\n",
       "      <td>0.1363</td>\n",
       "      <td>0.2171</td>\n",
       "      <td>-0.2718</td>\n",
       "      <td>-0.5257</td>\n",
       "      <td>0.4056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>-0.2110</td>\n",
       "      <td>-0.0787</td>\n",
       "      <td>0.2162</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>0.4148</td>\n",
       "      <td>0.0816</td>\n",
       "      <td>0.3158</td>\n",
       "      <td>0.7831</td>\n",
       "      <td>-0.5834</td>\n",
       "      <td>-0.0316</td>\n",
       "      <td>0.0016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.4031</td>\n",
       "      <td>0.0457</td>\n",
       "      <td>-0.5495</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.1319</td>\n",
       "      <td>0.0831</td>\n",
       "      <td>-0.3385</td>\n",
       "      <td>-0.1739</td>\n",
       "      <td>0.0660</td>\n",
       "      <td>0.1352</td>\n",
       "      <td>0.7421</td>\n",
       "      <td>-0.5733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>-0.1125</td>\n",
       "      <td>0.1166</td>\n",
       "      <td>0.1823</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>-0.1319</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1146</td>\n",
       "      <td>0.5434</td>\n",
       "      <td>0.5027</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>-0.3036</td>\n",
       "      <td>-0.1186</td>\n",
       "      <td>0.0917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.3128</td>\n",
       "      <td>-0.0600</td>\n",
       "      <td>0.1597</td>\n",
       "      <td>0.4148</td>\n",
       "      <td>0.0831</td>\n",
       "      <td>0.1146</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.0353</td>\n",
       "      <td>0.2696</td>\n",
       "      <td>0.8907</td>\n",
       "      <td>-0.5845</td>\n",
       "      <td>0.0411</td>\n",
       "      <td>-0.0387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>-0.0619</td>\n",
       "      <td>0.1068</td>\n",
       "      <td>0.2573</td>\n",
       "      <td>0.0816</td>\n",
       "      <td>-0.3385</td>\n",
       "      <td>0.5434</td>\n",
       "      <td>-0.0353</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4078</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>-0.2034</td>\n",
       "      <td>-0.2951</td>\n",
       "      <td>0.2298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <td>-0.1123</td>\n",
       "      <td>0.0454</td>\n",
       "      <td>0.1363</td>\n",
       "      <td>0.3158</td>\n",
       "      <td>-0.1739</td>\n",
       "      <td>0.5027</td>\n",
       "      <td>0.2696</td>\n",
       "      <td>0.4078</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3420</td>\n",
       "      <td>-0.4058</td>\n",
       "      <td>-0.1323</td>\n",
       "      <td>0.0798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FSize</th>\n",
       "      <td>-0.3192</td>\n",
       "      <td>-0.0803</td>\n",
       "      <td>0.2171</td>\n",
       "      <td>0.7831</td>\n",
       "      <td>0.0660</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.8907</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.3420</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.6909</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>-0.0257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alone</th>\n",
       "      <td>0.2113</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>-0.2718</td>\n",
       "      <td>-0.5834</td>\n",
       "      <td>0.1352</td>\n",
       "      <td>-0.3036</td>\n",
       "      <td>-0.5845</td>\n",
       "      <td>-0.2034</td>\n",
       "      <td>-0.4058</td>\n",
       "      <td>-0.6909</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>-0.1075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deck</th>\n",
       "      <td>-0.2868</td>\n",
       "      <td>-0.0391</td>\n",
       "      <td>-0.5257</td>\n",
       "      <td>-0.0316</td>\n",
       "      <td>0.7421</td>\n",
       "      <td>-0.1186</td>\n",
       "      <td>0.0411</td>\n",
       "      <td>-0.2951</td>\n",
       "      <td>-0.1323</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.7589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Room</th>\n",
       "      <td>0.2312</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.4056</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>-0.5733</td>\n",
       "      <td>0.0917</td>\n",
       "      <td>-0.0387</td>\n",
       "      <td>0.2298</td>\n",
       "      <td>0.0798</td>\n",
       "      <td>-0.0257</td>\n",
       "      <td>-0.1075</td>\n",
       "      <td>-0.7589</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Age  Embarked    Fare   Parch  Pclass     Sex   SibSp  Survived  \\\n",
       "Age       1.0000   -0.0186  0.1048 -0.2110 -0.4031 -0.1125 -0.3128   -0.0619   \n",
       "Embarked -0.0186    1.0000  0.0621 -0.0787  0.0457  0.1166 -0.0600    0.1068   \n",
       "Fare      0.1048    0.0621  1.0000  0.2162 -0.5495  0.1823  0.1597    0.2573   \n",
       "Parch    -0.2110   -0.0787  0.2162  1.0000  0.0184  0.2455  0.4148    0.0816   \n",
       "Pclass   -0.4031    0.0457 -0.5495  0.0184  1.0000 -0.1319  0.0831   -0.3385   \n",
       "Sex      -0.1125    0.1166  0.1823  0.2455 -0.1319  1.0000  0.1146    0.5434   \n",
       "SibSp    -0.3128   -0.0600  0.1597  0.4148  0.0831  0.1146  1.0000   -0.0353   \n",
       "Survived -0.0619    0.1068  0.2573  0.0816 -0.3385  0.5434 -0.0353    1.0000   \n",
       "Title    -0.1123    0.0454  0.1363  0.3158 -0.1739  0.5027  0.2696    0.4078   \n",
       "FSize    -0.3192   -0.0803  0.2171  0.7831  0.0660  0.2010  0.8907    0.0166   \n",
       "Alone     0.2113    0.0178 -0.2718 -0.5834  0.1352 -0.3036 -0.5845   -0.2034   \n",
       "Deck     -0.2868   -0.0391 -0.5257 -0.0316  0.7421 -0.1186  0.0411   -0.2951   \n",
       "Room      0.2312    0.0238  0.4056  0.0016 -0.5733  0.0917 -0.0387    0.2298   \n",
       "\n",
       "           Title   FSize   Alone    Deck    Room  \n",
       "Age      -0.1123 -0.3192  0.2113 -0.2868  0.2312  \n",
       "Embarked  0.0454 -0.0803  0.0178 -0.0391  0.0238  \n",
       "Fare      0.1363  0.2171 -0.2718 -0.5257  0.4056  \n",
       "Parch     0.3158  0.7831 -0.5834 -0.0316  0.0016  \n",
       "Pclass   -0.1739  0.0660  0.1352  0.7421 -0.5733  \n",
       "Sex       0.5027  0.2010 -0.3036 -0.1186  0.0917  \n",
       "SibSp     0.2696  0.8907 -0.5845  0.0411 -0.0387  \n",
       "Survived  0.4078  0.0166 -0.2034 -0.2951  0.2298  \n",
       "Title     1.0000  0.3420 -0.4058 -0.1323  0.0798  \n",
       "FSize     0.3420  1.0000 -0.6909  0.0123 -0.0257  \n",
       "Alone    -0.4058 -0.6909  1.0000  0.1379 -0.1075  \n",
       "Deck     -0.1323  0.0123  0.1379  1.0000 -0.7589  \n",
       "Room      0.0798 -0.0257 -0.1075 -0.7589  1.0000  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma dos dados de teste: (418, 11)\n"
     ]
    }
   ],
   "source": [
    "# definir dados de teste\n",
    "test_data = data[data.Survived.isnull()]\n",
    "\n",
    "X_test = test_data[cols]\n",
    "\n",
    "print('Forma dos dados de teste:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "models = []\n",
    "scores = []\n",
    "stddevs = []\n",
    "times = []\n",
    "\n",
    "def add_model_info(name, model, score, stddev, elapsed):\n",
    "    names.append(name)\n",
    "    models.append((name, model))\n",
    "    scores.append(score)\n",
    "    stddevs.append(stddev)\n",
    "    times.append(elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação e ajuste fino de cada modelo preditivo\n",
    "\n",
    "-  https://scikit-learn.org/stable/modules/classes.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalized Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) \n",
      "Score: 79.12 (+/- 3.31) [ 1217 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.2s finished\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=42, solver='newton-cg', C=0.1, multi_class='auto', max_iter=500)\n",
    "\n",
    "params = dict(\n",
    "    solver=['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    C=np.logspace(-3, 3, 7)\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('LR', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=0.25,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=42, splitter='best') \n",
      "Score: 79.02 (+/- 3.35) [  339 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=42, criterion='entropy', max_depth=6, min_samples_split=0.25)\n",
    "\n",
    "#criterion=’mse’, splitter=’best’, max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, \n",
    "#min_impurity_decrease=0.0, min_impurity_split=None, presort=False\n",
    "\n",
    "params = dict(\n",
    "    criterion=['gini','entropy'],\n",
    "    max_depth=[4, 6, 8, 10, 12, 14],\n",
    "    min_samples_split=[0.25, 0.5, 0.75, 1.0]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('DT', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
      "                           solver='lsqr', store_covariance=False, tol=0.0001) \n",
      "Score: 81.03 (+/- 3.30) [  898 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "model = LinearDiscriminantAnalysis(solver='lsqr')\n",
    "\n",
    "#solver=’svd’, shrinkage=None, priors=None,\n",
    "#n_components=None, store_covariance=False, tol=0.0001\n",
    "\n",
    "params = dict(\n",
    "    solver=['svd', 'lsqr'] #, 'eigen']\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('LDA', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=1e-08) \n",
      "Score: 78.79 (+/- 3.11) [  319 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB(priors=None, var_smoothing=1e-8)\n",
    "\n",
    "#priors=None, var_smoothing=1e-09\n",
    "\n",
    "params = dict(\n",
    "    priors=[None],\n",
    "    var_smoothing=[1e-8, 1e-7, 1e-6, 1e-5, 1e-4]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('NB', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=11, p=2,\n",
      "                     weights='uniform') \n",
      "Score: 82.27 (+/- 3.07) [  766 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=11, weights='uniform')\n",
    "\n",
    "#n_neighbors=5, weights=’uniform’, algorithm=’auto’, leaf_size=30, p=2, metric=’minkowski’,\n",
    "#metric_params=None, n_jobs=None\n",
    "\n",
    "params = dict(\n",
    "    n_neighbors=[1, 3, 5, 7, 9, 11, 13],\n",
    "    weights=['uniform', 'distance']\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('KNN', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
      "    verbose=False) \n",
      "Score: 82.05 (+/- 3.46) [ 1994 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.0s finished\n"
     ]
    }
   ],
   "source": [
    "model = SVC(random_state=42, C=10, gamma=0.1, kernel='rbf')\n",
    "\n",
    "#kernel=’rbf’, degree=3, gamma=’auto_deprecated’, coef0=0.0, tol=0.001, C=1.0, \n",
    "#epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1\n",
    "\n",
    "params = dict(\n",
    "    C=[0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    gamma=[0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    kernel=['linear', 'rbf']\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('SVM', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='logistic', alpha=1, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=42, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False) \n",
      "Score: 81.71 (+/- 2.83) [69285 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.2min finished\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(random_state=42, solver='lbfgs', alpha=1, hidden_layer_sizes=(100,), activation='logistic')\n",
    "                \n",
    "#hidden_layer_sizes=(100, ), activation=’relu’, solver=’adam’, alpha=0.0001, batch_size=’auto’, \n",
    "#learning_rate=’constant’, learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, \n",
    "#random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, \n",
    "#early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10\n",
    "\n",
    "params = dict(\n",
    "    alpha=[1,0.1,0.01,0.001,0.0001,0],\n",
    "    hidden_layer_sizes=[(100,), (50,), (50,2), (5,5,2), (10,5,2)],\n",
    "    activation=['identity', 'logistic', 'tanh', 'relu'],\n",
    "    solver=['lbfgs', 'sgd', 'adam']\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('MLP', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R',\n",
      "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
      "                                                         criterion='gini',\n",
      "                                                         max_depth=None,\n",
      "                                                         max_features=None,\n",
      "                                                         max_leaf_nodes=None,\n",
      "                                                         min_impurity_decrease=0.0,\n",
      "                                                         min_impurity_split=None,\n",
      "                                                         min_samples_leaf=1,\n",
      "                                                         min_samples_split=2,\n",
      "                                                         min_weight_fraction_leaf=0.0,\n",
      "                                                         presort=False,\n",
      "                                                         random_state=42,\n",
      "                                                         splitter='best'),\n",
      "                   learning_rate=1.0, n_estimators=50, random_state=42) \n",
      "Score: 80.70 (+/- 3.66) [11591 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   11.6s finished\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier(DecisionTreeClassifier(random_state=42), random_state=42, n_estimators=50)\n",
    "\n",
    "#base_estimator=None, n_estimators=50, learning_rate=1.0,\n",
    "#algorithm=’SAMME.R’, random_state=None\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[10, 25, 50, 100]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('ABDT', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
      "                  max_features=0.8, max_samples=0.25, n_estimators=100,\n",
      "                  n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                  warm_start=False) \n",
      "Score: 83.84 (+/- 4.29) [ 9514 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    9.5s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "model = BaggingClassifier(random_state=42, n_estimators=100,\n",
    "                          max_samples=0.25, max_features=0.8)\n",
    "\n",
    "#base_estimator=None, n_estimators=10, max_samples=1.0, max_features=1.0,\n",
    "#bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False,\n",
    "#n_jobs=None, random_state=None, verbose=0\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[10, 50, 100, 500],\n",
    "    max_samples=[0.25, 0.5, 0.75, 1.0],\n",
    "    max_features=[0.7, 0.8, 0.9, 1.0]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('BC', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                     max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=0.25,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                     n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                     warm_start=False) \n",
      "Score: 79.91 (+/- 3.24) [ 7414 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    7.4s finished\n"
     ]
    }
   ],
   "source": [
    "model = ExtraTreesClassifier(random_state=42, n_estimators=100, max_depth=7, \n",
    "                             min_samples_split=0.25, max_features='auto')\n",
    "\n",
    "#n_estimators=’warn’, criterion=’gini’, max_depth=None, min_samples_split=2,\n",
    "#min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=’auto’, \n",
    "#max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, \n",
    "#bootstrap=False, oob_score=False, n_jobs=None, random_state=None, verbose=0,\n",
    "#warm_start=False, class_weight=None\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[10, 50, 100, 500],\n",
    "    max_depth=[None, 3, 7, 11],\n",
    "    min_samples_split=[0.25, 0.5],\n",
    "    max_features=['auto', 0.7, 0.85, 1.0]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('ET', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=4,\n",
      "                           max_features=0.75, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=42, subsample=0.6, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False) \n",
      "Score: 83.06 (+/- 3.44) [10184 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   10.2s finished\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(random_state=42, n_estimators=100, max_features=0.75,\n",
    "                                   max_depth=4, learning_rate=0.1, subsample=0.6)\n",
    "\n",
    "#loss=’ls’, learning_rate=0.1, n_estimators=100, subsample=1.0, criterion=’friedman_mse’, min_samples_split=2,\n",
    "#min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, \n",
    "#min_impurity_split=None, init=None, random_state=None, max_features=None, alpha=0.9, verbose=0, \n",
    "#max_leaf_nodes=None, warm_start=False, presort=’auto’, validation_fraction=0.1, n_iter_no_change=None, \n",
    "#tol=0.0001\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[100, 250, 500],\n",
    "    max_features=[0.75, 0.85, 1.0],\n",
    "    max_depth=[4, 6, 8, 10],\n",
    "    learning_rate=[0.05, 0.1, 0.15],\n",
    "    subsample=[0.4, 0.6, 0.8]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('GB', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False) \n",
      "Score: 82.94 (+/- 3.58) [ 8967 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    9.0s finished\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42, n_estimators=100, max_features='auto', max_depth=5)\n",
    "\n",
    "#n_estimators=’warn’, criterion=’mse’, max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#min_weight_fraction_leaf=0.0, max_features=’auto’, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, \n",
    "#verbose=0, warm_start=False\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[10, 50, 100, 500],\n",
    "    max_features=['auto', 'sqrt', 'log2'],\n",
    "    max_depth=[None, 3, 5, 7, 9, 11, 13]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('RF', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outros algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost\n",
    "\n",
    "- https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1) \n",
      "Score: 83.39 (+/- 3.77) [ 3613 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    3.6s finished\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(max_depth=3, n_estimators=100)\n",
    "\n",
    "#max_depth=3, learning_rate=0.1, n_estimators=100, verbosity=1, silent=None, objective='reg:squarederror',\n",
    "#booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, \n",
    "#colsample_bytree=1, colsample_bylevel=1, colsample_bynode=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, \n",
    "#base_score=0.5, random_state=0, seed=None, missing=None, importance_type='gain'\n",
    "\n",
    "params = dict(\n",
    "    max_depth=[3, 5, 7, 9],\n",
    "    n_estimators=[50, 75, 100, 200]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('XGB', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Abaixo é criado um classificador MLP com 20 neurônios na camada intermediária e dropout de 50%. Foi utilizada a função de ativação sigmoid, a função de loss mean squared error e o otimizador RMSProp. O treinamento é realizado por 200 épocas com batch size de 64.\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=X_train.shape[1], activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mse', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hist = model.fit(X_train, y_train, batch_size=64, nb_epoch=200, verbose=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def plot_line(loss, ylabel, xlabel='Epochs'):\n",
    "    fig = plt.figure()\n",
    "    plt.plot(loss)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_line(hist.history['acc'], 'accuracy')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_line(hist.history['loss'], 'loss')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "loss, accuracy = model.evaluate(v_X, v_y)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prefixo_arquivo = 'submissions/titanic-submission'\n",
    "sufixo_arquivo = '07jul'\n",
    "name = 'mlptf'\n",
    "\n",
    "print(model, '\\n')\n",
    "\n",
    "# executar previsão usando o modelo\n",
    "y_pred = model.predict(X_test).ravel()\n",
    "vfunc = np.vectorize(lambda x: 'yes' if x > 0.5 else 'no')\n",
    "\n",
    "# gerar dados de envio (submissão)\n",
    "submission = pd.DataFrame({\n",
    "  'person': X_test.index,\n",
    "  'survived': vfunc(y_pred)\n",
    "})\n",
    "submission.set_index('person', inplace=True)\n",
    "\n",
    "# gerar arquivo CSV para o envio\n",
    "filename = '%s-p-%s-%s.csv' % (prefixo_arquivo, sufixo_arquivo, name.lower())\n",
    "submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM\n",
    "\n",
    "- https://github.com/microsoft/LightGBM\n",
    "- https://lightgbm.readthedocs.io/en/latest/\n",
    "- https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "model = LGBMClassifier(random_state=42, objective='binary', metric='binary_logloss',\n",
    "                      boosting_type='goss', n_estimators=50, max_depth=11)\n",
    "\n",
    "params = dict(\n",
    "    boosting_type=['gbdt', 'dart', 'goss'], #rf\n",
    "    objective=['binary'],\n",
    "    metric=['binary_logloss'],\n",
    "    #bagging_freq=[1, 5, 10],\n",
    "    #bagging_fraction=[0.25, 0.5],\n",
    "    n_estimators=[50, 75, 100, 200],\n",
    "    max_depth=[3, 5, 7, 9, 11]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('LGBM', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "d_train = lgb.Dataset(X_train.values, label=y_train.values)\n",
    "\n",
    "params = {}\n",
    "params['random_state'] = 42\n",
    "params['objective'] = 'binary'\n",
    "params['boosting_type'] = 'goss' # gbdt, rf, dart, goss\n",
    "\n",
    "#params['learning_rate'] = 0.003\n",
    "#params['metric'] = 'binary_logloss'\n",
    "#params['sub_feature'] = 0.5\n",
    "#params['num_leaves'] = 10\n",
    "#params['min_data'] = 50\n",
    "#params['max_depth'] = 10\n",
    "\n",
    "#model = lgb.train(params, d_train, 100)\n",
    "model = lgb.cv(params, d_train, 100, nfold=10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prefixo_arquivo = 'submissions/titanic-submission'\n",
    "sufixo_arquivo = '08jul'\n",
    "name = 'lgbm_' + params['boosting_type']\n",
    "\n",
    "print(model, '\\n')\n",
    "\n",
    "# executar previsão usando o modelo\n",
    "y_pred = clf.predict(X_test.values)\n",
    "vfunc = np.vectorize(lambda x: 'yes' if x > 0.5 else 'no')\n",
    "\n",
    "# gerar dados de envio (submissão)\n",
    "submission = pd.DataFrame({\n",
    "  'person': X_test.index,\n",
    "  'survived': vfunc(y_pred)\n",
    "})\n",
    "submission.set_index('person', inplace=True)\n",
    "\n",
    "# gerar arquivo CSV para o envio\n",
    "filename = '%s-p-%s-%s.csv' % (prefixo_arquivo, sufixo_arquivo, name.lower())\n",
    "submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Learning Model\n",
    "\n",
    "- https://towardsdatascience.com/automate-stacking-in-python-fc3e7834772e\n",
    "- https://github.com/vecxoz/vecstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier(estimators=[('RF',\n",
      "                              RandomForestClassifier(bootstrap=True,\n",
      "                                                     class_weight=None,\n",
      "                                                     criterion='gini',\n",
      "                                                     max_depth=5,\n",
      "                                                     max_features='auto',\n",
      "                                                     max_leaf_nodes=None,\n",
      "                                                     min_impurity_decrease=0.0,\n",
      "                                                     min_impurity_split=None,\n",
      "                                                     min_samples_leaf=1,\n",
      "                                                     min_samples_split=2,\n",
      "                                                     min_weight_fraction_leaf=0.0,\n",
      "                                                     n_estimators=100,\n",
      "                                                     n_jobs=None,\n",
      "                                                     oob_score=False,\n",
      "                                                     random_state=42, verbose=0,\n",
      "                                                     w...\n",
      "                                                         max_leaf_nodes=None,\n",
      "                                                         min_impurity_decrease=0.0,\n",
      "                                                         min_impurity_split=None,\n",
      "                                                         min_samples_leaf=1,\n",
      "                                                         min_samples_split=2,\n",
      "                                                         min_weight_fraction_leaf=0.0,\n",
      "                                                         n_estimators=100,\n",
      "                                                         n_iter_no_change=None,\n",
      "                                                         presort='auto',\n",
      "                                                         random_state=42,\n",
      "                                                         subsample=0.6,\n",
      "                                                         tol=0.0001,\n",
      "                                                         validation_fraction=0.1,\n",
      "                                                         verbose=0,\n",
      "                                                         warm_start=False))],\n",
      "                 flatten_transform=True, n_jobs=-1, voting='hard',\n",
      "                 weights=(2, 1, 1)) \n",
      "Score: 83.05 (+/- 4.18) [39746 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   39.7s finished\n"
     ]
    }
   ],
   "source": [
    "estimators =  [\n",
    "    ('RF', RandomForestClassifier(random_state=42, n_estimators=100, max_features='auto', max_depth=5)),\n",
    "    ('BC', BaggingClassifier(random_state=42, n_estimators=100, max_samples=0.25, max_features=0.8)),\n",
    "    ('GB', GradientBoostingClassifier(random_state=42, max_depth=4, max_features=0.75,\n",
    "                                   n_estimators=100, learning_rate=0.1, subsample=0.6)),\n",
    "#    ('XGB', XGBClassifier(max_depth=3, n_estimators=100)),\n",
    "]\n",
    "model = VotingClassifier(estimators, n_jobs=-1, weights=(2,1,1))\n",
    "\n",
    "#estimators, weights=None, n_jobs=None\n",
    "\n",
    "params = dict(\n",
    "    weights=[(1,1,1), (2,1,1), (3,1,1), (3,2,1), (2,2,1), (2,1,2), (5,4,3), (1,2,1), (1,1,2), ]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('VC', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = SGDClassifier(random_state=42, max_iter=100, tol=0.1)\n",
    "\n",
    "params = {'max_iter':[100, 200, 350, 500, 1000], 'tol':[0.1, 0.01]}\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = Perceptron(random_state=42, max_iter=100, tol=0.01)\n",
    "\n",
    "params = dict(\n",
    "    max_iter=[100, 200, 350, 500, 1000],\n",
    "    tol=[0.1, 0.01, 0.001]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = LinearSVC(random_state=42, max_iter=1000, C=10)\n",
    "\n",
    "params = dict(\n",
    "    C=[0.001, 0.01, 0.1, 1, 10, 100]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliar importância dos atributos no modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <td>0.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deck</th>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FSize</th>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alone</th>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          importance\n",
       "feature             \n",
       "Age            0.224\n",
       "Fare           0.204\n",
       "Title          0.193\n",
       "Sex            0.127\n",
       "Pclass         0.064\n",
       "Deck           0.059\n",
       "FSize          0.045\n",
       "SibSp          0.029\n",
       "Embarked       0.028\n",
       "Parch          0.017\n",
       "Alone          0.008"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42, max_features='auto', n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "importances = pd.DataFrame({'feature': X_train.columns,\n",
    "                            'importance': np.round(model.feature_importances_, 3)})\n",
    "importances = importances.sort_values('importance', ascending=False).set_index('feature')\n",
    "importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xa153e42c>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação final entre os algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Score</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Time (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BC</td>\n",
       "      <td>83.8414</td>\n",
       "      <td>4.2852</td>\n",
       "      <td>9514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGB</td>\n",
       "      <td>83.3920</td>\n",
       "      <td>3.7737</td>\n",
       "      <td>3613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GB</td>\n",
       "      <td>83.0562</td>\n",
       "      <td>3.4408</td>\n",
       "      <td>10184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>VC</td>\n",
       "      <td>83.0537</td>\n",
       "      <td>4.1832</td>\n",
       "      <td>39746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RF</td>\n",
       "      <td>82.9401</td>\n",
       "      <td>3.5830</td>\n",
       "      <td>8967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>82.2697</td>\n",
       "      <td>3.0721</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>82.0462</td>\n",
       "      <td>3.4590</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLP</td>\n",
       "      <td>81.7079</td>\n",
       "      <td>2.8304</td>\n",
       "      <td>69285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LDA</td>\n",
       "      <td>81.0337</td>\n",
       "      <td>3.3045</td>\n",
       "      <td>898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ABDT</td>\n",
       "      <td>80.7004</td>\n",
       "      <td>3.6560</td>\n",
       "      <td>11591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ET</td>\n",
       "      <td>79.9101</td>\n",
       "      <td>3.2350</td>\n",
       "      <td>7414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>79.1236</td>\n",
       "      <td>3.3080</td>\n",
       "      <td>1217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>79.0200</td>\n",
       "      <td>3.3458</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB</td>\n",
       "      <td>78.7890</td>\n",
       "      <td>3.1068</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Algorithm    Score  Std Dev  Time (ms)\n",
       "8         BC  83.8414   4.2852       9514\n",
       "12       XGB  83.3920   3.7737       3613\n",
       "10        GB  83.0562   3.4408      10184\n",
       "13        VC  83.0537   4.1832      39746\n",
       "11        RF  82.9401   3.5830       8967\n",
       "4        KNN  82.2697   3.0721        766\n",
       "5        SVM  82.0462   3.4590       1994\n",
       "6        MLP  81.7079   2.8304      69285\n",
       "2        LDA  81.0337   3.3045        898\n",
       "7       ABDT  80.7004   3.6560      11591\n",
       "9         ET  79.9101   3.2350       7414\n",
       "0         LR  79.1236   3.3080       1217\n",
       "1         DT  79.0200   3.3458        339\n",
       "3         NB  78.7890   3.1068        319"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'Algorithm': names, 'Score': scores, 'Std Dev': stddevs, 'Time (ms)': times})\n",
    "results.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerar arquivos com resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar diretório para os arquivos de envio\n",
    "!test -d submissions || mkdir submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) \n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=0.25,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=42, splitter='best') \n",
      "\n",
      "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
      "                           solver='lsqr', store_covariance=False, tol=0.0001) \n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-08) \n",
      "\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=11, p=2,\n",
      "                     weights='uniform') \n",
      "\n",
      "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
      "    verbose=False) \n",
      "\n",
      "MLPClassifier(activation='logistic', alpha=1, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=42, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False) \n",
      "\n",
      "AdaBoostClassifier(algorithm='SAMME.R',\n",
      "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
      "                                                         criterion='gini',\n",
      "                                                         max_depth=None,\n",
      "                                                         max_features=None,\n",
      "                                                         max_leaf_nodes=None,\n",
      "                                                         min_impurity_decrease=0.0,\n",
      "                                                         min_impurity_split=None,\n",
      "                                                         min_samples_leaf=1,\n",
      "                                                         min_samples_split=2,\n",
      "                                                         min_weight_fraction_leaf=0.0,\n",
      "                                                         presort=False,\n",
      "                                                         random_state=42,\n",
      "                                                         splitter='best'),\n",
      "                   learning_rate=1.0, n_estimators=50, random_state=42) \n",
      "\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
      "                  max_features=0.8, max_samples=0.25, n_estimators=100,\n",
      "                  n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                  warm_start=False) \n",
      "\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                     max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=0.25,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                     n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                     warm_start=False) \n",
      "\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=4,\n",
      "                           max_features=0.75, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=42, subsample=0.6, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False) \n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False) \n",
      "\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1) \n",
      "\n",
      "VotingClassifier(estimators=[('RF',\n",
      "                              RandomForestClassifier(bootstrap=True,\n",
      "                                                     class_weight=None,\n",
      "                                                     criterion='gini',\n",
      "                                                     max_depth=5,\n",
      "                                                     max_features='auto',\n",
      "                                                     max_leaf_nodes=None,\n",
      "                                                     min_impurity_decrease=0.0,\n",
      "                                                     min_impurity_split=None,\n",
      "                                                     min_samples_leaf=1,\n",
      "                                                     min_samples_split=2,\n",
      "                                                     min_weight_fraction_leaf=0.0,\n",
      "                                                     n_estimators=100,\n",
      "                                                     n_jobs=None,\n",
      "                                                     oob_score=False,\n",
      "                                                     random_state=42, verbose=0,\n",
      "                                                     w...\n",
      "                                                         max_leaf_nodes=None,\n",
      "                                                         min_impurity_decrease=0.0,\n",
      "                                                         min_impurity_split=None,\n",
      "                                                         min_samples_leaf=1,\n",
      "                                                         min_samples_split=2,\n",
      "                                                         min_weight_fraction_leaf=0.0,\n",
      "                                                         n_estimators=100,\n",
      "                                                         n_iter_no_change=None,\n",
      "                                                         presort='auto',\n",
      "                                                         random_state=42,\n",
      "                                                         subsample=0.6,\n",
      "                                                         tol=0.0001,\n",
      "                                                         validation_fraction=0.1,\n",
      "                                                         verbose=0,\n",
      "                                                         warm_start=False))],\n",
      "                 flatten_transform=True, n_jobs=-1, voting='hard',\n",
      "                 weights=(2, 1, 1)) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prefixo_arquivo = 'submissions/titanic-submission'\n",
    "sufixo_arquivo = '06set'\n",
    "\n",
    "for name, model in models:\n",
    "    print(model, '\\n')\n",
    "    \n",
    "    # treinar o modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # executar previsão usando o modelo\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_int = y_pred.astype(int)\n",
    "    #vfunc = np.vectorize(lambda x: 'yes' if x > 0 else 'no')\n",
    "\n",
    "    # gerar dados de envio (submissão)\n",
    "    submission = pd.DataFrame({\n",
    "      'PassengerId': X_test.index,\n",
    "      'Survived': y_pred_int #vfunc(y_pred)\n",
    "    })\n",
    "    submission.set_index('PassengerId', inplace=True)\n",
    "\n",
    "    # gerar arquivo CSV para o envio\n",
    "    filename = '%s-p-%s-%s.csv' % (prefixo_arquivo, sufixo_arquivo, name.lower())\n",
    "    submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> submissions/titanic-submission-p-06set-abdt.csv <==\r\n",
      "PassengerId,Survived\r\n",
      "892,0\r\n",
      "893,0\r\n",
      "894,0\r\n",
      "895,1\r\n",
      "896,0\r\n",
      "897,0\r\n",
      "898,0\r\n",
      "899,0\r\n",
      "900,1\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-06set-bc.csv <==\r\n",
      "PassengerId,Survived\r\n",
      "892,0\r\n",
      "893,0\r\n",
      "894,0\r\n",
      "895,0\r\n",
      "896,1\r\n",
      "897,0\r\n",
      "898,1\r\n",
      "899,0\r\n",
      "900,1\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-06set-dt.csv <==\r\n",
      "PassengerId,Survived\r\n",
      "892,0\r\n",
      "893,0\r\n",
      "894,0\r\n",
      "895,0\r\n",
      "896,0\r\n",
      "897,0\r\n",
      "898,0\r\n",
      "899,0\r\n",
      "900,0\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-06set-et.csv <==\r\n",
      "PassengerId,Survived\r\n",
      "892,0\r\n",
      "893,1\r\n",
      "894,0\r\n",
      "895,0\r\n",
      "896,1\r\n",
      "897,0\r\n",
      "898,1\r\n",
      "899,0\r\n",
      "900,1\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-06set-gb.csv <==\r\n",
      "PassengerId,Survived\r\n",
      "892,0\r\n",
      "893,0\r\n",
      "894,0\r\n",
      "895,0\r\n",
      "896,1\r\n",
      "897,0\r\n",
      "898,0\r\n",
      "899,0\r\n",
      "900,1\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-06set-knn.csv <==\r\n",
      "PassengerId,Survived\r\n",
      "892,0\r\n",
      "893,0\r\n",
      "894,0\r\n",
      "895,0\r\n",
      "896,1\r\n",
      "897,0\r\n",
      "898,1\r\n",
      "899,0\r\n",
      "900,1\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-06set-lda.csv <==\r\n",
      "PassengerId,Survived\r\n",
      "892,0\r\n",
      "893,1\r\n",
      "894,0\r\n",
      "895,0\r\n",
      "896,1\r\n",
      "897,0\r\n",
      "898,1\r\n",
      "899,0\r\n",
      "900,1\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-06set-lr.csv <==\r\n",
      "PassengerId,Survived\r\n",
      "892,0\r\n",
      "893,1\r\n",
      "894,0\r\n",
      "895,0\r\n",
      "896,1\r\n",
      "897,0\r\n",
      "898,1\r\n",
      "899,0\r\n",
      "900,1\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-06set-mlp.csv <==\r\n",
      "PassengerId,Survived\r\n",
      "892,0\r\n",
      "893,1\r\n",
      "894,0\r\n",
      "895,0\r\n",
      "896,1\r\n",
      "897,0\r\n",
      "898,1\r\n",
      "899,0\r\n",
      "900,1\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-06set-nb.csv <==\r\n",
      "PassengerId,Survived\r\n",
      "892,0\r\n",
      "893,1\r\n",
      "894,0\r\n",
      "895,0\r\n",
      "896,1\r\n",
      "897,0\r\n",
      "898,1\r\n",
      "899,0\r\n",
      "900,1\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-06set-rf.csv <==\r\n",
      "PassengerId,Survived\r\n",
      "892,0\r\n",
      "893,0\r\n",
      "894,0\r\n",
      "895,0\r\n",
      "896,1\r\n",
      "897,0\r\n",
      "898,1\r\n",
      "899,0\r\n",
      "900,1\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-06set-svm.csv <==\r\n",
      "PassengerId,Survived\r\n",
      "892,0\r\n",
      "893,0\r\n",
      "894,0\r\n",
      "895,0\r\n",
      "896,0\r\n",
      "897,0\r\n",
      "898,1\r\n",
      "899,0\r\n",
      "900,1\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-06set-vc.csv <==\r\n",
      "PassengerId,Survived\r\n",
      "892,0\r\n",
      "893,0\r\n",
      "894,0\r\n",
      "895,0\r\n",
      "896,1\r\n",
      "897,0\r\n",
      "898,1\r\n",
      "899,0\r\n",
      "900,1\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-06set-xgb.csv <==\r\n",
      "PassengerId,Survived\r\n",
      "892,0\r\n",
      "893,0\r\n",
      "894,0\r\n",
      "895,0\r\n",
      "896,0\r\n",
      "897,0\r\n",
      "898,1\r\n",
      "899,0\r\n",
      "900,1\r\n"
     ]
    }
   ],
   "source": [
    "!head submissions/titanic-*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
