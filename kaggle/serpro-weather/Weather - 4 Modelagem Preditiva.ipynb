{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação dos pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar pacotes necessários\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir parâmetros extras\n",
    "#pd.set_option('precision', 2)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar pacotes usados na seleção do modelo e na medição da precisão\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# importar os pacotes necessários para os algoritmos de regressão\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "#from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lars\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import RadiusNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import NuSVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga dos dados de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1508, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-10-01</th>\n",
       "      <td>11.036840</td>\n",
       "      <td>74.800000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-02</th>\n",
       "      <td>14.340558</td>\n",
       "      <td>58.444444</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-03</th>\n",
       "      <td>14.518382</td>\n",
       "      <td>78.555556</td>\n",
       "      <td>1.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-04</th>\n",
       "      <td>16.820351</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-05</th>\n",
       "      <td>16.948431</td>\n",
       "      <td>70.555556</td>\n",
       "      <td>3.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            temperature   humidity  wind_speed\n",
       "date                                          \n",
       "2012-10-01    11.036840  74.800000    0.000000\n",
       "2012-10-02    14.340558  58.444444    0.666667\n",
       "2012-10-03    14.518382  78.555556    1.888889\n",
       "2012-10-04    16.820351  86.000000    1.333333\n",
       "2012-10-05    16.948431  70.555556    3.666667"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carregar arquivo de dados de treino\n",
    "filename = 'weather-train.csv'\n",
    "#filename = 'https://github.com/hjort/ai-labs/raw/master/kaggle/serpro-abalone/abalone-train.csv'\n",
    "data = pd.read_csv(filename, index_col='date', parse_dates=['date'])\n",
    "\n",
    "# mostrar tamanho\n",
    "print(data.shape)\n",
    "\n",
    "# mostrar alguns exemplos de registros\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.dropna(inplace=True)\n",
    "data.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma dos dados originais: (1507, 2) (1507,)\n"
     ]
    }
   ],
   "source": [
    "# definir dados de entrada\n",
    "X = data.drop(['temperature'], axis=1) # tudo, exceto a coluna alvo\n",
    "y = data['temperature'] # apenas a coluna alvo\n",
    "\n",
    "print('Forma dos dados originais:', X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento dos modelos preditivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "# cria função para cálculo do RMSE (REMQ)\n",
    "def root_mean_squared_error(ground_truth, predictions):\n",
    "    return mean_squared_error(ground_truth, predictions) ** 0.5\n",
    "\n",
    "RMSE = make_scorer(root_mean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import SCORERS\n",
    "#sorted(SCORERS.keys())\n",
    "MAE = 'neg_mean_absolute_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# avalia o desempenho do modelo, retornando o valor do RMSE\n",
    "def evaluate_model_cv(model, X=X, y=y):\n",
    "    start = datetime.now()\n",
    "    kfold = KFold(n_splits=10, random_state=42)\n",
    "    results = cross_val_score(model, X, y, cv=kfold, scoring=MAE, verbose=1)\n",
    "    #results = cross_val_score(model, X, y, cv=kfold, scoring=RMSE, verbose=1)\n",
    "    end = datetime.now()\n",
    "    elapsed = int((end - start).total_seconds() * 1000)\n",
    "    score = (-1) * results.mean()\n",
    "    stddev = results.std()\n",
    "    print(model, '\\nScore: %.2f (+/- %.2f) [%5s ms]' % (score, stddev, elapsed))\n",
    "    return score, stddev, elapsed"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# executa o teste definitivo (contra a solução)\n",
    "from datetime import datetime\n",
    "\n",
    "X_test = pd.get_dummies(pd.read_csv('abalone-test.csv', index_col='id'))\n",
    "y_real = pd.read_csv('abalone-solution.csv', index_col='id')\n",
    "\n",
    "names = []\n",
    "scores = []\n",
    "stddevs = []\n",
    "times = []\n",
    "\n",
    "def evaluate_model_cv(model):\n",
    "    start = datetime.now()\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = root_mean_squared_error(y_real, y_pred)\n",
    "    end = datetime.now()\n",
    "    elapsed = int((end - start).total_seconds() * 1000)\n",
    "    print(model, '\\nScore: %.2f [%5s ms]' % (score, elapsed))\n",
    "    names.append(model)\n",
    "    scores.append(score)\n",
    "    stddevs.append(0)\n",
    "    times.append(elapsed)\n",
    "    return score, 0, elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faz o ajuste fino do modelo, calculando os melhores hiperparâmetros\n",
    "def fine_tune_model(model, params, X=X, y=y):\n",
    "  print('\\nFine Tuning Model:')\n",
    "  print(model, \"\\nparams:\", params)\n",
    "  kfold = KFold(n_splits=10, random_state=42)\n",
    "  grid = GridSearchCV(estimator=model, param_grid=params, scoring=MAE, cv=kfold, verbose=1)\n",
    "  #grid = GridSearchCV(estimator=model, param_grid=params, scoring=RMSE, cv=kfold, verbose=1)\n",
    "  grid.fit(X, y)\n",
    "  print('\\nGrid Best Score: %.2f' % (grid.best_score_ * (-1)))\n",
    "  print('Best Params:', grid.best_params_)\n",
    "  return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação e ajuste fino de cada modelo preditivo\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/classes.html\n",
    "- https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalized Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True) \n",
      "Score: 10.32 (+/- 2.61) [  341 ms]\n",
      "\n",
      "Fine Tuning Model:\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True) \n",
      "params: {'fit_intercept': [True, False], 'normalize': [True, False]}\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "\n",
      "Grid Best Score: 10.32\n",
      "Best Params: {'fit_intercept': True, 'normalize': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=42, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'fit_intercept': [True, False], 'normalize': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_absolute_error', verbose=1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression(n_jobs=-1, fit_intercept=True, normalize=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = dict(\n",
    "    fit_intercept=[True, False],\n",
    "    normalize=[True, False]\n",
    ")\n",
    "fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = LogisticRegression(n_jobs=-1, random_state=42, multi_class='auto', C=1000, solver='newton-cg')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = dict(\n",
    "    solver=['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    C=np.logspace(-3, 3, 7)\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,\n",
      "             normalize=True, precompute='auto', tol=None) \n",
      "Score: 10.20 (+/- 2.54) [  262 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "model = OrthogonalMatchingPursuit(fit_intercept=True, normalize=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = dict(\n",
    "    n_nonzero_coefs=[None, 1, 2, 5, 7],\n",
    "    fit_intercept=[True, False],\n",
    "    normalize=[True, False]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassiveAggressiveRegressor(C=0.1, average=False, early_stopping=False,\n",
      "              epsilon=0.1, fit_intercept=True, loss='epsilon_insensitive',\n",
      "              max_iter=1000, n_iter=None, n_iter_no_change=5,\n",
      "              random_state=42, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Score: 13.80 (+/- 7.35) [  323 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "model = PassiveAggressiveRegressor(random_state=42, C=0.1, fit_intercept=True, max_iter=1000, tol=0.001)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {\n",
    "    'C': [0.1, 0.2, 0.4, 0.8, 1.0],\n",
    "    'fit_intercept': [True, False],\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "model = Perceptron(random_state=42, penalty='l2', alpha=1e-3, fit_intercept=True, max_iter=1000, tol=1e-3)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#penalty=None, alpha=0.0001, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, eta0=1.0,\n",
    "#n_jobs=None, random_state=0, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, \n",
    "#class_weight=None, warm_start=False\n",
    "\n",
    "params = {\n",
    "    'penalty': [None, 'l2', 'l1', 'elasticnet'],\n",
    "    'alpha': np.logspace(-6, -1, 6),\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANSACRegressor(base_estimator=None, is_data_valid=None, is_model_valid=None,\n",
      "        loss='absolute_loss', max_skips=inf, max_trials=100,\n",
      "        min_samples=0.75, random_state=42, residual_threshold=None,\n",
      "        stop_n_inliers=inf, stop_probability=0.99, stop_score=inf) \n",
      "Score: 10.55 (+/- 2.84) [ 7681 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    7.7s finished\n"
     ]
    }
   ],
   "source": [
    "model = RANSACRegressor(random_state=42, min_samples=0.75)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#base_estimator=None, min_samples=None, residual_threshold=None, is_data_valid=None, is_model_valid=None,\n",
    "#max_trials=100, max_skips=inf, stop_n_inliers=inf, stop_score=inf, stop_probability=0.99, loss=’absolute_loss’,\n",
    "#random_state=None\n",
    "\n",
    "params = {\n",
    "    'min_samples': [None, 0.1, 0.25, 0.5, 0.75, 1.0]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=0.001, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=True, random_state=42, solver='auto', tol=0.001) \n",
      "Score: 10.32 (+/- 2.61) [  284 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "model = Ridge(random_state=42, alpha=0.001, fit_intercept=True, normalize=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, solver=’auto’,\n",
    "#random_state=None\n",
    "\n",
    "params = {\n",
    "    'alpha': np.logspace(-6, -1, 6),\n",
    "    'fit_intercept': [True, False],\n",
    "    'normalize': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "       n_iter=None, n_iter_no_change=5, penalty='l2', power_t=0.25,\n",
      "       random_state=42, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "       verbose=0, warm_start=False) \n",
      "Score: 942148954292.23 (+/- 594679127202.16) [ 1681 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.7s finished\n"
     ]
    }
   ],
   "source": [
    "model = SGDRegressor(random_state=42, max_iter=1000, tol=1e-3)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#loss=’squared_loss’, penalty=’l2’, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001,\n",
    "#shuffle=True, verbose=0, epsilon=0.1, random_state=None, learning_rate=’invscaling’, eta0=0.01, power_t=0.25,\n",
    "#early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, warm_start=False, average=False\n",
    "\n",
    "params = {\n",
    "    'penalty': [None, 'l2', 'l1', 'elasticnet'],\n",
    "    'alpha': np.logspace(-6, -1, 6),\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheilSenRegressor(copy_X=True, fit_intercept=True, max_iter=300,\n",
      "         max_subpopulation=10000, n_jobs=-1, n_subsamples=None,\n",
      "         random_state=42, tol=0.001, verbose=False) \n",
      "Score: 10.39 (+/- 2.96) [53517 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   53.5s finished\n"
     ]
    }
   ],
   "source": [
    "model = TheilSenRegressor(random_state=42, n_jobs=-1, fit_intercept=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#fit_intercept=True, copy_X=True, max_subpopulation=10000.0, n_subsamples=None, \n",
    "#max_iter=300, tol=0.001, random_state=None, n_jobs=None, verbose=False\n",
    "\n",
    "params = {\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor(criterion='mse', max_depth=4, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=0.25, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=42, splitter='best') \n",
      "Score: 10.31 (+/- 2.48) [  296 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(random_state=42, max_depth=4, min_samples_split=0.25)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#criterion=’mse’, splitter=’best’, max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, \n",
    "#min_impurity_decrease=0.0, min_impurity_split=None, presort=False\n",
    "\n",
    "params = dict(\n",
    "    max_depth=[4, 6, 8, 10, 12, 14],\n",
    "    min_samples_split=[0.25, 0.5, 0.75, 1.0]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianProcessRegressor(alpha=0.01, copy_X_train=True, kernel=None,\n",
      "             n_restarts_optimizer=0, normalize_y=False,\n",
      "             optimizer='fmin_l_bfgs_b', random_state=42) \n",
      "Score: 11.52 (+/- 2.57) [24700 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   24.7s finished\n"
     ]
    }
   ],
   "source": [
    "model = GaussianProcessRegressor(random_state=42, alpha=0.01, normalize_y=False)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#kernel=None, alpha=1e-10, optimizer=’fmin_l_bfgs_b’, n_restarts_optimizer=0,\n",
    "#normalize_y=False, copy_X_train=True, random_state=None\n",
    "\n",
    "params = dict(\n",
    "    alpha=np.logspace(-6, -1, 6),\n",
    "    normalize_y=[True, False]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KernelRidge(alpha=0.1, coef0=1, degree=3, gamma=None, kernel='linear',\n",
      "      kernel_params=None) \n",
      "Score: 10.40 (+/- 2.68) [11561 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   11.6s finished\n"
     ]
    }
   ],
   "source": [
    "model = KernelRidge(alpha=0.1)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#alpha=1, kernel=’linear’, gamma=None, degree=3, coef0=1, kernel_params=None\n",
    "\n",
    "params = dict(\n",
    "    alpha=np.logspace(-6, -1, 6)\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naïve Bayes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = GaussianNB(var_smoothing=0.001)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#priors=None, var_smoothing=1e-09\n",
    "\n",
    "params = dict(\n",
    "    var_smoothing=np.logspace(-9, -1, 5)\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=-1, n_neighbors=11, p=2,\n",
      "          weights='distance') \n",
      "Score: 10.70 (+/- 2.57) [  636 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsRegressor(n_jobs=-1, n_neighbors=11, weights='distance')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#n_neighbors=5, weights=’uniform’, algorithm=’auto’, leaf_size=30, p=2, metric=’minkowski’,\n",
    "#metric_params=None, n_jobs=None\n",
    "\n",
    "params = {\n",
    "    'n_neighbors': [1, 3, 5, 7, 9, 11, 13],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False) \n",
      "Score: 10.53 (+/- 2.97) [ 9574 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    9.6s finished\n"
     ]
    }
   ],
   "source": [
    "model = SVR(gamma='auto', kernel='linear')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#kernel=’rbf’, degree=3, gamma=’auto_deprecated’, coef0=0.0, tol=0.001, C=1.0, \n",
    "#epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1\n",
    "\n",
    "params = {\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']#, 'precomputed']\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False) \n",
      "Score: 10.32 (+/- 2.61) [ 1238 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.2s finished\n"
     ]
    }
   ],
   "source": [
    "model = MLPRegressor(random_state=42, max_iter=500,\n",
    "                     activation='tanh', hidden_layer_sizes=(5, 2), solver='lbfgs')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#hidden_layer_sizes=(100, ), activation=’relu’, solver=’adam’, alpha=0.0001, batch_size=’auto’, \n",
    "#learning_rate=’constant’, learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, \n",
    "#random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, \n",
    "#early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10\n",
    "\n",
    "params = dict(\n",
    "    hidden_layer_sizes=[(100,), (50,), (50,2)],\n",
    "    activation=['identity', 'logistic', 'tanh', 'relu'],\n",
    "    solver=['lbfgs', 'sgd', 'adam']\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=9,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "           oob_score=False, random_state=42, verbose=0, warm_start=False) \n",
      "Score: 10.38 (+/- 2.51) [13020 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   13.0s finished\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(random_state=42, n_jobs=-1, n_estimators=100, max_depth=9)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#n_estimators=’warn’, criterion=’mse’, max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#min_weight_fraction_leaf=0.0, max_features=’auto’, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, \n",
    "#verbose=0, warm_start=False\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [5, 10, 25, 50, 75, 100],\n",
    "    'max_depth': [None, 3, 5, 7, 9, 11, 13]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.05, loss='ls', max_depth=6, max_features=0.75,\n",
      "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "             min_impurity_split=None, min_samples_leaf=1,\n",
      "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "             n_estimators=100, n_iter_no_change=None, presort='auto',\n",
      "             random_state=42, subsample=0.8, tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Score: 10.39 (+/- 2.51) [ 4981 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    5.0s finished\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(random_state=42, learning_rate=0.05, n_estimators=100,\n",
    "                                  subsample=0.8, max_depth=6, max_features=0.75)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#loss=’ls’, learning_rate=0.1, n_estimators=100, subsample=1.0, criterion=’friedman_mse’, min_samples_split=2,\n",
    "#min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, \n",
    "#min_impurity_split=None, init=None, random_state=None, max_features=None, alpha=0.9, verbose=0, \n",
    "#max_leaf_nodes=None, warm_start=False, presort=’auto’, validation_fraction=0.1, n_iter_no_change=None, \n",
    "#tol=0.0001\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[100, 250, 500],\n",
    "    max_features=[0.75, 0.85, 1.0],\n",
    "    max_depth=[4, 6, 8, 10],\n",
    "    learning_rate=[0.05, 0.1, 0.15],\n",
    "    subsample=[0.4, 0.6, 0.8]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features=0.75, max_leaf_nodes=None,\n",
      "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
      "          oob_score=False, random_state=42, verbose=0, warm_start=False) \n",
      "Score: 11.17 (+/- 2.22) [27874 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   27.9s finished\n"
     ]
    }
   ],
   "source": [
    "model = ExtraTreesRegressor(random_state=42, n_jobs=-1, n_estimators=200, max_features=0.75)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#n_estimators=’warn’, criterion=’mse’, max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#min_weight_fraction_leaf=0.0, max_features=’auto’, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#min_impurity_split=None, bootstrap=False, oob_score=False, n_jobs=None, random_state=None, verbose=0,\n",
    "#warm_start=False\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[50, 75, 100, 200],\n",
    "    max_features=['auto', 0.75, 0.85, 1.0]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingRegressor(base_estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best'),\n",
      "         bootstrap=True, bootstrap_features=False, max_features=0.75,\n",
      "         max_samples=1.0, n_estimators=75, n_jobs=-1, oob_score=False,\n",
      "         random_state=42, verbose=0, warm_start=False) \n",
      "Score: 10.53 (+/- 2.65) [ 9676 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    9.7s finished\n"
     ]
    }
   ],
   "source": [
    "model = BaggingRegressor(random_state=42, n_jobs=-1, base_estimator=DecisionTreeRegressor(),\n",
    "                        max_features=0.75, n_estimators=75)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#base_estimator=None, n_estimators=10, max_samples=1.0, max_features=1.0, bootstrap=True, \n",
    "#bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=None, random_state=None, verbose=0\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[50, 75, 100, 200],\n",
    "    max_features=[0.5, 0.75, 1.0]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best'),\n",
      "         learning_rate=1.0, loss='linear', n_estimators=200,\n",
      "         random_state=42) \n",
      "Score: 11.06 (+/- 2.21) [23436 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   23.4s finished\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostRegressor(random_state=42, n_estimators=200, base_estimator=DecisionTreeRegressor())\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "# base_estimator=None, n_estimators=50, learning_rate=1.0, algorithm=’SAMME.R’, random_state=None\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[50, 75, 100, 200]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outros algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost\n",
    "\n",
    "- https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# https://machinelearningmastery.com/how-to-fix-futurewarning-messages-in-scikit-learn/\n",
    "\n",
    "# import warnings filter\n",
    "#from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "#simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# ignore all caught warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=5, min_child_weight=1, missing=None, n_estimators=50,\n",
      "       n_jobs=-1, nthread=None, objective='reg:squarederror',\n",
      "       random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=None, subsample=1, verbosity=1) \n",
      "Score: 10.43 (+/- 2.56) [ 4128 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    4.1s finished\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "model = XGBRegressor(random_state=42, n_jobs=-1, learning_rate=0.1,\n",
    "                     n_estimators=50, max_depth=5, objective='reg:squarederror')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#max_depth=3, learning_rate=0.1, n_estimators=100, verbosity=1, silent=None, objective='reg:squarederror',\n",
    "#booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, \n",
    "#colsample_bytree=1, colsample_bylevel=1, colsample_bynode=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, \n",
    "#base_score=0.5, random_state=0, seed=None, missing=None, importance_type='gain'\n",
    "\n",
    "params = dict(\n",
    "    max_depth=[3, 5, 7, 9],\n",
    "    n_estimators=[50, 75, 100, 200]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Learning Model\n",
    "\n",
    "- https://towardsdatascience.com/automate-stacking-in-python-fc3e7834772e\n",
    "- https://github.com/vecxoz/vecstack"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "?stacking"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from vecstack import stacking\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Make train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize 1-st level models\n",
    "ensemble_models = [\n",
    "    RandomForestRegressor(random_state=42, n_jobs=2, n_estimators=100, max_depth=7),\n",
    "    GradientBoostingRegressor(random_state=42, learning_rate=0.05, n_estimators=100,\n",
    "                                  subsample=0.4, max_depth=6, max_features=1.0),\n",
    "    #ExtraTreesRegressor(random_state=42, n_jobs=2, n_estimators=100)\n",
    "    XGBRegressor(random_state=42, n_jobs=2, learning_rate=0.1,\n",
    "                     n_estimators=50, max_depth=5, objective='reg:squarederror')\n",
    "]\n",
    "\n",
    "# Compute stacking features\n",
    "S_train, S_test = stacking(ensemble_models, X_train, y_train, X_test,\n",
    "    regression=True, metric=mean_squared_error, n_folds=4, shuffle=True,\n",
    "    random_state=42, verbose=2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "S_train, S_test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Initialize 2-nd level model\n",
    "model = XGBRegressor(random_state=42, n_jobs=2, learning_rate=0.1,\n",
    "                     n_estimators=50, max_depth=5, objective='reg:squarederror')\n",
    "\n",
    "# Fit 2-nd level model\n",
    "model = model.fit(S_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(S_test)\n",
    "\n",
    "# Final prediction score\n",
    "print('Final prediction score: [%.8f]' % mean_squared_error(y_test, y_pred) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingRegressor(estimators=[('MLP',\n",
      "                             MLPRegressor(activation='tanh', alpha=0.0001,\n",
      "                                          batch_size='auto', beta_1=0.9,\n",
      "                                          beta_2=0.999, early_stopping=False,\n",
      "                                          epsilon=1e-08,\n",
      "                                          hidden_layer_sizes=(5, 2),\n",
      "                                          learning_rate='constant',\n",
      "                                          learning_rate_init=0.001,\n",
      "                                          max_iter=500, momentum=0.9,\n",
      "                                          n_iter_no_change=10,\n",
      "                                          nesterovs_momentum=True, power_t=0.5,\n",
      "                                          random_state=42, shuffle=True,\n",
      "                                          solver='...\n",
      "                                                       loss='ls', max_depth=6,\n",
      "                                                       max_features=0.75,\n",
      "                                                       max_leaf_nodes=None,\n",
      "                                                       min_impurity_decrease=0.0,\n",
      "                                                       min_impurity_split=None,\n",
      "                                                       min_samples_leaf=1,\n",
      "                                                       min_samples_split=2,\n",
      "                                                       min_weight_fraction_leaf=0.0,\n",
      "                                                       n_estimators=100,\n",
      "                                                       n_iter_no_change=None,\n",
      "                                                       presort='auto',\n",
      "                                                       random_state=42,\n",
      "                                                       subsample=0.8,\n",
      "                                                       tol=0.0001,\n",
      "                                                       validation_fraction=0.1,\n",
      "                                                       verbose=0,\n",
      "                                                       warm_start=False))],\n",
      "                n_jobs=-1, weights=(2, 1, 1)) \n",
      "Score: 2.09 (+/- 0.18) [ 5852 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    5.9s finished\n"
     ]
    }
   ],
   "source": [
    "# https://towardsdatascience.com/ensemble-learning-using-scikit-learn-85c4531ff86a\n",
    "\n",
    "# classe não disponível no pacote :P\n",
    "#from sklearn.ensemble import VotingRegressor\n",
    "#conda update scikit-learn\n",
    "#pip install -U scikit-learn\n",
    "\n",
    "estimators =  [\n",
    "    ('MLP', MLPRegressor(random_state=42, max_iter=500,\n",
    "                     activation='tanh', hidden_layer_sizes=(5, 2), solver='lbfgs')),\n",
    "    ('GPR', GaussianProcessRegressor(random_state=42, alpha=0.01, normalize_y=False)),\n",
    "    ('GBR', GradientBoostingRegressor(random_state=42, learning_rate=0.05, n_estimators=100,\n",
    "                                  subsample=0.8, max_depth=6, max_features=0.75))\n",
    "    #('RFR', RandomForestRegressor(random_state=42, n_jobs=-1, n_estimators=100, max_depth=7)),\n",
    "    #('ETR', ExtraTreesRegressor(random_state=42, n_jobs=-1, n_estimators=100)),\n",
    "    #('XGBR', XGBRegressor(random_state=42, n_jobs=-1, learning_rate=0.1,\n",
    "    #             n_estimators=50, max_depth=5, objective='reg:squarederror'))\n",
    "]\n",
    "\n",
    "model = VotingRegressor(estimators, n_jobs=-1, weights=(2,1,1))\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#estimators, weights=None, n_jobs=None\n",
    "\n",
    "params = dict(\n",
    "    weights=[(1,1,1), (5,4,3), (2,1,1), (3,2,1)]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação final entre os algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "# Generalized Linear Models\n",
    "models.append(('LinReg', LinearRegression(n_jobs=-1, fit_intercept=True, normalize=True)))\n",
    "models.append(('LogReg', LogisticRegression(n_jobs=-1, random_state=42, multi_class='auto', C=1000, solver='newton-cg')))\n",
    "models.append(('OMP', OrthogonalMatchingPursuit(n_nonzero_coefs=7, fit_intercept=True, normalize=True)))\n",
    "models.append(('PAR', PassiveAggressiveRegressor(random_state=42, C=0.1, fit_intercept=True, max_iter=1000, tol=0.001)))\n",
    "models.append(('PP', Perceptron(random_state=42, penalty='l2', alpha=1e-3, fit_intercept=True, max_iter=1000, tol=1e-3)))\n",
    "models.append(('RANSAC', RANSACRegressor(random_state=42, min_samples=0.75)))\n",
    "models.append(('Ridge', Ridge(random_state=42, alpha=0.001, fit_intercept=True, normalize=True)))\n",
    "models.append(('SGD', SGDRegressor(random_state=42, alpha=1e-6, fit_intercept=True, penalty=None, tol=1e-3)))\n",
    "models.append(('TSR', TheilSenRegressor(random_state=42, n_jobs=-1, fit_intercept=True)))\n",
    "\n",
    "# Decision Trees\n",
    "models.append(('DTR', DecisionTreeRegressor(random_state=42, max_depth=4, min_samples_split=0.25)))\n",
    "\n",
    "# Gaussian Processes\n",
    "models.append(('GPR', GaussianProcessRegressor(random_state=42, alpha=0.01, normalize_y=False)))\n",
    "\n",
    "# Kernel Ridge Regression\n",
    "models.append(('KRR', KernelRidge(alpha=0.1)))\n",
    "\n",
    "# Naïve Bayes\n",
    "models.append(('GNB', GaussianNB(var_smoothing=0.001)))\n",
    "\n",
    "# Nearest Neighbors\n",
    "models.append(('kNN', KNeighborsRegressor(n_jobs=-1, n_neighbors=11, weights='distance')))\n",
    "\n",
    "# Support Vector Machines\n",
    "models.append(('SVM', SVR(gamma='auto', kernel='linear')))\n",
    "\n",
    "# Neural network models\n",
    "models.append(('MLP', MLPRegressor(random_state=42, max_iter=500,\n",
    "                     activation='tanh', hidden_layer_sizes=(5, 2), solver='lbfgs')))\n",
    "\n",
    "# Ensemble Methods\n",
    "models.append(('RFR', RandomForestRegressor(random_state=42, n_jobs=-1, n_estimators=100, max_depth=9)))\n",
    "models.append(('GBR', GradientBoostingRegressor(random_state=42, learning_rate=0.05, n_estimators=100,\n",
    "                                  subsample=0.8, max_depth=6, max_features=0.75)))\n",
    "models.append(('ETR', ExtraTreesRegressor(random_state=42, n_jobs=-1, n_estimators=200, max_features=0.75)))\n",
    "models.append(('BDTR', BaggingRegressor(random_state=42, n_jobs=-1, base_estimator=DecisionTreeRegressor(),\n",
    "                                       max_features=0.75, n_estimators=75)))\n",
    "models.append(('ABDTR', AdaBoostRegressor(random_state=42, n_estimators=200, base_estimator=DecisionTreeRegressor())))\n",
    "\n",
    "# XGBoost\n",
    "models.append(('XGBR', XGBRegressor(random_state=42, n_jobs=-1, learning_rate=0.1,\n",
    "                                    n_estimators=50, max_depth=5, objective='reg:squarederror')))\n",
    "\n",
    "# Voting\n",
    "models.append(('VR', VotingRegressor(estimators=[\n",
    "    ('MLP', MLPRegressor(random_state=42, max_iter=500,\n",
    "                     activation='tanh', hidden_layer_sizes=(5, 2), solver='lbfgs')),\n",
    "    ('GPR', GaussianProcessRegressor(random_state=42, alpha=0.01, normalize_y=False)),\n",
    "    ('GBR', GradientBoostingRegressor(random_state=42, learning_rate=0.05, n_estimators=100,\n",
    "                                  subsample=0.8, max_depth=6, max_features=0.75))\n",
    "], n_jobs=-1, weights=(2,1,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True) \n",
      "Score: 2.21 (+/- 0.17) [   25 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   23.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=-1, penalty='l2', random_state=42,\n",
      "                   solver='newton-cg', tol=0.0001, verbose=0, warm_start=False) \n",
      "Score: 2.46 (+/- 0.22) [23008 ms]\n",
      "OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=7, normalize=True,\n",
      "                          precompute='auto', tol=None) \n",
      "Score: 2.21 (+/- 0.17) [   20 ms]\n",
      "PassiveAggressiveRegressor(C=0.1, average=False, early_stopping=False,\n",
      "                           epsilon=0.1, fit_intercept=True,\n",
      "                           loss='epsilon_insensitive', max_iter=1000,\n",
      "                           n_iter_no_change=5, random_state=42, shuffle=True,\n",
      "                           tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False) \n",
      "Score: 2.29 (+/- 0.25) [   36 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron(alpha=0.001, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
      "           penalty='l2', random_state=42, shuffle=True, tol=0.001,\n",
      "           validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Score: 3.07 (+/- 0.31) [  193 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANSACRegressor(base_estimator=None, is_data_valid=None, is_model_valid=None,\n",
      "                loss='absolute_loss', max_skips=inf, max_trials=100,\n",
      "                min_samples=0.75, random_state=42, residual_threshold=None,\n",
      "                stop_n_inliers=inf, stop_probability=0.99, stop_score=inf) \n",
      "Score: 2.23 (+/- 0.19) [  621 ms]\n",
      "Ridge(alpha=0.001, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=True, random_state=42, solver='auto', tol=0.001) \n",
      "Score: 2.21 (+/- 0.18) [   18 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor(alpha=1e-06, average=False, early_stopping=False, epsilon=0.1,\n",
      "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
      "             n_iter_no_change=5, penalty=None, power_t=0.25, random_state=42,\n",
      "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False) \n",
      "Score: 2.28 (+/- 0.21) [  524 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    4.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheilSenRegressor(copy_X=True, fit_intercept=True, max_iter=300,\n",
      "                  max_subpopulation=10000, n_jobs=-1, n_subsamples=None,\n",
      "                  random_state=42, tol=0.001, verbose=False) \n",
      "Score: 2.22 (+/- 0.16) [ 4667 ms]\n",
      "DecisionTreeRegressor(criterion='mse', max_depth=4, max_features=None,\n",
      "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=0.25, min_weight_fraction_leaf=0.0,\n",
      "                      presort=False, random_state=42, splitter='best') \n",
      "Score: 2.50 (+/- 0.22) [   35 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianProcessRegressor(alpha=0.01, copy_X_train=True, kernel=None,\n",
      "                         n_restarts_optimizer=0, normalize_y=False,\n",
      "                         optimizer='fmin_l_bfgs_b', random_state=42) \n",
      "Score: 2.13 (+/- 0.17) [ 2347 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KernelRidge(alpha=0.1, coef0=1, degree=3, gamma=None, kernel='linear',\n",
      "            kernel_params=None) \n",
      "Score: 2.21 (+/- 0.17) [ 1163 ms]\n",
      "GaussianNB(priors=None, var_smoothing=0.001) \n",
      "Score: 5.35 (+/- 0.47) [   38 ms]\n",
      "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=11, p=2,\n",
      "                    weights='distance') \n",
      "Score: 2.24 (+/- 0.20) [  144 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "    kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False) \n",
      "Score: 2.34 (+/- 0.23) [ 2198 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "             random_state=42, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=False, warm_start=False) \n",
      "Score: 2.10 (+/- 0.16) [ 2428 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=9,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                      oob_score=False, random_state=42, verbose=0,\n",
      "                      warm_start=False) \n",
      "Score: 2.18 (+/- 0.20) [ 4062 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.05, loss='ls', max_depth=6,\n",
      "                          max_features=0.75, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=42, subsample=0.8, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Score: 2.17 (+/- 0.19) [ 1858 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    4.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "                    max_features=0.75, max_leaf_nodes=None,\n",
      "                    min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                    min_samples_leaf=1, min_samples_split=2,\n",
      "                    min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
      "                    oob_score=False, random_state=42, verbose=0,\n",
      "                    warm_start=False) \n",
      "Score: 2.23 (+/- 0.19) [ 4571 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingRegressor(base_estimator=DecisionTreeRegressor(criterion='mse',\n",
      "                                                      max_depth=None,\n",
      "                                                      max_features=None,\n",
      "                                                      max_leaf_nodes=None,\n",
      "                                                      min_impurity_decrease=0.0,\n",
      "                                                      min_impurity_split=None,\n",
      "                                                      min_samples_leaf=1,\n",
      "                                                      min_samples_split=2,\n",
      "                                                      min_weight_fraction_leaf=0.0,\n",
      "                                                      presort=False,\n",
      "                                                      random_state=None,\n",
      "                                                      splitter='best'),\n",
      "                 bootstrap=True, bootstrap_features=False, max_features=0.75,\n",
      "                 max_samples=1.0, n_estimators=75, n_jobs=-1, oob_score=False,\n",
      "                 random_state=42, verbose=0, warm_start=False) \n",
      "Score: 2.19 (+/- 0.20) [ 1591 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   15.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/dados/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/dados/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/dados/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/dados/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/dados/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/dados/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/dados/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='mse',\n",
      "                                                       max_depth=None,\n",
      "                                                       max_features=None,\n",
      "                                                       max_leaf_nodes=None,\n",
      "                                                       min_impurity_decrease=0.0,\n",
      "                                                       min_impurity_split=None,\n",
      "                                                       min_samples_leaf=1,\n",
      "                                                       min_samples_split=2,\n",
      "                                                       min_weight_fraction_leaf=0.0,\n",
      "                                                       presort=False,\n",
      "                                                       random_state=None,\n",
      "                                                       splitter='best'),\n",
      "                  learning_rate=1.0, loss='linear', n_estimators=200,\n",
      "                  random_state=42) \n",
      "Score: 2.25 (+/- 0.20) [15714 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dados/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/dados/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/dados/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
      "             max_depth=5, min_child_weight=1, missing=None, n_estimators=50,\n",
      "             n_jobs=-1, nthread=None, objective='reg:squarederror',\n",
      "             random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "             seed=None, silent=None, subsample=1, verbosity=1) \n",
      "Score: 2.21 (+/- 0.20) [  324 ms]\n",
      "VotingRegressor(estimators=[('MLP',\n",
      "                             MLPRegressor(activation='tanh', alpha=0.0001,\n",
      "                                          batch_size='auto', beta_1=0.9,\n",
      "                                          beta_2=0.999, early_stopping=False,\n",
      "                                          epsilon=1e-08,\n",
      "                                          hidden_layer_sizes=(5, 2),\n",
      "                                          learning_rate='constant',\n",
      "                                          learning_rate_init=0.001,\n",
      "                                          max_iter=500, momentum=0.9,\n",
      "                                          n_iter_no_change=10,\n",
      "                                          nesterovs_momentum=True, power_t=0.5,\n",
      "                                          random_state=42, shuffle=True,\n",
      "                                          solver='...\n",
      "                                                       loss='ls', max_depth=6,\n",
      "                                                       max_features=0.75,\n",
      "                                                       max_leaf_nodes=None,\n",
      "                                                       min_impurity_decrease=0.0,\n",
      "                                                       min_impurity_split=None,\n",
      "                                                       min_samples_leaf=1,\n",
      "                                                       min_samples_split=2,\n",
      "                                                       min_weight_fraction_leaf=0.0,\n",
      "                                                       n_estimators=100,\n",
      "                                                       n_iter_no_change=None,\n",
      "                                                       presort='auto',\n",
      "                                                       random_state=42,\n",
      "                                                       subsample=0.8,\n",
      "                                                       tol=0.0001,\n",
      "                                                       validation_fraction=0.1,\n",
      "                                                       verbose=0,\n",
      "                                                       warm_start=False))],\n",
      "                n_jobs=-1, weights=(2, 1, 1)) \n",
      "Score: 2.09 (+/- 0.18) [ 6617 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    6.6s finished\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "scores = []\n",
    "stddevs = []\n",
    "times = []\n",
    "\n",
    "for name, model in models:\n",
    "    score, stddev, elapsed = evaluate_model_cv(model, X=X, y=y)\n",
    "    results.append((score, stddev))\n",
    "    names.append(name)\n",
    "    scores.append(score)\n",
    "    stddevs.append(stddev)\n",
    "    times.append(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# comparar desempenhos dos algoritmos\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "fig.suptitle('Comparação dos Algoritmos')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Time (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>VR</td>\n",
       "      <td>2.089943</td>\n",
       "      <td>0.176079</td>\n",
       "      <td>6617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MLP</td>\n",
       "      <td>2.097064</td>\n",
       "      <td>0.164217</td>\n",
       "      <td>2428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GPR</td>\n",
       "      <td>2.132577</td>\n",
       "      <td>0.174771</td>\n",
       "      <td>2347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GBR</td>\n",
       "      <td>2.169043</td>\n",
       "      <td>0.185749</td>\n",
       "      <td>1858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RFR</td>\n",
       "      <td>2.176777</td>\n",
       "      <td>0.195910</td>\n",
       "      <td>4062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BDTR</td>\n",
       "      <td>2.187452</td>\n",
       "      <td>0.204435</td>\n",
       "      <td>1591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OMP</td>\n",
       "      <td>2.205400</td>\n",
       "      <td>0.171963</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>2.206863</td>\n",
       "      <td>0.175725</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KRR</td>\n",
       "      <td>2.207157</td>\n",
       "      <td>0.173504</td>\n",
       "      <td>1163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>2.207549</td>\n",
       "      <td>0.171718</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBR</td>\n",
       "      <td>2.210407</td>\n",
       "      <td>0.197146</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TSR</td>\n",
       "      <td>2.222101</td>\n",
       "      <td>0.163881</td>\n",
       "      <td>4667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RANSAC</td>\n",
       "      <td>2.232146</td>\n",
       "      <td>0.188434</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ETR</td>\n",
       "      <td>2.232194</td>\n",
       "      <td>0.192364</td>\n",
       "      <td>4571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>kNN</td>\n",
       "      <td>2.239973</td>\n",
       "      <td>0.202382</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ABDTR</td>\n",
       "      <td>2.247850</td>\n",
       "      <td>0.199649</td>\n",
       "      <td>15714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SGD</td>\n",
       "      <td>2.283132</td>\n",
       "      <td>0.211120</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PAR</td>\n",
       "      <td>2.292748</td>\n",
       "      <td>0.254799</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVM</td>\n",
       "      <td>2.339422</td>\n",
       "      <td>0.228479</td>\n",
       "      <td>2198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>2.458222</td>\n",
       "      <td>0.219889</td>\n",
       "      <td>23008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DTR</td>\n",
       "      <td>2.501580</td>\n",
       "      <td>0.220212</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PP</td>\n",
       "      <td>3.066736</td>\n",
       "      <td>0.314203</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GNB</td>\n",
       "      <td>5.352474</td>\n",
       "      <td>0.468921</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model     Score   Std Dev  Time (ms)\n",
       "22      VR  2.089943  0.176079       6617\n",
       "15     MLP  2.097064  0.164217       2428\n",
       "10     GPR  2.132577  0.174771       2347\n",
       "17     GBR  2.169043  0.185749       1858\n",
       "16     RFR  2.176777  0.195910       4062\n",
       "19    BDTR  2.187452  0.204435       1591\n",
       "2      OMP  2.205400  0.171963         20\n",
       "6    Ridge  2.206863  0.175725         18\n",
       "11     KRR  2.207157  0.173504       1163\n",
       "0   LinReg  2.207549  0.171718         25\n",
       "21    XGBR  2.210407  0.197146        324\n",
       "8      TSR  2.222101  0.163881       4667\n",
       "5   RANSAC  2.232146  0.188434        621\n",
       "18     ETR  2.232194  0.192364       4571\n",
       "13     kNN  2.239973  0.202382        144\n",
       "20   ABDTR  2.247850  0.199649      15714\n",
       "7      SGD  2.283132  0.211120        524\n",
       "3      PAR  2.292748  0.254799         36\n",
       "14     SVM  2.339422  0.228479       2198\n",
       "1   LogReg  2.458222  0.219889      23008\n",
       "9      DTR  2.501580  0.220212         35\n",
       "4       PP  3.066736  0.314203        193\n",
       "12     GNB  5.352474  0.468921         38"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame({'Model': names, 'Score': scores, 'Std Dev': stddevs, 'Time (ms)': times})\n",
    "results_df.sort_values(by='Score', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
