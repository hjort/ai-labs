{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação dos pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar pacotes necessários\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir parâmetros extras\n",
    "pd.set_option('precision', 4)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prefixo_arquivos = ''\n",
    "prefixo_arquivos = 'https://github.com/hjort/ai-labs/raw/master/kaggle/serpro-titanic/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregar arquivo de dados de treino\n",
    "train_data = pd.read_csv(prefixo_arquivos + 'titanic-train.csv', index_col='person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregar arquivo de dados de teste\n",
    "test_data = pd.read_csv(prefixo_arquivos + 'titanic-test.csv', index_col='person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>fare</th>\n",
       "      <th>home_destination</th>\n",
       "      <th>name</th>\n",
       "      <th>parch</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>survived</th>\n",
       "      <th>ticket</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>26.000</td>\n",
       "      <td>Liverpool / Montreal, PQ</td>\n",
       "      <td>Gaskell, Mr. Alfred</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>239865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>30.0</td>\n",
       "      <td>C106</td>\n",
       "      <td>S</td>\n",
       "      <td>26.000</td>\n",
       "      <td>Brockton, MA</td>\n",
       "      <td>Maguire, Mr. John Edward</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>110469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abbing, Mr. Anthony</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>C.A. 5547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>13.775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peacock, Miss. Treasteall</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>SOTON/O.Q. 3101315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ilmakangas, Miss. Pieta Sofia</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>STON/O2. 3101271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age cabin embarked    fare          home_destination  \\\n",
       "person                                                          \n",
       "416     16.0   NaN        S  26.000  Liverpool / Montreal, PQ   \n",
       "194     30.0  C106        S  26.000              Brockton, MA   \n",
       "600     42.0   NaN        S   7.550                       NaN   \n",
       "1112     3.0   NaN        S  13.775                       NaN   \n",
       "878     25.0   NaN        S   7.925                       NaN   \n",
       "\n",
       "                                 name  parch  pclass     sex  sibsp survived  \\\n",
       "person                                                                         \n",
       "416               Gaskell, Mr. Alfred      0       2    male      0       no   \n",
       "194          Maguire, Mr. John Edward      0       1    male      0       no   \n",
       "600               Abbing, Mr. Anthony      0       3    male      0       no   \n",
       "1112        Peacock, Miss. Treasteall      1       3  female      1       no   \n",
       "878     Ilmakangas, Miss. Pieta Sofia      0       3  female      1       no   \n",
       "\n",
       "                    ticket  \n",
       "person                      \n",
       "416                 239865  \n",
       "194                 110469  \n",
       "600              C.A. 5547  \n",
       "1112    SOTON/O.Q. 3101315  \n",
       "878       STON/O2. 3101271  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unir ambos os dados de treino e teste\n",
    "data = pd.concat([train_data, test_data])\n",
    "\n",
    "# mostrar alguns exemplos de registros\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformações nos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformar colunas textuais em categóricas\n",
    "data['survived'] = data['survived'].map({'yes': 1, 'no': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>title</th>\n",
       "      <th>Capt</th>\n",
       "      <th>Col</th>\n",
       "      <th>Countess</th>\n",
       "      <th>Don</th>\n",
       "      <th>Dona</th>\n",
       "      <th>Dr</th>\n",
       "      <th>Jonkheer</th>\n",
       "      <th>Lady</th>\n",
       "      <th>Major</th>\n",
       "      <th>Master</th>\n",
       "      <th>Miss</th>\n",
       "      <th>Mlle</th>\n",
       "      <th>Mme</th>\n",
       "      <th>Mr</th>\n",
       "      <th>Mrs</th>\n",
       "      <th>Ms</th>\n",
       "      <th>Rev</th>\n",
       "      <th>Sir</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>757</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "title   Capt  Col  Countess  Don  Dona  Dr  Jonkheer  Lady  Major  Master  \\\n",
       "sex                                                                         \n",
       "female     0    0         1    0     1   1         0     1      0       0   \n",
       "male       1    4         0    1     0   7         1     0      2      61   \n",
       "\n",
       "title   Miss  Mlle  Mme   Mr  Mrs  Ms  Rev  Sir  \n",
       "sex                                              \n",
       "female   260     2    1    0  197   2    0    0  \n",
       "male       0     0    0  757    0   0    8    1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extrair títulos das pessoas a partir do nome\n",
    "data['title'] = data['name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "# exibir relação entre título e sexo\n",
    "pd.crosstab(data['title'], data['sex']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>title</th>\n",
       "      <th>Master</th>\n",
       "      <th>Miss</th>\n",
       "      <th>Mr</th>\n",
       "      <th>Mrs</th>\n",
       "      <th>Rare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>757</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "title   Master  Miss   Mr  Mrs  Rare\n",
       "sex                                 \n",
       "female       0   264    0  198     4\n",
       "male        61     0  757    0    25"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agregar títulos incomuns\n",
    "replacements = {\n",
    "    'Miss': ['Mlle', 'Ms'],\n",
    "    'Mrs': ['Mme'],\n",
    "    'Rare': ['Lady', 'Countess', 'Capt', 'Col', 'Don', \\\n",
    "             'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona']\n",
    "}\n",
    "for k, v in replacements.items():\n",
    "    data['title'] = data['title'].replace(v, k)\n",
    "    \n",
    "# exibir relação entre título e sexo\n",
    "pd.crosstab(data['title'], data['sex']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorizar os valores dos títulos\n",
    "title_mapping = {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Rare': 5}\n",
    "data['title'] = data['title'].map(title_mapping)\n",
    "data['title'] = data['title'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorizar os valores dos sexos\n",
    "data['sex'] = data['sex'].map({'female': 1, 'male': 0}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preencher e categorizar os valores dos portos de embarque\n",
    "data['embarked'].fillna(data.embarked.mode()[0], inplace=True)\n",
    "data['embarked'] = data['embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preencher os valores da passagem\n",
    "data['fare'].fillna(data.fare.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar coluna com tamanho da família\n",
    "data['fsize'] = data['parch'] + data['sibsp'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar coluna indicando se estava sozinho\n",
    "data['alone'] = 0\n",
    "data.loc[data.fsize == 1, 'alone'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar coluna contendo o deque\n",
    "data['deck'] = data['cabin'].str[:1]\n",
    "data['deck'] = data['deck'].fillna('N').astype('category')\n",
    "data['deck'] = data['deck'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar coluna contendo o número do quarto\n",
    "data['room'] = data['cabin'].str.extract(\"([0-9]+)\", expand=False)\n",
    "data['room'] = data['room'].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>fare</th>\n",
       "      <th>home_destination</th>\n",
       "      <th>name</th>\n",
       "      <th>parch</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>survived</th>\n",
       "      <th>ticket</th>\n",
       "      <th>title</th>\n",
       "      <th>fsize</th>\n",
       "      <th>alone</th>\n",
       "      <th>deck</th>\n",
       "      <th>room</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000</td>\n",
       "      <td>Liverpool / Montreal, PQ</td>\n",
       "      <td>Gaskell, Mr. Alfred</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239865</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>30.0</td>\n",
       "      <td>C106</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000</td>\n",
       "      <td>Brockton, MA</td>\n",
       "      <td>Maguire, Mr. John Edward</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110469</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7.550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abbing, Mr. Anthony</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C.A. 5547</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13.775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peacock, Miss. Treasteall</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SOTON/O.Q. 3101315</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7.925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ilmakangas, Miss. Pieta Sofia</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>STON/O2. 3101271</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age cabin  embarked    fare          home_destination  \\\n",
       "person                                                           \n",
       "416     16.0   NaN         0  26.000  Liverpool / Montreal, PQ   \n",
       "194     30.0  C106         0  26.000              Brockton, MA   \n",
       "600     42.0   NaN         0   7.550                       NaN   \n",
       "1112     3.0   NaN         0  13.775                       NaN   \n",
       "878     25.0   NaN         0   7.925                       NaN   \n",
       "\n",
       "                                 name  parch  pclass  sex  sibsp  survived  \\\n",
       "person                                                                       \n",
       "416               Gaskell, Mr. Alfred      0       2    0      0       0.0   \n",
       "194          Maguire, Mr. John Edward      0       1    0      0       0.0   \n",
       "600               Abbing, Mr. Anthony      0       3    0      0       0.0   \n",
       "1112        Peacock, Miss. Treasteall      1       3    1      1       0.0   \n",
       "878     Ilmakangas, Miss. Pieta Sofia      0       3    1      1       0.0   \n",
       "\n",
       "                    ticket  title  fsize  alone  deck  room  \n",
       "person                                                       \n",
       "416                 239865      1      1      1     7     0  \n",
       "194                 110469      1      1      1     2   106  \n",
       "600              C.A. 5547      1      1      1     7     0  \n",
       "1112    SOTON/O.Q. 3101315      2      3      0     7     0  \n",
       "878       STON/O2. 3101271      2      2      0     7     0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferir idades faltantes dos passageiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def evaluate_regression_model(model, X, y):\n",
    "    kfold = KFold(n_splits=10, random_state=42)\n",
    "    results = cross_val_score(model, X, y, cv=kfold, scoring='neg_mean_squared_error', verbose=1)\n",
    "    score = (-1) * results.mean()\n",
    "    stddev = results.std()\n",
    "    print(model, '\\nScore: %.2f (+/- %.2f)' % (score, stddev))\n",
    "    return score, stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "age_models = [\n",
    "#    ('LR', LinearRegression(n_jobs=-1, fit_intercept=True, normalize=True)),\n",
    "    ('GBR', GradientBoostingRegressor(random_state=42)),\n",
    "    ('RFR', RandomForestRegressor(random_state=42)),\n",
    "    ('XGB', XGBRegressor(random_state=42, objective='reg:squarederror')),\n",
    "#    ('MLP', MLPRegressor(random_state=42, max_iter=500, activation='tanh',\n",
    "#                         hidden_layer_sizes=(10,5,5), solver='lbfgs')),\n",
    "#    ('GPR', GaussianProcessRegressor(random_state=42, alpha=0.01, normalize_y=True))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>title</th>\n",
       "      <th>age</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.550</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.775</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.925</td>\n",
       "      <td>2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pclass  sibsp  parch    fare  title   age  alone\n",
       "person                                                  \n",
       "416          2      0      0  26.000      1  16.0      1\n",
       "194          1      0      0  26.000      1  30.0      1\n",
       "600          3      0      0   7.550      1  42.0      1\n",
       "1112         3      1      1  13.775      2   3.0      0\n",
       "878          3      1      0   7.925      2  25.0      0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecionar dados para o treino\n",
    "\n",
    "cols = ['pclass', 'sibsp', 'parch', 'fare', 'title', 'age', 'alone']\n",
    "#cols = ['pclass', 'sibsp', 'parch', 'fare', 'sex', 'embarked', 'title', 'age', 'alone']\n",
    "\n",
    "data_age = data[cols].dropna()\n",
    "\n",
    "X_age = data_age.drop(['age'], axis=1)\n",
    "y_age = data_age['age']\n",
    "\n",
    "data_age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>title</th>\n",
       "      <th>age</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pclass</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>-0.5651</td>\n",
       "      <td>-0.1541</td>\n",
       "      <td>-0.4081</td>\n",
       "      <td>0.1595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sibsp</th>\n",
       "      <td>0.0472</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3745</td>\n",
       "      <td>0.1412</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>-0.2437</td>\n",
       "      <td>-0.6274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parch</th>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.3745</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>0.3151</td>\n",
       "      <td>-0.1509</td>\n",
       "      <td>-0.5701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare</th>\n",
       "      <td>-0.5651</td>\n",
       "      <td>0.1412</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1484</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>-0.2598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>-0.1541</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>0.3151</td>\n",
       "      <td>0.1484</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.0926</td>\n",
       "      <td>-0.3973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-0.4081</td>\n",
       "      <td>-0.2437</td>\n",
       "      <td>-0.1509</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>-0.0926</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alone</th>\n",
       "      <td>0.1595</td>\n",
       "      <td>-0.6274</td>\n",
       "      <td>-0.5701</td>\n",
       "      <td>-0.2598</td>\n",
       "      <td>-0.3973</td>\n",
       "      <td>0.1288</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pclass   sibsp   parch    fare   title     age   alone\n",
       "pclass  1.0000  0.0472  0.0172 -0.5651 -0.1541 -0.4081  0.1595\n",
       "sibsp   0.0472  1.0000  0.3745  0.1412  0.3080 -0.2437 -0.6274\n",
       "parch   0.0172  0.3745  1.0000  0.2167  0.3151 -0.1509 -0.5701\n",
       "fare   -0.5651  0.1412  0.2167  1.0000  0.1484  0.1782 -0.2598\n",
       "title  -0.1541  0.3080  0.3151  0.1484  1.0000 -0.0926 -0.3973\n",
       "age    -0.4081 -0.2437 -0.1509  0.1782 -0.0926  1.0000  0.1288\n",
       "alone   0.1595 -0.6274 -0.5701 -0.2598 -0.3973  0.1288  1.0000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_age.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=42, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Score: 112.44 (+/- 12.38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
      "                      n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                      warm_start=False) \n",
      "Score: 133.69 (+/- 10.32)\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
      "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "             n_jobs=1, nthread=None, objective='reg:squarederror',\n",
      "             random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "             seed=None, silent=None, subsample=1, verbosity=1) \n",
      "Score: 112.10 (+/- 12.57)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    3.1s finished\n"
     ]
    }
   ],
   "source": [
    "names = []\n",
    "scores = []\n",
    "lowest = 999\n",
    "best_model = None\n",
    "\n",
    "for name, model in age_models:\n",
    "    \n",
    "    score, stddev = evaluate_regression_model(model, X_age, y_age)\n",
    "    names.append(name)\n",
    "    scores.append(score)\n",
    "    \n",
    "    if score < lowest:\n",
    "        best_model = model\n",
    "        lowest = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGB</td>\n",
       "      <td>112.0968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GBR</td>\n",
       "      <td>112.4377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RFR</td>\n",
       "      <td>133.6927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Age Model     Score\n",
       "2       XGB  112.0968\n",
       "0       GBR  112.4377\n",
       "1       RFR  133.6927"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'Age Model': names, 'Score': scores})\n",
    "results.sort_values(by='Score', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "             n_jobs=1, nthread=None, objective='reg:squarederror',\n",
       "             random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "             seed=None, silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_model = best_model\n",
    "age_model.fit(X_age, y_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>fare</th>\n",
       "      <th>home_destination</th>\n",
       "      <th>name</th>\n",
       "      <th>parch</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>survived</th>\n",
       "      <th>ticket</th>\n",
       "      <th>title</th>\n",
       "      <th>fsize</th>\n",
       "      <th>alone</th>\n",
       "      <th>deck</th>\n",
       "      <th>room</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000</td>\n",
       "      <td>Liverpool / Montreal, PQ</td>\n",
       "      <td>Gaskell, Mr. Alfred</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239865</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>30.0</td>\n",
       "      <td>C106</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000</td>\n",
       "      <td>Brockton, MA</td>\n",
       "      <td>Maguire, Mr. John Edward</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110469</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7.550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abbing, Mr. Anthony</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C.A. 5547</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13.775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peacock, Miss. Treasteall</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SOTON/O.Q. 3101315</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7.925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ilmakangas, Miss. Pieta Sofia</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>STON/O2. 3101271</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age cabin  embarked    fare          home_destination  \\\n",
       "person                                                           \n",
       "416     16.0   NaN         0  26.000  Liverpool / Montreal, PQ   \n",
       "194     30.0  C106         0  26.000              Brockton, MA   \n",
       "600     42.0   NaN         0   7.550                       NaN   \n",
       "1112     3.0   NaN         0  13.775                       NaN   \n",
       "878     25.0   NaN         0   7.925                       NaN   \n",
       "\n",
       "                                 name  parch  pclass  sex  sibsp  survived  \\\n",
       "person                                                                       \n",
       "416               Gaskell, Mr. Alfred      0       2    0      0       0.0   \n",
       "194          Maguire, Mr. John Edward      0       1    0      0       0.0   \n",
       "600               Abbing, Mr. Anthony      0       3    0      0       0.0   \n",
       "1112        Peacock, Miss. Treasteall      1       3    1      1       0.0   \n",
       "878     Ilmakangas, Miss. Pieta Sofia      0       3    1      1       0.0   \n",
       "\n",
       "                    ticket  title  fsize  alone  deck  room  \n",
       "person                                                       \n",
       "416                 239865      1      1      1     7     0  \n",
       "194                 110469      1      1      1     2   106  \n",
       "600              C.A. 5547      1      1      1     7     0  \n",
       "1112    SOTON/O.Q. 3101315      2      3      0     7     0  \n",
       "878       STON/O2. 3101271      2      2      0     7     0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preencher dados faltantes de idade a partir de uma regressão\n",
    "data['age_pred'] = age_model.predict(data[cols].drop('age', axis=1))\n",
    "data.loc[data.age.isnull(), 'age'] = data['age_pred']\n",
    "data.drop('age_pred', axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cabin               1014\n",
       "home_destination     564\n",
       "survived             437\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# existem colunas com dados nulos?\n",
    "data[data.columns[data.isnull().any()]].isnull().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# criar colunas adicionais\n",
    "data['ageclass'] = data['age'] * data['pclass']\n",
    "data['pfare'] = data['fare'] / data['fsize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>fare</th>\n",
       "      <th>home_destination</th>\n",
       "      <th>name</th>\n",
       "      <th>parch</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>survived</th>\n",
       "      <th>ticket</th>\n",
       "      <th>title</th>\n",
       "      <th>fsize</th>\n",
       "      <th>alone</th>\n",
       "      <th>deck</th>\n",
       "      <th>room</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000</td>\n",
       "      <td>Liverpool / Montreal, PQ</td>\n",
       "      <td>Gaskell, Mr. Alfred</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239865</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>30.0</td>\n",
       "      <td>C106</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000</td>\n",
       "      <td>Brockton, MA</td>\n",
       "      <td>Maguire, Mr. John Edward</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110469</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7.550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abbing, Mr. Anthony</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C.A. 5547</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13.775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peacock, Miss. Treasteall</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SOTON/O.Q. 3101315</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7.925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ilmakangas, Miss. Pieta Sofia</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>STON/O2. 3101271</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age cabin  embarked    fare          home_destination  \\\n",
       "person                                                           \n",
       "416     16.0   NaN         0  26.000  Liverpool / Montreal, PQ   \n",
       "194     30.0  C106         0  26.000              Brockton, MA   \n",
       "600     42.0   NaN         0   7.550                       NaN   \n",
       "1112     3.0   NaN         0  13.775                       NaN   \n",
       "878     25.0   NaN         0   7.925                       NaN   \n",
       "\n",
       "                                 name  parch  pclass  sex  sibsp  survived  \\\n",
       "person                                                                       \n",
       "416               Gaskell, Mr. Alfred      0       2    0      0       0.0   \n",
       "194          Maguire, Mr. John Edward      0       1    0      0       0.0   \n",
       "600               Abbing, Mr. Anthony      0       3    0      0       0.0   \n",
       "1112        Peacock, Miss. Treasteall      1       3    1      1       0.0   \n",
       "878     Ilmakangas, Miss. Pieta Sofia      0       3    1      1       0.0   \n",
       "\n",
       "                    ticket  title  fsize  alone  deck  room  \n",
       "person                                                       \n",
       "416                 239865      1      1      1     7     0  \n",
       "194                 110469      1      1      1     2   106  \n",
       "600              C.A. 5547      1      1      1     7     0  \n",
       "1112    SOTON/O.Q. 3101315      2      3      0     7     0  \n",
       "878       STON/O2. 3101271      2      2      0     7     0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# gerar \"one hot encoding\" em atributos categóricos\n",
    "#cols = ['pclass', 'sex', 'embarked']\n",
    "cols = ['embarked', 'pclass', 'title', 'deck']\n",
    "data = pd.get_dummies(data, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realizar normalização nos dados numéricos contínuos\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#cols = ['age', 'fare']\n",
    "cols = ['age', 'fare', 'parch', 'pclass', 'sibsp', 'fsize']\n",
    "#cols = ['age', 'embarked', 'fare', 'parch', 'pclass', 'sex', 'sibsp', 'title', 'fsize', 'deck']\n",
    "#cols = ['age', 'embarked', 'fare', 'parch', 'pclass', 'sex', 'sibsp', 'title', 'fsize', 'deck', 'room']\n",
    "\n",
    "#for col in cols:\n",
    "data.loc[:,cols] = scaler.fit_transform(data.loc[:,cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>fare</th>\n",
       "      <th>home_destination</th>\n",
       "      <th>name</th>\n",
       "      <th>parch</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>survived</th>\n",
       "      <th>ticket</th>\n",
       "      <th>title</th>\n",
       "      <th>fsize</th>\n",
       "      <th>alone</th>\n",
       "      <th>deck</th>\n",
       "      <th>room</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0.1983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0507</td>\n",
       "      <td>Liverpool / Montreal, PQ</td>\n",
       "      <td>Gaskell, Mr. Alfred</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239865</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.3737</td>\n",
       "      <td>C106</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0507</td>\n",
       "      <td>Brockton, MA</td>\n",
       "      <td>Maguire, Mr. John Edward</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110469</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.5240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abbing, Mr. Anthony</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C.A. 5547</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>0.0355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peacock, Miss. Treasteall</td>\n",
       "      <td>0.1111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SOTON/O.Q. 3101315</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0.3110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ilmakangas, Miss. Pieta Sofia</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>STON/O2. 3101271</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age cabin  embarked    fare          home_destination  \\\n",
       "person                                                             \n",
       "416     0.1983   NaN         0  0.0507  Liverpool / Montreal, PQ   \n",
       "194     0.3737  C106         0  0.0507              Brockton, MA   \n",
       "600     0.5240   NaN         0  0.0147                       NaN   \n",
       "1112    0.0355   NaN         0  0.0269                       NaN   \n",
       "878     0.3110   NaN         0  0.0155                       NaN   \n",
       "\n",
       "                                 name   parch  pclass  sex  sibsp  survived  \\\n",
       "person                                                                        \n",
       "416               Gaskell, Mr. Alfred  0.0000     0.5    0  0.000       0.0   \n",
       "194          Maguire, Mr. John Edward  0.0000     0.0    0  0.000       0.0   \n",
       "600               Abbing, Mr. Anthony  0.0000     1.0    0  0.000       0.0   \n",
       "1112        Peacock, Miss. Treasteall  0.1111     1.0    1  0.125       0.0   \n",
       "878     Ilmakangas, Miss. Pieta Sofia  0.0000     1.0    1  0.125       0.0   \n",
       "\n",
       "                    ticket  title  fsize  alone  deck  room  \n",
       "person                                                       \n",
       "416                 239865      1    0.0      1     7     0  \n",
       "194                 110469      1    0.0      1     2   106  \n",
       "600              C.A. 5547      1    0.0      1     7     0  \n",
       "1112    SOTON/O.Q. 3101315      2    0.2      0     7     0  \n",
       "878       STON/O2. 3101271      2    0.1      0     7     0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem preditiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar os pacotes necessários para os algoritmos de classificação\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# avalia o desempenho do modelo, retornando o valor da precisão\n",
    "def evaluate_classification_model(model, X, y):\n",
    "    start = datetime.now()\n",
    "    kfold = KFold(n_splits=10, random_state=42)\n",
    "    results = cross_val_score(model, X, y, cv=kfold, scoring='accuracy', verbose=1)\n",
    "    end = datetime.now()\n",
    "    elapsed = int((end - start).total_seconds() * 1000)\n",
    "    score = 100.0 * results.mean()\n",
    "    stddev = 100.0 * results.std()\n",
    "    print(model, '\\nScore: %.2f (+/- %.2f) [%5s ms]' % (score, stddev, elapsed))\n",
    "    return score, stddev, elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# faz o ajuste fino do modelo, calculando os melhores hiperparâmetros\n",
    "def fine_tune_model(model, params, X, y):\n",
    "    print('\\nFine Tuning Model:')\n",
    "    print(model, \"\\nparams:\", params)\n",
    "    kfold = KFold(n_splits=10, random_state=42)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=params, scoring='accuracy', cv=kfold, verbose=1)\n",
    "    grid.fit(X, y)\n",
    "    print('\\nGrid Best Score: %.2f' % (grid.best_score_ * 100.0))\n",
    "    print('Best Params:', grid.best_params_)\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma dos dados de treino: (872, 11) (872,)\n"
     ]
    }
   ],
   "source": [
    "# definir dados de treino\n",
    "train_data = data[data.survived.isnull() == False]\n",
    "\n",
    "# selecionar atributos para o modelo\n",
    "cols = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'title', 'fsize', 'alone', 'deck']\n",
    "#cols = ['pclass', 'sex', 'age', 'fare', 'title', 'fsize', 'deck']\n",
    "#cols = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'title', 'fsize', 'alone', 'deck', 'room']\n",
    "\n",
    "X_train = train_data[cols]\n",
    "y_train = train_data['survived']\n",
    "\n",
    "print('Forma dos dados de treino:', X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>embarked</th>\n",
       "      <th>fare</th>\n",
       "      <th>parch</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>survived</th>\n",
       "      <th>title</th>\n",
       "      <th>fsize</th>\n",
       "      <th>alone</th>\n",
       "      <th>deck</th>\n",
       "      <th>room</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.1816</td>\n",
       "      <td>-0.1558</td>\n",
       "      <td>-0.4520</td>\n",
       "      <td>-0.0954</td>\n",
       "      <td>-0.2562</td>\n",
       "      <td>-0.0458</td>\n",
       "      <td>-0.1153</td>\n",
       "      <td>-0.2529</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>-0.3259</td>\n",
       "      <td>0.2699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarked</th>\n",
       "      <td>0.0303</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0296</td>\n",
       "      <td>-0.0931</td>\n",
       "      <td>0.0589</td>\n",
       "      <td>0.1035</td>\n",
       "      <td>-0.0592</td>\n",
       "      <td>0.0866</td>\n",
       "      <td>0.0340</td>\n",
       "      <td>-0.0894</td>\n",
       "      <td>0.0340</td>\n",
       "      <td>-0.0174</td>\n",
       "      <td>0.0256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare</th>\n",
       "      <td>0.1816</td>\n",
       "      <td>0.0296</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2559</td>\n",
       "      <td>-0.5721</td>\n",
       "      <td>0.1734</td>\n",
       "      <td>0.1865</td>\n",
       "      <td>0.2405</td>\n",
       "      <td>0.1421</td>\n",
       "      <td>0.2613</td>\n",
       "      <td>-0.3066</td>\n",
       "      <td>-0.5651</td>\n",
       "      <td>0.4329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parch</th>\n",
       "      <td>-0.1558</td>\n",
       "      <td>-0.0931</td>\n",
       "      <td>0.2559</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.2209</td>\n",
       "      <td>0.3849</td>\n",
       "      <td>0.0784</td>\n",
       "      <td>0.3085</td>\n",
       "      <td>0.7948</td>\n",
       "      <td>-0.5510</td>\n",
       "      <td>-0.0410</td>\n",
       "      <td>0.0116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pclass</th>\n",
       "      <td>-0.4520</td>\n",
       "      <td>0.0589</td>\n",
       "      <td>-0.5721</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.0897</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>-0.2944</td>\n",
       "      <td>-0.1122</td>\n",
       "      <td>0.0541</td>\n",
       "      <td>0.1265</td>\n",
       "      <td>0.7276</td>\n",
       "      <td>-0.5538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-0.0954</td>\n",
       "      <td>0.1035</td>\n",
       "      <td>0.1734</td>\n",
       "      <td>0.2209</td>\n",
       "      <td>-0.0897</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>0.5134</td>\n",
       "      <td>0.5218</td>\n",
       "      <td>0.1864</td>\n",
       "      <td>-0.2741</td>\n",
       "      <td>-0.1025</td>\n",
       "      <td>0.0836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sibsp</th>\n",
       "      <td>-0.2562</td>\n",
       "      <td>-0.0592</td>\n",
       "      <td>0.1865</td>\n",
       "      <td>0.3849</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.0259</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>0.8660</td>\n",
       "      <td>-0.5906</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>-0.0092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>-0.0458</td>\n",
       "      <td>0.0866</td>\n",
       "      <td>0.2405</td>\n",
       "      <td>0.0784</td>\n",
       "      <td>-0.2944</td>\n",
       "      <td>0.5134</td>\n",
       "      <td>-0.0259</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3704</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>-0.1957</td>\n",
       "      <td>-0.2818</td>\n",
       "      <td>0.2411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>-0.1153</td>\n",
       "      <td>0.0340</td>\n",
       "      <td>0.1421</td>\n",
       "      <td>0.3085</td>\n",
       "      <td>-0.1122</td>\n",
       "      <td>0.5218</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>0.3704</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.3352</td>\n",
       "      <td>-0.3768</td>\n",
       "      <td>-0.1024</td>\n",
       "      <td>0.0745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fsize</th>\n",
       "      <td>-0.2529</td>\n",
       "      <td>-0.0894</td>\n",
       "      <td>0.2613</td>\n",
       "      <td>0.7948</td>\n",
       "      <td>0.0541</td>\n",
       "      <td>0.1864</td>\n",
       "      <td>0.8660</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.3352</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.6868</td>\n",
       "      <td>-0.0140</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alone</th>\n",
       "      <td>0.1581</td>\n",
       "      <td>0.0340</td>\n",
       "      <td>-0.3066</td>\n",
       "      <td>-0.5510</td>\n",
       "      <td>0.1265</td>\n",
       "      <td>-0.2741</td>\n",
       "      <td>-0.5906</td>\n",
       "      <td>-0.1957</td>\n",
       "      <td>-0.3768</td>\n",
       "      <td>-0.6868</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1608</td>\n",
       "      <td>-0.1427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deck</th>\n",
       "      <td>-0.3259</td>\n",
       "      <td>-0.0174</td>\n",
       "      <td>-0.5651</td>\n",
       "      <td>-0.0410</td>\n",
       "      <td>0.7276</td>\n",
       "      <td>-0.1025</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>-0.2818</td>\n",
       "      <td>-0.1024</td>\n",
       "      <td>-0.0140</td>\n",
       "      <td>0.1608</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.7522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room</th>\n",
       "      <td>0.2699</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>0.4329</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>-0.5538</td>\n",
       "      <td>0.0836</td>\n",
       "      <td>-0.0092</td>\n",
       "      <td>0.2411</td>\n",
       "      <td>0.0745</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>-0.1427</td>\n",
       "      <td>-0.7522</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             age  embarked    fare   parch  pclass     sex   sibsp  survived  \\\n",
       "age       1.0000    0.0303  0.1816 -0.1558 -0.4520 -0.0954 -0.2562   -0.0458   \n",
       "embarked  0.0303    1.0000  0.0296 -0.0931  0.0589  0.1035 -0.0592    0.0866   \n",
       "fare      0.1816    0.0296  1.0000  0.2559 -0.5721  0.1734  0.1865    0.2405   \n",
       "parch    -0.1558   -0.0931  0.2559  1.0000  0.0156  0.2209  0.3849    0.0784   \n",
       "pclass   -0.4520    0.0589 -0.5721  0.0156  1.0000 -0.0897  0.0695   -0.2944   \n",
       "sex      -0.0954    0.1035  0.1734  0.2209 -0.0897  1.0000  0.1015    0.5134   \n",
       "sibsp    -0.2562   -0.0592  0.1865  0.3849  0.0695  0.1015  1.0000   -0.0259   \n",
       "survived -0.0458    0.0866  0.2405  0.0784 -0.2944  0.5134 -0.0259    1.0000   \n",
       "title    -0.1153    0.0340  0.1421  0.3085 -0.1122  0.5218  0.2556    0.3704   \n",
       "fsize    -0.2529   -0.0894  0.2613  0.7948  0.0541  0.1864  0.8660    0.0254   \n",
       "alone     0.1581    0.0340 -0.3066 -0.5510  0.1265 -0.2741 -0.5906   -0.1957   \n",
       "deck     -0.3259   -0.0174 -0.5651 -0.0410  0.7276 -0.1025  0.0124   -0.2818   \n",
       "room      0.2699    0.0256  0.4329  0.0116 -0.5538  0.0836 -0.0092    0.2411   \n",
       "\n",
       "           title   fsize   alone    deck    room  \n",
       "age      -0.1153 -0.2529  0.1581 -0.3259  0.2699  \n",
       "embarked  0.0340 -0.0894  0.0340 -0.0174  0.0256  \n",
       "fare      0.1421  0.2613 -0.3066 -0.5651  0.4329  \n",
       "parch     0.3085  0.7948 -0.5510 -0.0410  0.0116  \n",
       "pclass   -0.1122  0.0541  0.1265  0.7276 -0.5538  \n",
       "sex       0.5218  0.1864 -0.2741 -0.1025  0.0836  \n",
       "sibsp     0.2556  0.8660 -0.5906  0.0124 -0.0092  \n",
       "survived  0.3704  0.0254 -0.1957 -0.2818  0.2411  \n",
       "title     1.0000  0.3352 -0.3768 -0.1024  0.0745  \n",
       "fsize     0.3352  1.0000 -0.6868 -0.0140  0.0002  \n",
       "alone    -0.3768 -0.6868  1.0000  0.1608 -0.1427  \n",
       "deck     -0.1024 -0.0140  0.1608  1.0000 -0.7522  \n",
       "room      0.0745  0.0002 -0.1427 -0.7522  1.0000  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma dos dados de teste: (437, 11)\n"
     ]
    }
   ],
   "source": [
    "# definir dados de teste\n",
    "test_data = data[data.survived.isnull()]\n",
    "\n",
    "X_test = test_data[cols]\n",
    "\n",
    "print('Forma dos dados de teste:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "models = []\n",
    "scores = []\n",
    "stddevs = []\n",
    "times = []\n",
    "\n",
    "def add_model_info(name, model, score, stddev, elapsed):\n",
    "    names.append(name)\n",
    "    models.append((name, model))\n",
    "    scores.append(score)\n",
    "    stddevs.append(stddev)\n",
    "    times.append(elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação e ajuste fino de cada modelo preditivo\n",
    "\n",
    "-  https://scikit-learn.org/stable/modules/classes.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalized Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) \n",
      "Score: 78.45 (+/- 4.95) [ 1229 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.2s finished\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=42, solver='newton-cg', C=0.1, multi_class='auto', max_iter=500)\n",
    "\n",
    "params = dict(\n",
    "    solver=['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    C=np.logspace(-3, 3, 7)\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('LR', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=0.25,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=42, splitter='best') \n",
      "Score: 78.44 (+/- 2.62) [  415 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=42, criterion='entropy', max_depth=6, min_samples_split=0.25)\n",
    "\n",
    "#criterion=’mse’, splitter=’best’, max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, \n",
    "#min_impurity_decrease=0.0, min_impurity_split=None, presort=False\n",
    "\n",
    "params = dict(\n",
    "    criterion=['gini','entropy'],\n",
    "    max_depth=[4, 6, 8, 10, 12, 14],\n",
    "    min_samples_split=[0.25, 0.5, 0.75, 1.0]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('DT', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
      "                           solver='lsqr', store_covariance=False, tol=0.0001) \n",
      "Score: 78.79 (+/- 4.79) [  911 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "model = LinearDiscriminantAnalysis(solver='lsqr')\n",
    "\n",
    "#solver=’svd’, shrinkage=None, priors=None,\n",
    "#n_components=None, store_covariance=False, tol=0.0001\n",
    "\n",
    "params = dict(\n",
    "    solver=['svd', 'lsqr'] #, 'eigen']\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('LDA', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=1e-08) \n",
      "Score: 76.16 (+/- 6.36) [  409 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB(priors=None, var_smoothing=1e-8)\n",
    "\n",
    "#priors=None, var_smoothing=1e-09\n",
    "\n",
    "params = dict(\n",
    "    priors=[None],\n",
    "    var_smoothing=[1e-8, 1e-7, 1e-6, 1e-5, 1e-4]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('NB', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=11, p=2,\n",
      "                     weights='uniform') \n",
      "Score: 79.25 (+/- 3.53) [  564 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=11, weights='uniform')\n",
    "\n",
    "#n_neighbors=5, weights=’uniform’, algorithm=’auto’, leaf_size=30, p=2, metric=’minkowski’,\n",
    "#metric_params=None, n_jobs=None\n",
    "\n",
    "params = dict(\n",
    "    n_neighbors=[1, 3, 5, 7, 9, 11, 13],\n",
    "    weights=['uniform', 'distance']\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('KNN', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
      "    verbose=False) \n",
      "Score: 80.50 (+/- 3.56) [ 2462 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.5s finished\n"
     ]
    }
   ],
   "source": [
    "model = SVC(random_state=42, C=10, gamma=0.1, kernel='rbf')\n",
    "\n",
    "#kernel=’rbf’, degree=3, gamma=’auto_deprecated’, coef0=0.0, tol=0.001, C=1.0, \n",
    "#epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1\n",
    "\n",
    "params = dict(\n",
    "    C=[0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    gamma=[0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    kernel=['linear', 'rbf']\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('SVM', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='logistic', alpha=1, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=42, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False) \n",
      "Score: 79.82 (+/- 4.75) [68593 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(random_state=42, solver='lbfgs', alpha=1, hidden_layer_sizes=(100,), activation='logistic')\n",
    "                \n",
    "#hidden_layer_sizes=(100, ), activation=’relu’, solver=’adam’, alpha=0.0001, batch_size=’auto’, \n",
    "#learning_rate=’constant’, learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, \n",
    "#random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, \n",
    "#early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10\n",
    "\n",
    "params = dict(\n",
    "    alpha=[1,0.1,0.01,0.001,0.0001,0],\n",
    "    hidden_layer_sizes=[(100,), (50,), (50,2), (5,5,2), (10,5,2)],\n",
    "    activation=['identity', 'logistic', 'tanh', 'relu'],\n",
    "    solver=['lbfgs', 'sgd', 'adam']\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('MLP', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R',\n",
      "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
      "                                                         criterion='gini',\n",
      "                                                         max_depth=None,\n",
      "                                                         max_features=None,\n",
      "                                                         max_leaf_nodes=None,\n",
      "                                                         min_impurity_decrease=0.0,\n",
      "                                                         min_impurity_split=None,\n",
      "                                                         min_samples_leaf=1,\n",
      "                                                         min_samples_split=2,\n",
      "                                                         min_weight_fraction_leaf=0.0,\n",
      "                                                         presort=False,\n",
      "                                                         random_state=42,\n",
      "                                                         splitter='best'),\n",
      "                   learning_rate=1.0, n_estimators=50, random_state=42) \n",
      "Score: 74.20 (+/- 4.69) [11763 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   11.7s finished\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier(DecisionTreeClassifier(random_state=42), random_state=42, n_estimators=50)\n",
    "\n",
    "#base_estimator=None, n_estimators=50, learning_rate=1.0,\n",
    "#algorithm=’SAMME.R’, random_state=None\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[10, 25, 50, 100]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('ABDT', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
      "                  max_features=0.8, max_samples=0.25, n_estimators=100,\n",
      "                  n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                  warm_start=False) \n",
      "Score: 81.55 (+/- 3.51) [ 9826 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    9.8s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "model = BaggingClassifier(random_state=42, n_estimators=100,\n",
    "                          max_samples=0.25, max_features=0.8)\n",
    "\n",
    "#base_estimator=None, n_estimators=10, max_samples=1.0, max_features=1.0,\n",
    "#bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False,\n",
    "#n_jobs=None, random_state=None, verbose=0\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[10, 50, 100, 500],\n",
    "    max_samples=[0.25, 0.5, 0.75, 1.0],\n",
    "    max_features=[0.7, 0.8, 0.9, 1.0]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('BC', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                     max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=0.25,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                     n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                     warm_start=False) \n",
      "Score: 79.59 (+/- 4.52) [ 7894 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    7.9s finished\n"
     ]
    }
   ],
   "source": [
    "model = ExtraTreesClassifier(random_state=42, n_estimators=100, max_depth=7, \n",
    "                             min_samples_split=0.25, max_features='auto')\n",
    "\n",
    "#n_estimators=’warn’, criterion=’gini’, max_depth=None, min_samples_split=2,\n",
    "#min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=’auto’, \n",
    "#max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, \n",
    "#bootstrap=False, oob_score=False, n_jobs=None, random_state=None, verbose=0,\n",
    "#warm_start=False, class_weight=None\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[10, 50, 100, 500],\n",
    "    max_depth=[None, 3, 7, 11],\n",
    "    min_samples_split=[0.25, 0.5],\n",
    "    max_features=['auto', 0.7, 0.85, 1.0]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('ET', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=4,\n",
      "                           max_features=0.75, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=42, subsample=0.6, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False) \n",
      "Score: 81.08 (+/- 2.31) [10606 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   10.6s finished\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(random_state=42, n_estimators=100, max_features=0.75,\n",
    "                                   max_depth=4, learning_rate=0.1, subsample=0.6)\n",
    "\n",
    "#loss=’ls’, learning_rate=0.1, n_estimators=100, subsample=1.0, criterion=’friedman_mse’, min_samples_split=2,\n",
    "#min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, \n",
    "#min_impurity_split=None, init=None, random_state=None, max_features=None, alpha=0.9, verbose=0, \n",
    "#max_leaf_nodes=None, warm_start=False, presort=’auto’, validation_fraction=0.1, n_iter_no_change=None, \n",
    "#tol=0.0001\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[100, 250, 500],\n",
    "    max_features=[0.75, 0.85, 1.0],\n",
    "    max_depth=[4, 6, 8, 10],\n",
    "    learning_rate=[0.05, 0.1, 0.15],\n",
    "    subsample=[0.4, 0.6, 0.8]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('GB', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False) \n",
      "Score: 81.08 (+/- 4.36) [ 8792 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    8.8s finished\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42, n_estimators=100, max_features='auto', max_depth=5)\n",
    "\n",
    "#n_estimators=’warn’, criterion=’mse’, max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#min_weight_fraction_leaf=0.0, max_features=’auto’, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, \n",
    "#verbose=0, warm_start=False\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[10, 50, 100, 500],\n",
    "    max_features=['auto', 'sqrt', 'log2'],\n",
    "    max_depth=[None, 3, 5, 7, 9, 11, 13]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('RF', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outros algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost\n",
    "\n",
    "- https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1) \n",
      "Score: 79.59 (+/- 2.26) [ 4490 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    4.5s finished\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(max_depth=3, n_estimators=100)\n",
    "\n",
    "#max_depth=3, learning_rate=0.1, n_estimators=100, verbosity=1, silent=None, objective='reg:squarederror',\n",
    "#booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, \n",
    "#colsample_bytree=1, colsample_bylevel=1, colsample_bynode=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, \n",
    "#base_score=0.5, random_state=0, seed=None, missing=None, importance_type='gain'\n",
    "\n",
    "params = dict(\n",
    "    max_depth=[3, 5, 7, 9],\n",
    "    n_estimators=[50, 75, 100, 200]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('XGB', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Abaixo é criado um classificador MLP com 20 neurônios na camada intermediária e dropout de 50%. Foi utilizada a função de ativação sigmoid, a função de loss mean squared error e o otimizador RMSProp. O treinamento é realizado por 200 épocas com batch size de 64.\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=X_train.shape[1], activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mse', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hist = model.fit(X_train, y_train, batch_size=64, nb_epoch=200, verbose=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def plot_line(loss, ylabel, xlabel='Epochs'):\n",
    "    fig = plt.figure()\n",
    "    plt.plot(loss)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_line(hist.history['acc'], 'accuracy')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_line(hist.history['loss'], 'loss')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "loss, accuracy = model.evaluate(v_X, v_y)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prefixo_arquivo = 'submissions/titanic-submission'\n",
    "sufixo_arquivo = '07jul'\n",
    "name = 'mlptf'\n",
    "\n",
    "print(model, '\\n')\n",
    "\n",
    "# executar previsão usando o modelo\n",
    "y_pred = model.predict(X_test).ravel()\n",
    "vfunc = np.vectorize(lambda x: 'yes' if x > 0.5 else 'no')\n",
    "\n",
    "# gerar dados de envio (submissão)\n",
    "submission = pd.DataFrame({\n",
    "  'person': X_test.index,\n",
    "  'survived': vfunc(y_pred)\n",
    "})\n",
    "submission.set_index('person', inplace=True)\n",
    "\n",
    "# gerar arquivo CSV para o envio\n",
    "filename = '%s-p-%s-%s.csv' % (prefixo_arquivo, sufixo_arquivo, name.lower())\n",
    "submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM\n",
    "\n",
    "- https://github.com/microsoft/LightGBM\n",
    "- https://lightgbm.readthedocs.io/en/latest/\n",
    "- https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "model = LGBMClassifier(random_state=42, objective='binary', metric='binary_logloss',\n",
    "                      boosting_type='goss', n_estimators=50, max_depth=11)\n",
    "\n",
    "params = dict(\n",
    "    boosting_type=['gbdt', 'dart', 'goss'], #rf\n",
    "    objective=['binary'],\n",
    "    metric=['binary_logloss'],\n",
    "    #bagging_freq=[1, 5, 10],\n",
    "    #bagging_fraction=[0.25, 0.5],\n",
    "    n_estimators=[50, 75, 100, 200],\n",
    "    max_depth=[3, 5, 7, 9, 11]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('LGBM', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "d_train = lgb.Dataset(X_train.values, label=y_train.values)\n",
    "\n",
    "params = {}\n",
    "params['random_state'] = 42\n",
    "params['objective'] = 'binary'\n",
    "params['boosting_type'] = 'goss' # gbdt, rf, dart, goss\n",
    "\n",
    "#params['learning_rate'] = 0.003\n",
    "#params['metric'] = 'binary_logloss'\n",
    "#params['sub_feature'] = 0.5\n",
    "#params['num_leaves'] = 10\n",
    "#params['min_data'] = 50\n",
    "#params['max_depth'] = 10\n",
    "\n",
    "#model = lgb.train(params, d_train, 100)\n",
    "model = lgb.cv(params, d_train, 100, nfold=10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prefixo_arquivo = 'submissions/titanic-submission'\n",
    "sufixo_arquivo = '08jul'\n",
    "name = 'lgbm_' + params['boosting_type']\n",
    "\n",
    "print(model, '\\n')\n",
    "\n",
    "# executar previsão usando o modelo\n",
    "y_pred = clf.predict(X_test.values)\n",
    "vfunc = np.vectorize(lambda x: 'yes' if x > 0.5 else 'no')\n",
    "\n",
    "# gerar dados de envio (submissão)\n",
    "submission = pd.DataFrame({\n",
    "  'person': X_test.index,\n",
    "  'survived': vfunc(y_pred)\n",
    "})\n",
    "submission.set_index('person', inplace=True)\n",
    "\n",
    "# gerar arquivo CSV para o envio\n",
    "filename = '%s-p-%s-%s.csv' % (prefixo_arquivo, sufixo_arquivo, name.lower())\n",
    "submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Learning Model\n",
    "\n",
    "- https://towardsdatascience.com/automate-stacking-in-python-fc3e7834772e\n",
    "- https://github.com/vecxoz/vecstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier(estimators=[('RF',\n",
      "                              RandomForestClassifier(bootstrap=True,\n",
      "                                                     class_weight=None,\n",
      "                                                     criterion='gini',\n",
      "                                                     max_depth=5,\n",
      "                                                     max_features='auto',\n",
      "                                                     max_leaf_nodes=None,\n",
      "                                                     min_impurity_decrease=0.0,\n",
      "                                                     min_impurity_split=None,\n",
      "                                                     min_samples_leaf=1,\n",
      "                                                     min_samples_split=2,\n",
      "                                                     min_weight_fraction_leaf=0.0,\n",
      "                                                     n_estimators=100,\n",
      "                                                     n_jobs=None,\n",
      "                                                     oob_score=False,\n",
      "                                                     random_state=42, verbose=0,\n",
      "                                                     w...\n",
      "                                                         max_leaf_nodes=None,\n",
      "                                                         min_impurity_decrease=0.0,\n",
      "                                                         min_impurity_split=None,\n",
      "                                                         min_samples_leaf=1,\n",
      "                                                         min_samples_split=2,\n",
      "                                                         min_weight_fraction_leaf=0.0,\n",
      "                                                         n_estimators=100,\n",
      "                                                         n_iter_no_change=None,\n",
      "                                                         presort='auto',\n",
      "                                                         random_state=42,\n",
      "                                                         subsample=0.6,\n",
      "                                                         tol=0.0001,\n",
      "                                                         validation_fraction=0.1,\n",
      "                                                         verbose=0,\n",
      "                                                         warm_start=False))],\n",
      "                 flatten_transform=True, n_jobs=-1, voting='hard',\n",
      "                 weights=(2, 1, 1)) \n",
      "Score: 81.20 (+/- 3.66) [39837 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   39.8s finished\n"
     ]
    }
   ],
   "source": [
    "estimators =  [\n",
    "    ('RF', RandomForestClassifier(random_state=42, n_estimators=100, max_features='auto', max_depth=5)),\n",
    "    ('BC', BaggingClassifier(random_state=42, n_estimators=100, max_samples=0.25, max_features=0.8)),\n",
    "    ('GB', GradientBoostingClassifier(random_state=42, max_depth=4, max_features=0.75,\n",
    "                                   n_estimators=100, learning_rate=0.1, subsample=0.6)),\n",
    "#    ('XGB', XGBClassifier(max_depth=3, n_estimators=100)),\n",
    "]\n",
    "model = VotingClassifier(estimators, n_jobs=-1, weights=(2,1,1))\n",
    "\n",
    "#estimators, weights=None, n_jobs=None\n",
    "\n",
    "params = dict(\n",
    "    weights=[(1,1,1), (2,1,1), (3,1,1), (3,2,1), (2,2,1), (2,1,2), (5,4,3), (1,2,1), (1,1,2), ]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('VC', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = SGDClassifier(random_state=42, max_iter=100, tol=0.1)\n",
    "\n",
    "params = {'max_iter':[100, 200, 350, 500, 1000], 'tol':[0.1, 0.01]}\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = Perceptron(random_state=42, max_iter=100, tol=0.01)\n",
    "\n",
    "params = dict(\n",
    "    max_iter=[100, 200, 350, 500, 1000],\n",
    "    tol=[0.1, 0.01, 0.001]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = LinearSVC(random_state=42, max_iter=1000, C=10)\n",
    "\n",
    "params = dict(\n",
    "    C=[0.001, 0.01, 0.1, 1, 10, 100]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliar importância dos atributos no modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare</th>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>0.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>0.123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deck</th>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pclass</th>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fsize</th>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarked</th>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sibsp</th>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parch</th>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alone</th>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          importance\n",
       "feature             \n",
       "age            0.238\n",
       "fare           0.223\n",
       "title          0.157\n",
       "sex            0.123\n",
       "deck           0.068\n",
       "pclass         0.058\n",
       "fsize          0.047\n",
       "embarked       0.029\n",
       "sibsp          0.025\n",
       "parch          0.022\n",
       "alone          0.009"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42, max_features='auto', n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "importances = pd.DataFrame({'feature': X_train.columns,\n",
    "                            'importance': np.round(model.feature_importances_, 3)})\n",
    "importances = importances.sort_values('importance', ascending=False).set_index('feature')\n",
    "importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xa3ea136c>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação final entre os algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Score</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Time (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BC</td>\n",
       "      <td>81.5465</td>\n",
       "      <td>3.5101</td>\n",
       "      <td>11675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>VC</td>\n",
       "      <td>81.2004</td>\n",
       "      <td>3.6610</td>\n",
       "      <td>39837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RF</td>\n",
       "      <td>81.0841</td>\n",
       "      <td>4.3619</td>\n",
       "      <td>10781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GB</td>\n",
       "      <td>81.0776</td>\n",
       "      <td>2.3145</td>\n",
       "      <td>12273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>80.5042</td>\n",
       "      <td>3.5591</td>\n",
       "      <td>2689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLP</td>\n",
       "      <td>79.8250</td>\n",
       "      <td>4.7540</td>\n",
       "      <td>82824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ET</td>\n",
       "      <td>79.5938</td>\n",
       "      <td>4.5237</td>\n",
       "      <td>9092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGB</td>\n",
       "      <td>79.5899</td>\n",
       "      <td>2.2581</td>\n",
       "      <td>4490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>79.2476</td>\n",
       "      <td>3.5340</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LDA</td>\n",
       "      <td>78.7918</td>\n",
       "      <td>4.7886</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>78.4522</td>\n",
       "      <td>4.9543</td>\n",
       "      <td>1498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>78.4444</td>\n",
       "      <td>2.6234</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB</td>\n",
       "      <td>76.1586</td>\n",
       "      <td>6.3555</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ABDT</td>\n",
       "      <td>74.1967</td>\n",
       "      <td>4.6902</td>\n",
       "      <td>14378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Algorithm    Score  Std Dev  Time (ms)\n",
       "8         BC  81.5465   3.5101      11675\n",
       "13        VC  81.2004   3.6610      39837\n",
       "11        RF  81.0841   4.3619      10781\n",
       "10        GB  81.0776   2.3145      12273\n",
       "5        SVM  80.5042   3.5591       2689\n",
       "6        MLP  79.8250   4.7540      82824\n",
       "9         ET  79.5938   4.5237       9092\n",
       "12       XGB  79.5899   2.2581       4490\n",
       "4        KNN  79.2476   3.5340        582\n",
       "2        LDA  78.7918   4.7886        457\n",
       "0         LR  78.4522   4.9543       1498\n",
       "1         DT  78.4444   2.6234        468\n",
       "3         NB  76.1586   6.3555        388\n",
       "7       ABDT  74.1967   4.6902      14378"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'Algorithm': names, 'Score': scores, 'Std Dev': stddevs, 'Time (ms)': times})\n",
    "results.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerar arquivos com resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar diretório para os arquivos de envio\n",
    "!test -d submissions || mkdir submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) \n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=0.25,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=42, splitter='best') \n",
      "\n",
      "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
      "                           solver='lsqr', store_covariance=False, tol=0.0001) \n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-08) \n",
      "\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=11, p=2,\n",
      "                     weights='uniform') \n",
      "\n",
      "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
      "    verbose=False) \n",
      "\n",
      "MLPClassifier(activation='logistic', alpha=1, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=42, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False) \n",
      "\n",
      "AdaBoostClassifier(algorithm='SAMME.R',\n",
      "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
      "                                                         criterion='gini',\n",
      "                                                         max_depth=None,\n",
      "                                                         max_features=None,\n",
      "                                                         max_leaf_nodes=None,\n",
      "                                                         min_impurity_decrease=0.0,\n",
      "                                                         min_impurity_split=None,\n",
      "                                                         min_samples_leaf=1,\n",
      "                                                         min_samples_split=2,\n",
      "                                                         min_weight_fraction_leaf=0.0,\n",
      "                                                         presort=False,\n",
      "                                                         random_state=42,\n",
      "                                                         splitter='best'),\n",
      "                   learning_rate=1.0, n_estimators=50, random_state=42) \n",
      "\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
      "                  max_features=0.8, max_samples=0.25, n_estimators=100,\n",
      "                  n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                  warm_start=False) \n",
      "\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                     max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=0.25,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                     n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                     warm_start=False) \n",
      "\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=4,\n",
      "                           max_features=0.75, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=42, subsample=0.6, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False) \n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False) \n",
      "\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1) \n",
      "\n",
      "VotingClassifier(estimators=[('RF',\n",
      "                              RandomForestClassifier(bootstrap=True,\n",
      "                                                     class_weight=None,\n",
      "                                                     criterion='gini',\n",
      "                                                     max_depth=5,\n",
      "                                                     max_features='auto',\n",
      "                                                     max_leaf_nodes=None,\n",
      "                                                     min_impurity_decrease=0.0,\n",
      "                                                     min_impurity_split=None,\n",
      "                                                     min_samples_leaf=1,\n",
      "                                                     min_samples_split=2,\n",
      "                                                     min_weight_fraction_leaf=0.0,\n",
      "                                                     n_estimators=100,\n",
      "                                                     n_jobs=None,\n",
      "                                                     oob_score=False,\n",
      "                                                     random_state=42, verbose=0,\n",
      "                                                     w...\n",
      "                                                         max_leaf_nodes=None,\n",
      "                                                         min_impurity_decrease=0.0,\n",
      "                                                         min_impurity_split=None,\n",
      "                                                         min_samples_leaf=1,\n",
      "                                                         min_samples_split=2,\n",
      "                                                         min_weight_fraction_leaf=0.0,\n",
      "                                                         n_estimators=100,\n",
      "                                                         n_iter_no_change=None,\n",
      "                                                         presort='auto',\n",
      "                                                         random_state=42,\n",
      "                                                         subsample=0.6,\n",
      "                                                         tol=0.0001,\n",
      "                                                         validation_fraction=0.1,\n",
      "                                                         verbose=0,\n",
      "                                                         warm_start=False))],\n",
      "                 flatten_transform=True, n_jobs=-1, voting='hard',\n",
      "                 weights=(2, 1, 1)) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prefixo_arquivo = 'submissions/titanic-submission'\n",
    "sufixo_arquivo = '08jul'\n",
    "\n",
    "for name, model in models:\n",
    "    print(model, '\\n')\n",
    "    \n",
    "    # treinar o modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # executar previsão usando o modelo\n",
    "    y_pred = model.predict(X_test)\n",
    "    vfunc = np.vectorize(lambda x: 'yes' if x > 0 else 'no')\n",
    "\n",
    "    # gerar dados de envio (submissão)\n",
    "    submission = pd.DataFrame({\n",
    "      'person': X_test.index,\n",
    "      'survived': vfunc(y_pred)\n",
    "    })\n",
    "    submission.set_index('person', inplace=True)\n",
    "\n",
    "    # gerar arquivo CSV para o envio\n",
    "    filename = '%s-p-%s-%s.csv' % (prefixo_arquivo, sufixo_arquivo, name.lower())\n",
    "    submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> submissions/titanic-submission-p-03jul-abdt.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,yes\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,no\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-03jul-dt.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,no\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-03jul-gb.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-03jul-knn.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,yes\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,no\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-03jul-lda.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,yes\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-03jul-lr.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-03jul-lsvm.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-03jul-mlp.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,no\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-03jul-nb.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-03jul-nn.csv <==\r\n",
      "person,survived\r\n",
      "76,no\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,no\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,no\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-03jul-rf.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,yes\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,no\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-03jul-sgd.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,yes\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-03jul-svm.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-06jul-dt.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,no\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-06jul-gb.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,no\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-06jul-knn.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,no\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,no\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-06jul-lr.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-06jul-mlp.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-06jul-nb.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-06jul-rf.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-06jul-svm.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,no\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-06jul-vc.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,no\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-06jul-xgb.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,no\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-07jul-abdt.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,yes\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,no\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-07jul-bc.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-07jul-dt.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,no\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-07jul-et.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-07jul-gb.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,no\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-07jul-knn.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-07jul-lda.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-07jul-lr.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-07jul-mlp.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-07jul-nb.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-07jul-rf.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-07jul-svm.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,no\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-07jul-vc.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-07jul-xgb.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,no\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-08jul-abdt.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,yes\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,no\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-08jul-bc.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-08jul-dt.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,no\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-08jul-et.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-08jul-gb.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,no\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-08jul-knn.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-08jul-lda.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-08jul-lr.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-08jul-mlp.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-08jul-nb.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-08jul-rf.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-08jul-svm.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-08jul-vc.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,yes\r\n",
      "\r\n",
      "==> submissions/titanic-submission-p-08jul-xgb.csv <==\r\n",
      "person,survived\r\n",
      "76,yes\r\n",
      "87,no\r\n",
      "376,no\r\n",
      "645,no\r\n",
      "976,no\r\n",
      "584,yes\r\n",
      "769,no\r\n",
      "628,no\r\n",
      "1036,no\r\n"
     ]
    }
   ],
   "source": [
    "!head submissions/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
