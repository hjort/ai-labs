{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação dos pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar pacotes necessários\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir parâmetros extras\n",
    "#pd.set_option('precision', 2)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar pacotes usados na seleção do modelo e na medição da precisão\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# importar os pacotes necessários para os algoritmos de regressão\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "#from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lars\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import RadiusNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import NuSVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga dos dados de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2763, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>sex</th>\n",
       "      <th>rings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>0.535</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>0.3285</td>\n",
       "      <td>0.1690</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>M</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>0.630</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.3205</td>\n",
       "      <td>0.5945</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>F</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>0.565</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.5795</td>\n",
       "      <td>0.1825</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>M</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.7865</td>\n",
       "      <td>0.3320</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>I</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3445</th>\n",
       "      <td>0.495</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.5780</td>\n",
       "      <td>0.2545</td>\n",
       "      <td>0.1305</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>I</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      length  diameter  height  whole_weight  shucked_weight  viscera_weight  \\\n",
       "id                                                                             \n",
       "2758   0.535     0.430   0.155        0.7845          0.3285          0.1690   \n",
       "1384   0.630     0.485   0.170        1.3205          0.5945          0.3450   \n",
       "1131   0.565     0.435   0.150        0.9900          0.5795          0.1825   \n",
       "3726   0.500     0.395   0.145        0.7865          0.3320          0.1815   \n",
       "3445   0.495     0.400   0.145        0.5780          0.2545          0.1305   \n",
       "\n",
       "      shell_weight sex  rings  \n",
       "id                             \n",
       "2758        0.2450   M     10  \n",
       "1384        0.3450   F      9  \n",
       "1131        0.2060   M      8  \n",
       "3726        0.2455   I      8  \n",
       "3445        0.1645   I      8  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carregar arquivo de dados de treino\n",
    "filename = 'abalone-train.csv'\n",
    "filename = 'abalone-train-o6.csv' # removidos outliers\n",
    "#filename = 'https://github.com/hjort/ai-labs/raw/master/kaggle/serpro-abalone/abalone-train.csv'\n",
    "data = pd.read_csv(filename, index_col='id')\n",
    "\n",
    "# mostrar tamanho\n",
    "print(data.shape)\n",
    "\n",
    "# mostrar alguns exemplos de registros\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2763 entries, 2758 to 852\n",
      "Data columns (total 3 columns):\n",
      "sex_F    2763 non-null uint8\n",
      "sex_I    2763 non-null uint8\n",
      "sex_M    2763 non-null uint8\n",
      "dtypes: uint8(3)\n",
      "memory usage: 29.7 KB\n"
     ]
    }
   ],
   "source": [
    "data_sex = pd.get_dummies(data['sex'], prefix='sex')\n",
    "\n",
    "cols = {}\n",
    "for col in data_sex.columns:\n",
    "    cols[col] = col.lower()\n",
    "data.rename(columns=cols, inplace=True)\n",
    "\n",
    "data_sex.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>rings</th>\n",
       "      <th>sex_F</th>\n",
       "      <th>sex_I</th>\n",
       "      <th>sex_M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>0.535</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>0.3285</td>\n",
       "      <td>0.1690</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>0.630</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.3205</td>\n",
       "      <td>0.5945</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>0.565</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.5795</td>\n",
       "      <td>0.1825</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.7865</td>\n",
       "      <td>0.3320</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3445</th>\n",
       "      <td>0.495</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.5780</td>\n",
       "      <td>0.2545</td>\n",
       "      <td>0.1305</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      length  diameter  height  whole_weight  shucked_weight  viscera_weight  \\\n",
       "id                                                                             \n",
       "2758   0.535     0.430   0.155        0.7845          0.3285          0.1690   \n",
       "1384   0.630     0.485   0.170        1.3205          0.5945          0.3450   \n",
       "1131   0.565     0.435   0.150        0.9900          0.5795          0.1825   \n",
       "3726   0.500     0.395   0.145        0.7865          0.3320          0.1815   \n",
       "3445   0.495     0.400   0.145        0.5780          0.2545          0.1305   \n",
       "\n",
       "      shell_weight  rings  sex_F  sex_I  sex_M  \n",
       "id                                              \n",
       "2758        0.2450     10      0      0      1  \n",
       "1384        0.3450      9      1      0      0  \n",
       "1131        0.2060      8      0      0      1  \n",
       "3726        0.2455      8      0      1      0  \n",
       "3445        0.1645      8      0      1      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.join(data_sex)\n",
    "data.drop('sex', axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for sex in ['M', 'F', 'I']:\n",
    "    col = 'sex_' + sex\n",
    "    data[col] = data[col].astype('float')\n",
    "data['rings'] = data.rings.astype('float')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data.sex = data.sex.astype('category').cat.codes\n",
    "print(data.dtypes)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# excluir dados com valores inválidos\n",
    "outliers = np.concatenate((\n",
    "    data[data.height == 0.0].index,\n",
    "    data[(data['viscera_weight'] > 0.5) & (data['rings'] < 20 - 1.5)].index,\n",
    "    data[(data['viscera_weight'] < 0.5) & (data['rings'] > 25 - 1.5)].index,\n",
    "    data[(data['shell_weight'] > 0.6) & (data['rings'] < 25 - 1.5)].index,\n",
    "    data[(data['shell_weight'] < 0.8) & (data['rings'] > 25 - 1.5)].index,\n",
    "    data[(data['shucked_weight'] >= 1.0) & (data['rings'] < 20 - 1.5)].index,\n",
    "    data[(data['shucked_weight'] < 1.0)  & (data['rings'] > 20 - 1.5)].index,\n",
    "    data[(data['whole_weight'] >= 2.5) & (data['rings'] < 25 - 1.5)].index,\n",
    "    data[(data['whole_weight'] < 2.5)  & (data['rings'] > 25 - 1.5)].index,\n",
    "    data[(data['diameter'] < 0.1)  & (data['rings'] < 5 - 1.5)].index,\n",
    "    data[(data['diameter'] < 0.6)  & (data['rings'] > 25 - 1.5)].index,\n",
    "    data[(data['diameter'] >= 0.6) & (data['rings'] < 25 - 1.5)].index,\n",
    "    data[(data['height'] > 0.4) & (data['rings'] < 15 - 1.5)].index,\n",
    "    data[(data['height'] < 0.4) & (data['rings'] > 25 - 1.5)].index,\n",
    "    data[(data['length'] < 0.1)  & (data['rings'] < 5 - 1.5)].index,\n",
    "    data[(data['length'] < 0.8)  & (data['rings'] > 25 - 1.5)].index,\n",
    "    data[(data['length'] >= 0.8) & (data['rings'] < 25 - 1.5)].index\n",
    "), axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data[data.index.isin(outliers)].head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\"Número de outliers a serem removidos: %d\" % len(outliers))\n",
    "\n",
    "print(\"Antes:\", data.shape)\n",
    "data.drop(outliers, inplace=True)\n",
    "print(\"Depois:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma dos dados originais: (2763, 10) (2763,)\n"
     ]
    }
   ],
   "source": [
    "# definir dados de entrada\n",
    "\n",
    "X = data.drop(['rings'], axis=1) # tudo, exceto a coluna alvo\n",
    "y = data['rings'] # apenas a coluna alvo\n",
    "\n",
    "print('Forma dos dados originais:', X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento dos modelos preditivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "# cria função para cálculo do RMSE (REMQ)\n",
    "def root_mean_squared_error(ground_truth, predictions):\n",
    "    return mean_squared_error(ground_truth, predictions) ** 0.5\n",
    "\n",
    "RMSE = make_scorer(root_mean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# avalia o desempenho do modelo, retornando o valor do RMSE\n",
    "def evaluate_model_cv(model, X=X, y=y):\n",
    "    start = datetime.now()\n",
    "    kfold = KFold(n_splits=10, random_state=42)\n",
    "    results = cross_val_score(model, X, y, cv=kfold, scoring=RMSE, verbose=1)\n",
    "    end = datetime.now()\n",
    "    elapsed = int((end - start).total_seconds() * 1000)\n",
    "    score = (-1) * results.mean()\n",
    "    stddev = results.std()\n",
    "    print(model, '\\nScore: %.2f (+/- %.2f) [%5s ms]' % (score, stddev, elapsed))\n",
    "    return score, stddev, elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faz o ajuste fino do modelo, calculando os melhores hiperparâmetros\n",
    "def fine_tune_model(model, params, X=X, y=y):\n",
    "  print('\\nFine Tuning Model:')\n",
    "  print(model, \"\\nparams:\", params)\n",
    "\n",
    "  kfold = KFold(n_splits=10, random_state=42)\n",
    "  grid = GridSearchCV(estimator=model, param_grid=params, scoring=RMSE, cv=kfold, verbose=1)\n",
    "  grid.fit(X, y)\n",
    "\n",
    "  print('\\nGrid Best Score: %.2f' % (grid.best_score_ * (-1)))\n",
    "  print('Best Params:', grid.best_params_)\n",
    " \n",
    "  return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação e ajuste fino de cada modelo preditivo\n",
    "\n",
    "-  https://scikit-learn.org/stable/modules/classes.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalized Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=2, normalize=True) \n",
      "Score: 2.20 (+/- 0.16) [ 1468 ms]\n",
      "\n",
      "Fine Tuning Model:\n",
      "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=2, normalize=True) \n",
      "params: {'fit_intercept': [True, False], 'normalize': [True, False]}\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "\n",
      "Grid Best Score: 2.20\n",
      "Best Params: {'fit_intercept': False, 'normalize': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=42, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=LinearRegression(copy_X=True, fit_intercept=False, n_jobs=2, normalize=True),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'fit_intercept': [True, False], 'normalize': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(root_mean_squared_error, greater_is_better=False),\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression(n_jobs=2, fit_intercept=False, normalize=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = dict(\n",
    "    fit_intercept=[True, False],\n",
    "    normalize=[True, False]\n",
    ")\n",
    "fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(n_jobs=2, random_state=42, multi_class='auto', C=1000, solver='newton-cg')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'C':np.logspace(-3,3,7)\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OrthogonalMatchingPursuit(n_nonzero_coefs=8, fit_intercept=True, normalize=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {\n",
    "    'n_nonzero_coefs': [None, 1, 2, 4, 6, 8, 10],\n",
    "    'fit_intercept': [True, False],\n",
    "    'normalize': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = PassiveAggressiveRegressor(random_state=42, C=0.1, fit_intercept=True, max_iter=1000, tol=0.001)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {\n",
    "    'C': [0.1, 0.2, 0.4, 0.8, 1.0],\n",
    "    'fit_intercept': [True, False],\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Perceptron(random_state=42, penalty='l2', alpha=1e-5, fit_intercept=True, max_iter=1000, tol=1e-3)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#penalty=None, alpha=0.0001, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, eta0=1.0, n_jobs=None, \n",
    "#random_state=0, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, class_weight=None, warm_start=False\n",
    "\n",
    "params = {\n",
    "    'penalty': [None, 'l2', 'l1', 'elasticnet'],\n",
    "    'alpha': np.logspace(-6, -1, 6),\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RANSACRegressor(random_state=42, min_samples=0.75)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#base_estimator=None, min_samples=None, residual_threshold=None, is_data_valid=None, is_model_valid=None, max_trials=100, \n",
    "#max_skips=inf, stop_n_inliers=inf, stop_score=inf, stop_probability=0.99, loss=’absolute_loss’, random_state=None\n",
    "\n",
    "params = {\n",
    "    'min_samples': [None, 0.1, 0.25, 0.5, 0.75, 1.0]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge(random_state=42, alpha=0.1, fit_intercept=False, normalize=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, solver=’auto’, random_state=None\n",
    "\n",
    "params = {\n",
    "    'alpha': np.logspace(-6, -1, 4),\n",
    "    'fit_intercept': [True, False],\n",
    "    'normalize': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = SGDRegressor(random_state=42, alpha=1e-06, fit_intercept=True, penalty=None, tol=1e-3)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#loss=’squared_loss’, penalty=’l2’, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, \n",
    "#verbose=0, epsilon=0.1, random_state=None, learning_rate=’invscaling’, eta0=0.01, power_t=0.25, early_stopping=False, \n",
    "#validation_fraction=0.1, n_iter_no_change=5, warm_start=False, average=False\n",
    "\n",
    "params = {\n",
    "    'penalty': [None, 'l2', 'l1', 'elasticnet'],\n",
    "    'alpha': np.logspace(-6, -1, 4),\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TheilSenRegressor(random_state=42, n_jobs=2, fit_intercept=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#fit_intercept=True, copy_X=True, max_subpopulation=10000.0, n_subsamples=None, \n",
    "#max_iter=300, tol=0.001, random_state=None, n_jobs=None, verbose=False\n",
    "\n",
    "params = {\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeRegressor(random_state=42, max_depth=4, min_samples_split=0.25)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#criterion=’mse’, splitter=’best’, max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, \n",
    "#min_impurity_decrease=0.0, min_impurity_split=None, presort=False\n",
    "\n",
    "params = dict(\n",
    "    max_depth=[4, 6, 8, 10, 12, 14],\n",
    "    min_samples_split=[0.25, 0.5, 0.75, 1.0]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianProcessRegressor(random_state=42, alpha=0.01, normalize_y=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#kernel=None, alpha=1e-10, optimizer=’fmin_l_bfgs_b’, n_restarts_optimizer=0,\n",
    "#normalize_y=False, copy_X_train=True, random_state=None\n",
    "\n",
    "params = dict(\n",
    "    alpha=np.logspace(-6, -1, 6),\n",
    "    normalize_y=[True, False]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KernelRidge()\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#alpha=1, kernel=’linear’, gamma=None, degree=3, coef0=1, kernel_params=None\n",
    "\n",
    "params = dict(\n",
    "    alpha=np.logspace(-6, -1, 4)\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB(var_smoothing=0.1)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#priors=None, var_smoothing=1e-09\n",
    "\n",
    "params = dict(\n",
    "    var_smoothing=np.logspace(-9, -1, 5)\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = KNeighborsRegressor(n_jobs=2, n_neighbors=13, weights='distance')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#n_neighbors=5, weights=’uniform’, algorithm=’auto’, leaf_size=30, p=2, metric=’minkowski’,\n",
    "#metric_params=None, n_jobs=None\n",
    "\n",
    "params = {\n",
    "    'n_neighbors': [1, 3, 5, 7, 9, 11, 13],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = SVR(gamma='auto', kernel='linear')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#kernel=’rbf’, degree=3, gamma=’auto_deprecated’, coef0=0.0, tol=0.001, C=1.0, \n",
    "#epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1\n",
    "\n",
    "params = {\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']#, 'precomputed']\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = MLPRegressor(random_state=42, max_iter=500,\n",
    "                     activation='logistic', hidden_layer_sizes=(50,), solver='lbfgs')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#hidden_layer_sizes=(100, ), activation=’relu’, solver=’adam’, alpha=0.0001, batch_size=’auto’, \n",
    "#learning_rate=’constant’, learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, \n",
    "#random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, \n",
    "#early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10\n",
    "\n",
    "params = dict(\n",
    "    hidden_layer_sizes=[(100,), (50,), (50,2)],\n",
    "    activation=['identity', 'logistic', 'tanh', 'relu'],\n",
    "    solver=['lbfgs', 'sgd', 'adam']\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(random_state=42, n_jobs=2, n_estimators=100, max_depth=7)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#n_estimators=’warn’, criterion=’mse’, max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#min_weight_fraction_leaf=0.0, max_features=’auto’, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, \n",
    "#verbose=0, warm_start=False\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [5, 10, 25, 50, 75, 100],\n",
    "    'max_depth': [None, 3, 5, 7, 9, 11, 13]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor(random_state=42, learning_rate=0.05, n_estimators=100,\n",
    "                                  subsample=0.4, max_depth=6, max_features=10)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#loss=’ls’, learning_rate=0.1, n_estimators=100, subsample=1.0, criterion=’friedman_mse’, min_samples_split=2,\n",
    "#min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, \n",
    "#min_impurity_split=None, init=None, random_state=None, max_features=None, alpha=0.9, verbose=0, \n",
    "#max_leaf_nodes=None, warm_start=False, presort=’auto’, validation_fraction=0.1, n_iter_no_change=None, \n",
    "#tol=0.0001\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[100, 250, 500, 750, 1000],\n",
    "    max_features=[5, 7, 10],\n",
    "    max_depth=[4, 6, 8, 10, 12, 14],\n",
    "    learning_rate=[0.05, 0.1, 0.15, 0.2],\n",
    "    subsample=[0.4, 0.6, 0.8]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExtraTreesRegressor(random_state=42, n_jobs=2, n_estimators=200, max_features=5)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#n_estimators=’warn’, criterion=’mse’, max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#min_weight_fraction_leaf=0.0, max_features=’auto’, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#min_impurity_split=None, bootstrap=False, oob_score=False, n_jobs=None, random_state=None, verbose=0,\n",
    "#warm_start=False\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[10, 25, 50, 75, 100, 200],\n",
    "    max_features=['auto', 5, 7, 10]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaggingRegressor(random_state=42, n_jobs=2, base_estimator=DecisionTreeRegressor())\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#base_estimator=None, n_estimators=10, max_samples=1.0, max_features=1.0, bootstrap=True, \n",
    "#bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=None, random_state=None, verbose=0\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[10, 25, 50, 75, 100, 200],\n",
    "    max_features=[0.25, 0.5, 0.75, 1.0]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdaBoostRegressor(random_state=42, n_estimators=100, base_estimator=DecisionTreeRegressor())\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "# base_estimator=None, n_estimators=50, learning_rate=1.0, algorithm=’SAMME.R’, random_state=None\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[10, 25, 50, 75, 100, 200]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outros algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost\n",
    "\n",
    "- https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# https://machinelearningmastery.com/how-to-fix-futurewarning-messages-in-scikit-learn/\n",
    "\n",
    "# import warnings filter\n",
    "#from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "#simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# ignore all caught warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "model = XGBRegressor(random_state=42, n_jobs=2, learning_rate=0.1,\n",
    "                     n_estimators=50, max_depth=5, objective='reg:squarederror')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#max_depth=3, learning_rate=0.1, n_estimators=100, verbosity=1, silent=None, objective='reg:squarederror',\n",
    "#booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, \n",
    "#colsample_bytree=1, colsample_bylevel=1, colsample_bynode=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, \n",
    "#base_score=0.5, random_state=0, seed=None, missing=None, importance_type='gain'\n",
    "\n",
    "params = dict(\n",
    "    max_depth=[3, 5, 7, 9],\n",
    "    n_estimators=[10, 25, 50, 75, 100, 200]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Learning Model\n",
    "\n",
    "- https://towardsdatascience.com/automate-stacking-in-python-fc3e7834772e\n",
    "- https://github.com/vecxoz/vecstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vecstack import stacking\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Make train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize 1-st level models\n",
    "ensemble_models = [\n",
    "    RandomForestRegressor(random_state=42, n_jobs=2, n_estimators=100, max_depth=7),\n",
    "    GradientBoostingRegressor(random_state=42, learning_rate=0.05, n_estimators=100,\n",
    "                                  subsample=0.4, max_depth=6, max_features=10),\n",
    "    #ExtraTreesRegressor(random_state=42, n_jobs=2, n_estimators=100)\n",
    "    XGBRegressor(random_state=42, n_jobs=2, learning_rate=0.1,\n",
    "                     n_estimators=50, max_depth=5, objective='reg:squarederror')\n",
    "]\n",
    "\n",
    "# Compute stacking features\n",
    "S_train, S_test = stacking(ensemble_models, X_train, y_train, X_test,\n",
    "    regression=True, metric=mean_squared_error, n_folds=4, shuffle=True,\n",
    "    random_state=42, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_train, S_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize 2-nd level model\n",
    "model = XGBRegressor(random_state=42, n_jobs=2, learning_rate=0.1,\n",
    "                     n_estimators=50, max_depth=5, objective='reg:squarederror')\n",
    "\n",
    "# Fit 2-nd level model\n",
    "model = model.fit(S_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(S_test)\n",
    "\n",
    "# Final prediction score\n",
    "print('Final prediction score: [%.8f]' % mean_squared_error(y_test, y_pred) ** 0.5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# https://towardsdatascience.com/ensemble-learning-using-scikit-learn-85c4531ff86a\n",
    "\n",
    "# classe não disponível no pacote :P\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "model = VotingRegressor(\n",
    "    RandomForestRegressor(random_state=42, n_jobs=2, n_estimators=100, max_depth=7),\n",
    "    GradientBoostingRegressor(random_state=42),\n",
    "    ExtraTreesRegressor(random_state=42, n_jobs=2, n_estimators=100)\n",
    ")\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#estimators, weights=None, n_jobs=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação final entre os algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "# Generalized Linear Models\n",
    "models.append(('LinReg', LinearRegression(n_jobs=2, fit_intercept=False, normalize=True)))\n",
    "models.append(('LogReg', LogisticRegression(n_jobs=2, random_state=42, multi_class='auto', C=1000, solver='newton-cg')))\n",
    "models.append(('OMP', OrthogonalMatchingPursuit(n_nonzero_coefs=8, fit_intercept=True, normalize=True)))\n",
    "models.append(('PAR', PassiveAggressiveRegressor(random_state=42, C=0.1, fit_intercept=True, max_iter=1000, tol=0.001)))\n",
    "models.append(('PP', Perceptron(random_state=42, penalty='l2', alpha=1e-5, fit_intercept=True, max_iter=1000, tol=1e-3)))\n",
    "models.append(('RANSAC', RANSACRegressor(random_state=42, min_samples=0.75)))\n",
    "models.append(('Ridge', Ridge(random_state=42, alpha=0.1, fit_intercept=False, normalize=True)))\n",
    "models.append(('SGD', SGDRegressor(random_state=42, alpha=1e-06, fit_intercept=True, penalty=None, tol=1e-3)))\n",
    "models.append(('TSR', TheilSenRegressor(random_state=42, n_jobs=2, fit_intercept=True)))\n",
    "\n",
    "# Decision Trees\n",
    "models.append(('DTR', DecisionTreeRegressor(random_state=42, max_depth=4, min_samples_split=0.25)))\n",
    "\n",
    "# Gaussian Processes\n",
    "models.append(('GPR', GaussianProcessRegressor(random_state=42, alpha=0.01, normalize_y=True)))\n",
    "\n",
    "# Kernel Ridge Regression\n",
    "models.append(('KRR', KernelRidge()))\n",
    "\n",
    "# Naïve Bayes\n",
    "models.append(('GNB', GaussianNB(var_smoothing=0.1)))\n",
    "\n",
    "# Nearest Neighbors\n",
    "models.append(('kNN', KNeighborsRegressor(n_jobs=2, n_neighbors=13, weights='distance')))\n",
    "\n",
    "# Support Vector Machines\n",
    "models.append(('SVM', SVR(gamma='auto', kernel='linear')))\n",
    "\n",
    "# Neural network models\n",
    "models.append(('MLP', MLPRegressor(random_state=42, max_iter=500,\n",
    "                     activation='logistic', hidden_layer_sizes=(50,), solver='lbfgs')))\n",
    "\n",
    "# Ensemble Methods\n",
    "models.append(('RFR', RandomForestRegressor(random_state=42, n_jobs=2, n_estimators=100, max_depth=7)))\n",
    "models.append(('GBR', GradientBoostingRegressor(random_state=42, learning_rate=0.05, n_estimators=100,\n",
    "                                  subsample=0.4, max_depth=6, max_features=10)))\n",
    "models.append(('ETR', ExtraTreesRegressor(random_state=42, n_jobs=2, n_estimators=200, max_features=5)))\n",
    "models.append(('BDTR', BaggingRegressor(random_state=42, n_jobs=2, base_estimator=DecisionTreeRegressor())))\n",
    "models.append(('ABDTR', AdaBoostRegressor(random_state=42, n_estimators=100, base_estimator=DecisionTreeRegressor())))\n",
    "\n",
    "# XGBoost\n",
    "models.append(('XGBR', XGBRegressor(random_state=42, n_jobs=2, learning_rate=0.1,\n",
    "                                    n_estimators=50, max_depth=5, objective='reg:squarederror')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=2, normalize=True) \n",
      "Score: 2.20 (+/- 0.16) [  374 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 16.0min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='auto', n_jobs=2,\n",
      "          penalty='l2', random_state=42, solver='newton-cg', tol=0.0001,\n",
      "          verbose=0, warm_start=False) \n",
      "Score: 2.43 (+/- 0.22) [958755 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=8,\n",
      "             normalize=True, precompute='auto', tol=None) \n",
      "Score: 2.19 (+/- 0.16) [ 1025 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassiveAggressiveRegressor(C=0.1, average=False, early_stopping=False,\n",
      "              epsilon=0.1, fit_intercept=True, loss='epsilon_insensitive',\n",
      "              max_iter=1000, n_iter=None, n_iter_no_change=5,\n",
      "              random_state=42, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Score: 2.33 (+/- 0.19) [  941 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    4.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron(alpha=1e-05, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "      fit_intercept=True, max_iter=1000, n_iter=None, n_iter_no_change=5,\n",
      "      n_jobs=None, penalty='l2', random_state=42, shuffle=True, tol=0.001,\n",
      "      validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Score: 4.17 (+/- 1.87) [ 4665 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   14.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANSACRegressor(base_estimator=None, is_data_valid=None, is_model_valid=None,\n",
      "        loss='absolute_loss', max_skips=inf, max_trials=100,\n",
      "        min_samples=0.75, random_state=42, residual_threshold=None,\n",
      "        stop_n_inliers=inf, stop_probability=0.99, stop_score=inf) \n",
      "Score: 2.22 (+/- 0.18) [14519 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=0.1, copy_X=True, fit_intercept=False, max_iter=None,\n",
      "   normalize=True, random_state=42, solver='auto', tol=0.001) \n",
      "Score: 2.19 (+/- 0.17) [  393 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    7.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor(alpha=1e-06, average=False, early_stopping=False, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='invscaling', loss='squared_loss', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, penalty=None, power_t=0.25,\n",
      "       random_state=42, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "       verbose=0, warm_start=False) \n",
      "Score: 2.28 (+/- 0.20) [ 7564 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheilSenRegressor(copy_X=True, fit_intercept=True, max_iter=300,\n",
      "         max_subpopulation=10000, n_jobs=2, n_subsamples=None,\n",
      "         random_state=42, tol=0.001, verbose=False) \n",
      "Score: 2.20 (+/- 0.17) [101144 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor(criterion='mse', max_depth=4, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=0.25, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=42, splitter='best') \n",
      "Score: 2.49 (+/- 0.20) [  578 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianProcessRegressor(alpha=0.01, copy_X_train=True, kernel=None,\n",
      "             n_restarts_optimizer=0, normalize_y=True,\n",
      "             optimizer='fmin_l_bfgs_b', random_state=42) \n",
      "Score: 2.11 (+/- 0.16) [130991 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.0min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KernelRidge(alpha=1, coef0=1, degree=3, gamma=None, kernel='linear',\n",
      "      kernel_params=None) \n",
      "Score: 2.21 (+/- 0.18) [62219 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=0.1) \n",
      "Score: 5.78 (+/- 0.36) [  746 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=2, n_neighbors=13, p=2,\n",
      "          weights='distance') \n",
      "Score: 2.24 (+/- 0.19) [ 1331 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   18.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False) \n",
      "Score: 2.33 (+/- 0.22) [18719 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  4.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(50,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False) \n",
      "Score: 2.11 (+/- 0.14) [257395 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   31.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=7,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=2,\n",
      "           oob_score=False, random_state=42, verbose=0, warm_start=False) \n",
      "Score: 2.17 (+/- 0.18) [31203 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   22.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.05, loss='ls', max_depth=6, max_features=10,\n",
      "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "             min_impurity_split=None, min_samples_leaf=1,\n",
      "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "             n_estimators=100, n_iter_no_change=None, presort='auto',\n",
      "             random_state=42, subsample=0.4, tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Score: 2.19 (+/- 0.19) [22078 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   53.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features=5, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "          min_impurity_split=None, min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=2,\n",
      "          oob_score=False, random_state=42, verbose=0, warm_start=False) \n",
      "Score: 2.23 (+/- 0.17) [53608 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingRegressor(base_estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best'),\n",
      "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=10, n_jobs=2, oob_score=False,\n",
      "         random_state=42, verbose=0, warm_start=False) \n",
      "Score: 2.29 (+/- 0.16) [ 6060 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best'),\n",
      "         learning_rate=1.0, loss='linear', n_estimators=100,\n",
      "         random_state=42) \n",
      "Score: 2.26 (+/- 0.20) [95076 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=5, min_child_weight=1, missing=None, n_estimators=50,\n",
      "       n_jobs=2, nthread=None, objective='reg:squarederror',\n",
      "       random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=None, subsample=1, verbosity=1) \n",
      "Score: 2.18 (+/- 0.18) [10203 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   10.2s finished\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "scores = []\n",
    "stddevs = []\n",
    "times = []\n",
    "\n",
    "for name, model in models:\n",
    "    score, stddev, elapsed = evaluate_model_cv(model, X=X, y=y)\n",
    "    results.append((score, stddev))\n",
    "    names.append(name)\n",
    "    scores.append(score)\n",
    "    stddevs.append(stddev)\n",
    "    times.append(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# comparar desempenhos dos algoritmos\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "fig.suptitle('Comparação dos Algoritmos')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Time (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MLP</td>\n",
       "      <td>2.111813</td>\n",
       "      <td>0.141464</td>\n",
       "      <td>257395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GPR</td>\n",
       "      <td>2.111821</td>\n",
       "      <td>0.161481</td>\n",
       "      <td>130991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RFR</td>\n",
       "      <td>2.174495</td>\n",
       "      <td>0.182436</td>\n",
       "      <td>31203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBR</td>\n",
       "      <td>2.184693</td>\n",
       "      <td>0.177528</td>\n",
       "      <td>10203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GBR</td>\n",
       "      <td>2.189934</td>\n",
       "      <td>0.186093</td>\n",
       "      <td>22078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OMP</td>\n",
       "      <td>2.194522</td>\n",
       "      <td>0.164392</td>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>2.194962</td>\n",
       "      <td>0.166668</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>2.195141</td>\n",
       "      <td>0.164698</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TSR</td>\n",
       "      <td>2.203752</td>\n",
       "      <td>0.168800</td>\n",
       "      <td>101144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KRR</td>\n",
       "      <td>2.209984</td>\n",
       "      <td>0.179461</td>\n",
       "      <td>62219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RANSAC</td>\n",
       "      <td>2.216473</td>\n",
       "      <td>0.179052</td>\n",
       "      <td>14519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ETR</td>\n",
       "      <td>2.226935</td>\n",
       "      <td>0.174274</td>\n",
       "      <td>53608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>kNN</td>\n",
       "      <td>2.239189</td>\n",
       "      <td>0.191990</td>\n",
       "      <td>1331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ABDTR</td>\n",
       "      <td>2.255858</td>\n",
       "      <td>0.197317</td>\n",
       "      <td>95076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SGD</td>\n",
       "      <td>2.284606</td>\n",
       "      <td>0.204258</td>\n",
       "      <td>7564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BDTR</td>\n",
       "      <td>2.287212</td>\n",
       "      <td>0.164638</td>\n",
       "      <td>6060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVM</td>\n",
       "      <td>2.333840</td>\n",
       "      <td>0.217872</td>\n",
       "      <td>18719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PAR</td>\n",
       "      <td>2.334297</td>\n",
       "      <td>0.187917</td>\n",
       "      <td>941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>2.432804</td>\n",
       "      <td>0.221042</td>\n",
       "      <td>958755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DTR</td>\n",
       "      <td>2.490847</td>\n",
       "      <td>0.204985</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PP</td>\n",
       "      <td>4.171975</td>\n",
       "      <td>1.873108</td>\n",
       "      <td>4665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GNB</td>\n",
       "      <td>5.776984</td>\n",
       "      <td>0.364317</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model     Score   Std Dev  Time (ms)\n",
       "15     MLP  2.111813  0.141464     257395\n",
       "10     GPR  2.111821  0.161481     130991\n",
       "16     RFR  2.174495  0.182436      31203\n",
       "21    XGBR  2.184693  0.177528      10203\n",
       "17     GBR  2.189934  0.186093      22078\n",
       "2      OMP  2.194522  0.164392       1025\n",
       "6    Ridge  2.194962  0.166668        393\n",
       "0   LinReg  2.195141  0.164698        374\n",
       "8      TSR  2.203752  0.168800     101144\n",
       "11     KRR  2.209984  0.179461      62219\n",
       "5   RANSAC  2.216473  0.179052      14519\n",
       "18     ETR  2.226935  0.174274      53608\n",
       "13     kNN  2.239189  0.191990       1331\n",
       "20   ABDTR  2.255858  0.197317      95076\n",
       "7      SGD  2.284606  0.204258       7564\n",
       "19    BDTR  2.287212  0.164638       6060\n",
       "14     SVM  2.333840  0.217872      18719\n",
       "3      PAR  2.334297  0.187917        941\n",
       "1   LogReg  2.432804  0.221042     958755\n",
       "9      DTR  2.490847  0.204985        578\n",
       "4       PP  4.171975  1.873108       4665\n",
       "12     GNB  5.776984  0.364317        746"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame({'Model': names, 'Score': scores, 'Std Dev': stddevs, 'Time (ms)': times})\n",
    "results_df.sort_values(by='Score', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
