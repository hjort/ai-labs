{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação dos pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar pacotes necessários\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir parâmetros extras\n",
    "#pd.set_option('precision', 2)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar pacotes usados na seleção do modelo e na medição da precisão\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# importar os pacotes necessários para os algoritmos de regressão\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "#from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lars\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import RadiusNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import NuSVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga dos dados de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2784, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>rings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>M</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>0.3285</td>\n",
       "      <td>0.1690</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>F</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.3205</td>\n",
       "      <td>0.5945</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>M</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.5795</td>\n",
       "      <td>0.1825</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>I</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.7865</td>\n",
       "      <td>0.3320</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3445</th>\n",
       "      <td>I</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.5780</td>\n",
       "      <td>0.2545</td>\n",
       "      <td>0.1305</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sex  length  diameter  height  whole_weight  shucked_weight  \\\n",
       "id                                                                 \n",
       "2758   M   0.535     0.430   0.155        0.7845          0.3285   \n",
       "1384   F   0.630     0.485   0.170        1.3205          0.5945   \n",
       "1131   M   0.565     0.435   0.150        0.9900          0.5795   \n",
       "3726   I   0.500     0.395   0.145        0.7865          0.3320   \n",
       "3445   I   0.495     0.400   0.145        0.5780          0.2545   \n",
       "\n",
       "      viscera_weight  shell_weight  rings  \n",
       "id                                         \n",
       "2758          0.1690        0.2450     10  \n",
       "1384          0.3450        0.3450      9  \n",
       "1131          0.1825        0.2060      8  \n",
       "3726          0.1815        0.2455      8  \n",
       "3445          0.1305        0.1645      8  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carregar arquivo de dados de treino\n",
    "filename = 'abalone-train.csv'\n",
    "#filename = 'https://github.com/hjort/ai-labs/raw/master/kaggle/serpro-abalone/abalone-train.csv'\n",
    "data = pd.read_csv(filename, index_col='id')\n",
    "\n",
    "# mostrar tamanho\n",
    "print(data.shape)\n",
    "\n",
    "# mostrar alguns exemplos de registros\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>rings</th>\n",
       "      <th>sex_F</th>\n",
       "      <th>sex_I</th>\n",
       "      <th>sex_M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>0.535</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>0.3285</td>\n",
       "      <td>0.1690</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>0.630</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.3205</td>\n",
       "      <td>0.5945</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>0.565</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.5795</td>\n",
       "      <td>0.1825</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.7865</td>\n",
       "      <td>0.3320</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3445</th>\n",
       "      <td>0.495</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.5780</td>\n",
       "      <td>0.2545</td>\n",
       "      <td>0.1305</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      length  diameter  height  whole_weight  shucked_weight  viscera_weight  \\\n",
       "id                                                                             \n",
       "2758   0.535     0.430   0.155        0.7845          0.3285          0.1690   \n",
       "1384   0.630     0.485   0.170        1.3205          0.5945          0.3450   \n",
       "1131   0.565     0.435   0.150        0.9900          0.5795          0.1825   \n",
       "3726   0.500     0.395   0.145        0.7865          0.3320          0.1815   \n",
       "3445   0.495     0.400   0.145        0.5780          0.2545          0.1305   \n",
       "\n",
       "      shell_weight  rings  sex_F  sex_I  sex_M  \n",
       "id                                              \n",
       "2758        0.2450     10      0      0      1  \n",
       "1384        0.3450      9      1      0      0  \n",
       "1131        0.2060      8      0      0      1  \n",
       "3726        0.2455      8      0      1      0  \n",
       "3445        0.1645      8      0      1      0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gerar \"one hot encoding\" em atributos categóricos\n",
    "data = pd.get_dummies(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>rings</th>\n",
       "      <th>sex_F</th>\n",
       "      <th>sex_I</th>\n",
       "      <th>sex_M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>0.775</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.250</td>\n",
       "      <td>2.7795</td>\n",
       "      <td>1.3485</td>\n",
       "      <td>0.7600</td>\n",
       "      <td>0.5780</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>0.705</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.515</td>\n",
       "      <td>2.2100</td>\n",
       "      <td>1.1075</td>\n",
       "      <td>0.4865</td>\n",
       "      <td>0.5120</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>0.315</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.0575</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>0.3505</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      length  diameter  height  whole_weight  shucked_weight  viscera_weight  \\\n",
       "id                                                                             \n",
       "1763   0.775     0.630   0.250        2.7795          1.3485          0.7600   \n",
       "1417   0.705     0.565   0.515        2.2100          1.1075          0.4865   \n",
       "3996   0.315     0.230   0.000        0.1340          0.0575          0.0285   \n",
       "\n",
       "      shell_weight  rings  sex_F  sex_I  sex_M  \n",
       "id                                              \n",
       "1763        0.5780     12      0      0      1  \n",
       "1417        0.5120     10      0      0      1  \n",
       "3996        0.3505      6      0      1      0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encontrar possíveis outliers\n",
    "outliers = np.concatenate((\n",
    "    data[(data['height'] < 0.01) | (data['height'] > 0.3)].index,\n",
    "    data[(data['viscera_weight'] < 0.0001) | (data['viscera_weight'] > 0.6)].index\n",
    "), axis=0)\n",
    "\n",
    "# exibir outliers\n",
    "data[data.index.isin(outliers)].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de outliers a serem removidos: 3\n",
      "Antes: (2784, 11)\n",
      "Depois: (2781, 11)\n"
     ]
    }
   ],
   "source": [
    "# remover outliers detectados\n",
    "print(\"Número de outliers a serem removidos: %d\" % len(outliers))\n",
    "\n",
    "print(\"Antes:\", data.shape)\n",
    "data.drop(outliers, inplace=True)\n",
    "print(\"Depois:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma dos dados originais: (2781, 10) (2781,)\n"
     ]
    }
   ],
   "source": [
    "# definir dados de entrada\n",
    "X = data.drop(['rings'], axis=1) # tudo, exceto a coluna alvo\n",
    "y = data['rings'] # apenas a coluna alvo\n",
    "\n",
    "print('Forma dos dados originais:', X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento dos modelos preditivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "# cria função para cálculo do RMSE (REMQ)\n",
    "def root_mean_squared_error(ground_truth, predictions):\n",
    "    return mean_squared_error(ground_truth, predictions) ** 0.5\n",
    "\n",
    "RMSE = make_scorer(root_mean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# avalia o desempenho do modelo, retornando o valor do RMSE\n",
    "def evaluate_model_cv(model, X=X, y=y):\n",
    "    start = datetime.now()\n",
    "    kfold = KFold(n_splits=10, random_state=42)\n",
    "    results = cross_val_score(model, X, y, cv=kfold, scoring=RMSE, verbose=1)\n",
    "    end = datetime.now()\n",
    "    elapsed = int((end - start).total_seconds() * 1000)\n",
    "    score = (-1) * results.mean()\n",
    "    stddev = results.std()\n",
    "    print(model, '\\nScore: %.2f (+/- %.2f) [%5s ms]' % (score, stddev, elapsed))\n",
    "    return score, stddev, elapsed"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# executa o teste definitivo (contra a solução)\n",
    "from datetime import datetime\n",
    "\n",
    "X_test = pd.get_dummies(pd.read_csv('abalone-test.csv', index_col='id'))\n",
    "y_real = pd.read_csv('abalone-solution.csv', index_col='id')\n",
    "\n",
    "names = []\n",
    "scores = []\n",
    "stddevs = []\n",
    "times = []\n",
    "\n",
    "def evaluate_model_cv(model):\n",
    "    start = datetime.now()\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = root_mean_squared_error(y_real, y_pred)\n",
    "    end = datetime.now()\n",
    "    elapsed = int((end - start).total_seconds() * 1000)\n",
    "    print(model, '\\nScore: %.2f [%5s ms]' % (score, elapsed))\n",
    "    names.append(model)\n",
    "    scores.append(score)\n",
    "    stddevs.append(0)\n",
    "    times.append(elapsed)\n",
    "    return score, 0, elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faz o ajuste fino do modelo, calculando os melhores hiperparâmetros\n",
    "def fine_tune_model(model, params, X=X, y=y):\n",
    "  print('\\nFine Tuning Model:')\n",
    "  print(model, \"\\nparams:\", params)\n",
    "  kfold = KFold(n_splits=10, random_state=42)\n",
    "  grid = GridSearchCV(estimator=model, param_grid=params, scoring=RMSE, cv=kfold, verbose=1)\n",
    "  grid.fit(X, y)\n",
    "  print('\\nGrid Best Score: %.2f' % (grid.best_score_ * (-1)))\n",
    "  print('Best Params:', grid.best_params_)\n",
    "  return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação e ajuste fino de cada modelo preditivo\n",
    "\n",
    "-  https://scikit-learn.org/stable/modules/classes.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalized Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=True) \n",
      "Score: 2.21 (+/- 0.17) [ 1329 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.3s finished\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression(n_jobs=-1, fit_intercept=True, normalize=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = dict(\n",
    "    fit_intercept=[True, False],\n",
    "    normalize=[True, False]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(n_jobs=-1, random_state=42, multi_class='auto', C=1000, solver='newton-cg')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = dict(\n",
    "    solver=['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    C=np.logspace(-3, 3, 7)\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=7,\n",
      "             normalize=True, precompute='auto', tol=None) \n",
      "Score: 2.21 (+/- 0.17) [  876 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "model = OrthogonalMatchingPursuit(n_nonzero_coefs=7, fit_intercept=True, normalize=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = dict(\n",
    "    n_nonzero_coefs=[None, 1, 2, 5, 7],\n",
    "    fit_intercept=[True, False],\n",
    "    normalize=[True, False]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassiveAggressiveRegressor(C=0.1, average=False, early_stopping=False,\n",
      "              epsilon=0.1, fit_intercept=True, loss='epsilon_insensitive',\n",
      "              max_iter=1000, n_iter=None, n_iter_no_change=5,\n",
      "              random_state=42, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Score: 2.19 [   90 ms]\n"
     ]
    }
   ],
   "source": [
    "model = PassiveAggressiveRegressor(random_state=42, C=0.1, fit_intercept=True, max_iter=1000, tol=0.001)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {\n",
    "    'C': [0.1, 0.2, 0.4, 0.8, 1.0],\n",
    "    'fit_intercept': [True, False],\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron(alpha=1e-06, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "      fit_intercept=True, max_iter=1000, n_iter=None, n_iter_no_change=5,\n",
      "      n_jobs=None, penalty=None, random_state=42, shuffle=True, tol=0.001,\n",
      "      validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Score: 2.82 [  450 ms]\n"
     ]
    }
   ],
   "source": [
    "model = Perceptron(random_state=42, penalty='l2', alpha=1e-3, fit_intercept=True, max_iter=1000, tol=1e-3)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#penalty=None, alpha=0.0001, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, eta0=1.0,\n",
    "#n_jobs=None, random_state=0, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, \n",
    "#class_weight=None, warm_start=False\n",
    "\n",
    "params = {\n",
    "    'penalty': [None, 'l2', 'l1', 'elasticnet'],\n",
    "    'alpha': np.logspace(-6, -1, 6),\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANSACRegressor(base_estimator=None, is_data_valid=None, is_model_valid=None,\n",
      "        loss='absolute_loss', max_skips=inf, max_trials=100,\n",
      "        min_samples=0.75, random_state=42, residual_threshold=None,\n",
      "        stop_n_inliers=inf, stop_probability=0.99, stop_score=inf) \n",
      "Score: 2.23 (+/- 0.19) [14636 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   14.6s finished\n"
     ]
    }
   ],
   "source": [
    "model = RANSACRegressor(random_state=42, min_samples=0.75)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#base_estimator=None, min_samples=None, residual_threshold=None, is_data_valid=None, is_model_valid=None,\n",
    "#max_trials=100, max_skips=inf, stop_n_inliers=inf, stop_score=inf, stop_probability=0.99, loss=’absolute_loss’,\n",
    "#random_state=None\n",
    "\n",
    "params = {\n",
    "    'min_samples': [None, 0.1, 0.25, 0.5, 0.75, 1.0]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=0.1, copy_X=True, fit_intercept=False, max_iter=None,\n",
      "   normalize=True, random_state=42, solver='auto', tol=0.001) \n",
      "Score: 2.19 [   32 ms]\n"
     ]
    }
   ],
   "source": [
    "model = Ridge(random_state=42, alpha=0.1, fit_intercept=False, normalize=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, solver=’auto’,\n",
    "#random_state=None\n",
    "\n",
    "params = {\n",
    "    'alpha': np.logspace(-6, -1, 6),\n",
    "    'fit_intercept': [True, False],\n",
    "    'normalize': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor(alpha=1e-06, average=False, early_stopping=False, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='invscaling', loss='squared_loss', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, penalty=None, power_t=0.25,\n",
      "       random_state=42, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "       verbose=0, warm_start=False) \n",
      "Score: 2.21 [  769 ms]\n"
     ]
    }
   ],
   "source": [
    "model = SGDRegressor(random_state=42, alpha=1e-06, fit_intercept=True, penalty=None, tol=1e-3)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#loss=’squared_loss’, penalty=’l2’, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001,\n",
    "#shuffle=True, verbose=0, epsilon=0.1, random_state=None, learning_rate=’invscaling’, eta0=0.01, power_t=0.25,\n",
    "#early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, warm_start=False, average=False\n",
    "\n",
    "params = {\n",
    "    'penalty': [None, 'l2', 'l1', 'elasticnet'],\n",
    "    'alpha': np.logspace(-6, -1, 6),\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TheilSenRegressor(random_state=42, n_jobs=-1, fit_intercept=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#fit_intercept=True, copy_X=True, max_subpopulation=10000.0, n_subsamples=None, \n",
    "#max_iter=300, tol=0.001, random_state=None, n_jobs=None, verbose=False\n",
    "\n",
    "params = {\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor(criterion='mse', max_depth=6, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=0.25, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=42, splitter='best') \n",
      "Score: 2.44 [   42 ms]\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(random_state=42, max_depth=6, min_samples_split=0.25)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#criterion=’mse’, splitter=’best’, max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, \n",
    "#min_impurity_decrease=0.0, min_impurity_split=None, presort=False\n",
    "\n",
    "params = dict(\n",
    "    max_depth=[4, 6, 8, 10, 12, 14],\n",
    "    min_samples_split=[0.25, 0.5, 0.75, 1.0]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianProcessRegressor(alpha=0.01, copy_X_train=True, kernel=None,\n",
      "             n_restarts_optimizer=0, normalize_y=False,\n",
      "             optimizer='fmin_l_bfgs_b', random_state=42) \n",
      "Score: 2.03 [15765 ms]\n"
     ]
    }
   ],
   "source": [
    "model = GaussianProcessRegressor(random_state=42, alpha=0.01, normalize_y=False)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#kernel=None, alpha=1e-10, optimizer=’fmin_l_bfgs_b’, n_restarts_optimizer=0,\n",
    "#normalize_y=False, copy_X_train=True, random_state=None\n",
    "\n",
    "params = dict(\n",
    "    alpha=np.logspace(-6, -1, 6),\n",
    "    normalize_y=[True, False]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KernelRidge(alpha=1, coef0=1, degree=3, gamma=None, kernel='linear',\n",
      "      kernel_params=None) \n",
      "Score: 2.16 [ 5830 ms]\n"
     ]
    }
   ],
   "source": [
    "model = KernelRidge(alpha=0.1)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#alpha=1, kernel=’linear’, gamma=None, degree=3, coef0=1, kernel_params=None\n",
    "\n",
    "params = dict(\n",
    "    alpha=np.logspace(-6, -1, 6)\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=0.1) \n",
      "Score: 5.80 [   83 ms]\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB(var_smoothing=0.001)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#priors=None, var_smoothing=1e-09\n",
    "\n",
    "params = dict(\n",
    "    var_smoothing=np.logspace(-9, -1, 5)\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=-1, n_neighbors=13, p=2,\n",
      "          weights='distance') \n",
      "Score: 2.24 (+/- 0.21) [ 1283 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.3s finished\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsRegressor(n_jobs=-1, n_neighbors=11, weights='distance')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#n_neighbors=5, weights=’uniform’, algorithm=’auto’, leaf_size=30, p=2, metric=’minkowski’,\n",
    "#metric_params=None, n_jobs=None\n",
    "\n",
    "params = {\n",
    "    'n_neighbors': [1, 3, 5, 7, 9, 11, 13],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False) \n",
      "Score: 2.23 [ 2179 ms]\n"
     ]
    }
   ],
   "source": [
    "model = SVR(gamma='auto', kernel='linear')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#kernel=’rbf’, degree=3, gamma=’auto_deprecated’, coef0=0.0, tol=0.001, C=1.0, \n",
    "#epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1\n",
    "\n",
    "params = {\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']#, 'precomputed']\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(50,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False) \n",
      "Score: 2.03 [28134 ms]\n"
     ]
    }
   ],
   "source": [
    "model = MLPRegressor(random_state=42, max_iter=500,\n",
    "                     activation='logistic', hidden_layer_sizes=(50,), solver='lbfgs')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#hidden_layer_sizes=(100, ), activation=’relu’, solver=’adam’, alpha=0.0001, batch_size=’auto’, \n",
    "#learning_rate=’constant’, learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, \n",
    "#random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, \n",
    "#early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10\n",
    "\n",
    "params = dict(\n",
    "    hidden_layer_sizes=[(100,), (50,), (50,2)],\n",
    "    activation=['identity', 'logistic', 'tanh', 'relu'],\n",
    "    solver=['lbfgs', 'sgd', 'adam']\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=7,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=2,\n",
      "           oob_score=False, random_state=42, verbose=0, warm_start=False) \n",
      "Score: 2.11 [ 2405 ms]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(random_state=42, n_jobs=-1, n_estimators=100, max_depth=7)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#n_estimators=’warn’, criterion=’mse’, max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#min_weight_fraction_leaf=0.0, max_features=’auto’, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, \n",
    "#verbose=0, warm_start=False\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [5, 10, 25, 50, 75, 100],\n",
    "    'max_depth': [None, 3, 5, 7, 9, 11, 13]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.05, loss='ls', max_depth=6, max_features=1.0,\n",
      "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "             min_impurity_split=None, min_samples_leaf=1,\n",
      "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "             n_estimators=100, n_iter_no_change=None, presort='auto',\n",
      "             random_state=42, subsample=0.4, tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Score: 2.11 [ 1954 ms]\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(random_state=42, learning_rate=0.05, n_estimators=100,\n",
    "                                  subsample=0.4, max_depth=6, max_features=1.0)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#loss=’ls’, learning_rate=0.1, n_estimators=100, subsample=1.0, criterion=’friedman_mse’, min_samples_split=2,\n",
    "#min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, \n",
    "#min_impurity_split=None, init=None, random_state=None, max_features=None, alpha=0.9, verbose=0, \n",
    "#max_leaf_nodes=None, warm_start=False, presort=’auto’, validation_fraction=0.1, n_iter_no_change=None, \n",
    "#tol=0.0001\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[100, 250, 500],\n",
    "    max_features=[0.75, 0.85, 1.0],\n",
    "    max_depth=[4, 6, 8, 10],\n",
    "    learning_rate=[0.05, 0.1, 0.15],\n",
    "    subsample=[0.4, 0.6, 0.8]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features=1.0, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "          min_impurity_split=None, min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=2,\n",
      "          oob_score=False, random_state=42, verbose=0, warm_start=False) \n",
      "Score: 2.12 [ 4931 ms]\n"
     ]
    }
   ],
   "source": [
    "model = ExtraTreesRegressor(random_state=42, n_jobs=-1, n_estimators=200, max_features=1.0)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#n_estimators=’warn’, criterion=’mse’, max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#min_weight_fraction_leaf=0.0, max_features=’auto’, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#min_impurity_split=None, bootstrap=False, oob_score=False, n_jobs=None, random_state=None, verbose=0,\n",
    "#warm_start=False\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[50, 75, 100, 200],\n",
    "    max_features=['auto', 0.75, 0.85, 1.0]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingRegressor(base_estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best'),\n",
      "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=10, n_jobs=2, oob_score=False,\n",
      "         random_state=42, verbose=0, warm_start=False) \n",
      "Score: 2.26 [ 6857 ms]\n"
     ]
    }
   ],
   "source": [
    "model = BaggingRegressor(random_state=42, n_jobs=-1, base_estimator=DecisionTreeRegressor())\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#base_estimator=None, n_estimators=10, max_samples=1.0, max_features=1.0, bootstrap=True, \n",
    "#bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=None, random_state=None, verbose=0\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[50, 75, 100, 200],\n",
    "    max_features=[0.5, 0.75, 1.0]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best'),\n",
      "         learning_rate=1.0, loss='linear', n_estimators=100,\n",
      "         random_state=42) \n",
      "Score: 2.17 [ 8507 ms]\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostRegressor(random_state=42, n_estimators=100, base_estimator=DecisionTreeRegressor())\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "# base_estimator=None, n_estimators=50, learning_rate=1.0, algorithm=’SAMME.R’, random_state=None\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[50, 75, 100, 200]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outros algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost\n",
    "\n",
    "- https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# https://machinelearningmastery.com/how-to-fix-futurewarning-messages-in-scikit-learn/\n",
    "\n",
    "# import warnings filter\n",
    "#from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "#simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# ignore all caught warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=5, min_child_weight=1, missing=None, n_estimators=50,\n",
      "       n_jobs=2, nthread=None, objective='reg:squarederror',\n",
      "       random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=None, subsample=1, verbosity=1) \n",
      "Score: 2.10 [  625 ms]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "model = XGBRegressor(random_state=42, n_jobs=-1, learning_rate=0.1,\n",
    "                     n_estimators=50, max_depth=5, objective='reg:squarederror')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#max_depth=3, learning_rate=0.1, n_estimators=100, verbosity=1, silent=None, objective='reg:squarederror',\n",
    "#booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, \n",
    "#colsample_bytree=1, colsample_bylevel=1, colsample_bynode=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, \n",
    "#base_score=0.5, random_state=0, seed=None, missing=None, importance_type='gain'\n",
    "\n",
    "params = dict(\n",
    "    max_depth=[3, 5, 7, 9],\n",
    "    n_estimators=[50, 75, 100, 200]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Learning Model\n",
    "\n",
    "- https://towardsdatascience.com/automate-stacking-in-python-fc3e7834772e\n",
    "- https://github.com/vecxoz/vecstack"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "?stacking"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from vecstack import stacking\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Make train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize 1-st level models\n",
    "ensemble_models = [\n",
    "    RandomForestRegressor(random_state=42, n_jobs=2, n_estimators=100, max_depth=7),\n",
    "    GradientBoostingRegressor(random_state=42, learning_rate=0.05, n_estimators=100,\n",
    "                                  subsample=0.4, max_depth=6, max_features=1.0),\n",
    "    #ExtraTreesRegressor(random_state=42, n_jobs=2, n_estimators=100)\n",
    "    XGBRegressor(random_state=42, n_jobs=2, learning_rate=0.1,\n",
    "                     n_estimators=50, max_depth=5, objective='reg:squarederror')\n",
    "]\n",
    "\n",
    "# Compute stacking features\n",
    "S_train, S_test = stacking(ensemble_models, X_train, y_train, X_test,\n",
    "    regression=True, metric=mean_squared_error, n_folds=4, shuffle=True,\n",
    "    random_state=42, verbose=2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "S_train, S_test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Initialize 2-nd level model\n",
    "model = XGBRegressor(random_state=42, n_jobs=2, learning_rate=0.1,\n",
    "                     n_estimators=50, max_depth=5, objective='reg:squarederror')\n",
    "\n",
    "# Fit 2-nd level model\n",
    "model = model.fit(S_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(S_test)\n",
    "\n",
    "# Final prediction score\n",
    "print('Final prediction score: [%.8f]' % mean_squared_error(y_test, y_pred) ** 0.5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# https://towardsdatascience.com/ensemble-learning-using-scikit-learn-85c4531ff86a\n",
    "\n",
    "# classe não disponível no pacote :P\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "model = VotingRegressor(\n",
    "    RandomForestRegressor(random_state=42, n_jobs=2, n_estimators=100, max_depth=7),\n",
    "    GradientBoostingRegressor(random_state=42),\n",
    "    ExtraTreesRegressor(random_state=42, n_jobs=2, n_estimators=100)\n",
    ")\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#estimators, weights=None, n_jobs=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação final entre os algoritmos"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "models = []\n",
    "\n",
    "# Generalized Linear Models\n",
    "models.append(('LinReg', LinearRegression(n_jobs=2, fit_intercept=False, normalize=True)))\n",
    "models.append(('LogReg', LogisticRegression(n_jobs=2, random_state=42, multi_class='auto', C=1000, solver='newton-cg')))\n",
    "models.append(('OMP', OrthogonalMatchingPursuit(n_nonzero_coefs=8, fit_intercept=True, normalize=True)))\n",
    "models.append(('PAR', PassiveAggressiveRegressor(random_state=42, C=0.1, fit_intercept=True, max_iter=1000, tol=0.001)))\n",
    "models.append(('PP', Perceptron(random_state=42, penalty='l2', alpha=1e-5, fit_intercept=True, max_iter=1000, tol=1e-3)))\n",
    "models.append(('RANSAC', RANSACRegressor(random_state=42, min_samples=0.75)))\n",
    "models.append(('Ridge', Ridge(random_state=42, alpha=0.1, fit_intercept=False, normalize=True)))\n",
    "models.append(('SGD', SGDRegressor(random_state=42, alpha=1e-06, fit_intercept=True, penalty=None, tol=1e-3)))\n",
    "models.append(('TSR', TheilSenRegressor(random_state=42, n_jobs=2, fit_intercept=True)))\n",
    "\n",
    "# Decision Trees\n",
    "models.append(('DTR', DecisionTreeRegressor(random_state=42, max_depth=4, min_samples_split=0.25)))\n",
    "\n",
    "# Gaussian Processes\n",
    "models.append(('GPR', GaussianProcessRegressor(random_state=42, alpha=0.01, normalize_y=True)))\n",
    "\n",
    "# Kernel Ridge Regression\n",
    "models.append(('KRR', KernelRidge()))\n",
    "\n",
    "# Naïve Bayes\n",
    "models.append(('GNB', GaussianNB(var_smoothing=0.1)))\n",
    "\n",
    "# Nearest Neighbors\n",
    "models.append(('kNN', KNeighborsRegressor(n_jobs=2, n_neighbors=13, weights='distance')))\n",
    "\n",
    "# Support Vector Machines\n",
    "models.append(('SVM', SVR(gamma='auto', kernel='linear')))\n",
    "\n",
    "# Neural network models\n",
    "models.append(('MLP', MLPRegressor(random_state=42, max_iter=500,\n",
    "                     activation='logistic', hidden_layer_sizes=(50,), solver='lbfgs')))\n",
    "\n",
    "# Ensemble Methods\n",
    "models.append(('RFR', RandomForestRegressor(random_state=42, n_jobs=2, n_estimators=100, max_depth=7)))\n",
    "models.append(('GBR', GradientBoostingRegressor(random_state=42, learning_rate=0.05, n_estimators=100,\n",
    "                                  subsample=0.4, max_depth=6, max_features=1.0)))\n",
    "models.append(('ETR', ExtraTreesRegressor(random_state=42, n_jobs=2, n_estimators=200, max_features=1.0)))\n",
    "models.append(('BDTR', BaggingRegressor(random_state=42, n_jobs=2, base_estimator=DecisionTreeRegressor())))\n",
    "models.append(('ABDTR', AdaBoostRegressor(random_state=42, n_estimators=100, base_estimator=DecisionTreeRegressor())))\n",
    "\n",
    "# XGBoost\n",
    "models.append(('XGBR', XGBRegressor(random_state=42, n_jobs=2, learning_rate=0.1,\n",
    "                                    n_estimators=50, max_depth=5, objective='reg:squarederror')))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "results = []\n",
    "names = []\n",
    "scores = []\n",
    "stddevs = []\n",
    "times = []\n",
    "\n",
    "for name, model in models:\n",
    "    score, stddev, elapsed = evaluate_model_cv(model, X=X, y=y)\n",
    "    results.append((score, stddev))\n",
    "    names.append(name)\n",
    "    scores.append(score)\n",
    "    stddevs.append(stddev)\n",
    "    times.append(elapsed)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# comparar desempenhos dos algoritmos\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "fig.suptitle('Comparação dos Algoritmos')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "results_df = pd.DataFrame({'Model': names, 'Score': scores, 'Std Dev': stddevs, 'Time (ms)': times})\n",
    "results_df.sort_values(by='Score', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
