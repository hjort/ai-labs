{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação dos pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar pacotes necessários\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir parâmetros extras\n",
    "#pd.set_option('precision', 2)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar pacotes usados na seleção do modelo e na medição da precisão\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# importar os pacotes necessários para os algoritmos de regressão\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "#from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lars\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import RadiusNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import NuSVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga dos dados de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2765, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>sex</th>\n",
       "      <th>rings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>0.535</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>0.3285</td>\n",
       "      <td>0.1690</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>M</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>0.630</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.3205</td>\n",
       "      <td>0.5945</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>F</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>0.565</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.5795</td>\n",
       "      <td>0.1825</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>M</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.7865</td>\n",
       "      <td>0.3320</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>I</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3445</th>\n",
       "      <td>0.495</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.5780</td>\n",
       "      <td>0.2545</td>\n",
       "      <td>0.1305</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>I</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      length  diameter  height  whole_weight  shucked_weight  viscera_weight  \\\n",
       "id                                                                             \n",
       "2758   0.535     0.430   0.155        0.7845          0.3285          0.1690   \n",
       "1384   0.630     0.485   0.170        1.3205          0.5945          0.3450   \n",
       "1131   0.565     0.435   0.150        0.9900          0.5795          0.1825   \n",
       "3726   0.500     0.395   0.145        0.7865          0.3320          0.1815   \n",
       "3445   0.495     0.400   0.145        0.5780          0.2545          0.1305   \n",
       "\n",
       "      shell_weight sex  rings  \n",
       "id                             \n",
       "2758        0.2450   M     10  \n",
       "1384        0.3450   F      9  \n",
       "1131        0.2060   M      8  \n",
       "3726        0.2455   I      8  \n",
       "3445        0.1645   I      8  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carregar arquivo de dados de treino\n",
    "#filename = 'abalone-train.csv'\n",
    "filename = 'abalone-train-o1-0.50.csv' # removidos outliers\n",
    "#filename = 'https://github.com/hjort/ai-labs/raw/master/kaggle/serpro-abalone/abalone-train.csv'\n",
    "data = pd.read_csv(filename, index_col='id')\n",
    "\n",
    "# mostrar tamanho\n",
    "print(data.shape)\n",
    "\n",
    "# mostrar alguns exemplos de registros\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2765 entries, 2758 to 852\n",
      "Data columns (total 3 columns):\n",
      "sex_F    2765 non-null uint8\n",
      "sex_I    2765 non-null uint8\n",
      "sex_M    2765 non-null uint8\n",
      "dtypes: uint8(3)\n",
      "memory usage: 29.7 KB\n"
     ]
    }
   ],
   "source": [
    "data_sex = pd.get_dummies(data['sex'], prefix='sex')\n",
    "\n",
    "cols = {}\n",
    "for col in data_sex.columns:\n",
    "    cols[col] = col.lower()\n",
    "data.rename(columns=cols, inplace=True)\n",
    "\n",
    "data_sex.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>rings</th>\n",
       "      <th>sex_F</th>\n",
       "      <th>sex_I</th>\n",
       "      <th>sex_M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>0.535</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>0.3285</td>\n",
       "      <td>0.1690</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>0.630</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.3205</td>\n",
       "      <td>0.5945</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>0.565</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.5795</td>\n",
       "      <td>0.1825</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.7865</td>\n",
       "      <td>0.3320</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3445</th>\n",
       "      <td>0.495</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.5780</td>\n",
       "      <td>0.2545</td>\n",
       "      <td>0.1305</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      length  diameter  height  whole_weight  shucked_weight  viscera_weight  \\\n",
       "id                                                                             \n",
       "2758   0.535     0.430   0.155        0.7845          0.3285          0.1690   \n",
       "1384   0.630     0.485   0.170        1.3205          0.5945          0.3450   \n",
       "1131   0.565     0.435   0.150        0.9900          0.5795          0.1825   \n",
       "3726   0.500     0.395   0.145        0.7865          0.3320          0.1815   \n",
       "3445   0.495     0.400   0.145        0.5780          0.2545          0.1305   \n",
       "\n",
       "      shell_weight  rings  sex_F  sex_I  sex_M  \n",
       "id                                              \n",
       "2758        0.2450     10      0      0      1  \n",
       "1384        0.3450      9      1      0      0  \n",
       "1131        0.2060      8      0      0      1  \n",
       "3726        0.2455      8      0      1      0  \n",
       "3445        0.1645      8      0      1      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.join(data_sex)\n",
    "data.drop('sex', axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for sex in ['M', 'F', 'I']:\n",
    "    col = 'sex_' + sex\n",
    "    data[col] = data[col].astype('float')\n",
    "data['rings'] = data.rings.astype('float')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data.sex = data.sex.astype('category').cat.codes\n",
    "print(data.dtypes)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# excluir dados com valores inválidos\n",
    "outliers = np.concatenate((\n",
    "    data[data.height == 0.0].index,\n",
    "    data[(data['viscera_weight'] > 0.5) & (data['rings'] < 20 - 1.5)].index,\n",
    "    data[(data['viscera_weight'] < 0.5) & (data['rings'] > 25 - 1.5)].index,\n",
    "    data[(data['shell_weight'] > 0.6) & (data['rings'] < 25 - 1.5)].index,\n",
    "    data[(data['shell_weight'] < 0.8) & (data['rings'] > 25 - 1.5)].index,\n",
    "    data[(data['shucked_weight'] >= 1.0) & (data['rings'] < 20 - 1.5)].index,\n",
    "    data[(data['shucked_weight'] < 1.0)  & (data['rings'] > 20 - 1.5)].index,\n",
    "    data[(data['whole_weight'] >= 2.5) & (data['rings'] < 25 - 1.5)].index,\n",
    "    data[(data['whole_weight'] < 2.5)  & (data['rings'] > 25 - 1.5)].index,\n",
    "    data[(data['diameter'] < 0.1)  & (data['rings'] < 5 - 1.5)].index,\n",
    "    data[(data['diameter'] < 0.6)  & (data['rings'] > 25 - 1.5)].index,\n",
    "    data[(data['diameter'] >= 0.6) & (data['rings'] < 25 - 1.5)].index,\n",
    "    data[(data['height'] > 0.4) & (data['rings'] < 15 - 1.5)].index,\n",
    "    data[(data['height'] < 0.4) & (data['rings'] > 25 - 1.5)].index,\n",
    "    data[(data['length'] < 0.1)  & (data['rings'] < 5 - 1.5)].index,\n",
    "    data[(data['length'] < 0.8)  & (data['rings'] > 25 - 1.5)].index,\n",
    "    data[(data['length'] >= 0.8) & (data['rings'] < 25 - 1.5)].index\n",
    "), axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data[data.index.isin(outliers)].head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\"Número de outliers a serem removidos: %d\" % len(outliers))\n",
    "\n",
    "print(\"Antes:\", data.shape)\n",
    "data.drop(outliers, inplace=True)\n",
    "print(\"Depois:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma dos dados originais: (2765, 10) (2765,)\n"
     ]
    }
   ],
   "source": [
    "# definir dados de entrada\n",
    "\n",
    "X = data.drop(['rings'], axis=1) # tudo, exceto a coluna alvo\n",
    "y = data['rings'] # apenas a coluna alvo\n",
    "\n",
    "print('Forma dos dados originais:', X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento dos modelos preditivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "# cria função para cálculo do RMSE (REMQ)\n",
    "def root_mean_squared_error(ground_truth, predictions):\n",
    "    return mean_squared_error(ground_truth, predictions) ** 0.5\n",
    "\n",
    "RMSE = make_scorer(root_mean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# avalia o desempenho do modelo, retornando o valor do RMSE\n",
    "def evaluate_model_cv(model, X=X, y=y):\n",
    "    start = datetime.now()\n",
    "    kfold = KFold(n_splits=10, random_state=42)\n",
    "    results = cross_val_score(model, X, y, cv=kfold, scoring=RMSE, verbose=1)\n",
    "    end = datetime.now()\n",
    "    elapsed = int((end - start).total_seconds() * 1000)\n",
    "    score = (-1) * results.mean()\n",
    "    stddev = results.std()\n",
    "    print(model, '\\nScore: %.2f (+/- %.2f) [%5s ms]' % (score, stddev, elapsed))\n",
    "    return score, stddev, elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faz o ajuste fino do modelo, calculando os melhores hiperparâmetros\n",
    "def fine_tune_model(model, params, X=X, y=y):\n",
    "  print('\\nFine Tuning Model:')\n",
    "  print(model, \"\\nparams:\", params)\n",
    "\n",
    "  kfold = KFold(n_splits=10, random_state=42)\n",
    "  grid = GridSearchCV(estimator=model, param_grid=params, scoring=RMSE, cv=kfold, verbose=1)\n",
    "  grid.fit(X, y)\n",
    "\n",
    "  print('\\nGrid Best Score: %.2f' % (grid.best_score_ * (-1)))\n",
    "  print('Best Params:', grid.best_params_)\n",
    " \n",
    "  return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação e ajuste fino de cada modelo preditivo\n",
    "\n",
    "-  https://scikit-learn.org/stable/modules/classes.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalized Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=2, normalize=True) \n",
      "Score: 2.16 (+/- 0.17) [  790 ms]\n",
      "\n",
      "Fine Tuning Model:\n",
      "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=2, normalize=True) \n",
      "params: {'fit_intercept': [True, False], 'normalize': [True, False]}\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "\n",
      "Grid Best Score: 2.16\n",
      "Best Params: {'fit_intercept': True, 'normalize': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=42, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=LinearRegression(copy_X=True, fit_intercept=False, n_jobs=2, normalize=True),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'fit_intercept': [True, False], 'normalize': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(root_mean_squared_error, greater_is_better=False),\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression(n_jobs=2, fit_intercept=False, normalize=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = dict(\n",
    "    fit_intercept=[True, False],\n",
    "    normalize=[True, False]\n",
    ")\n",
    "fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='auto', n_jobs=2,\n",
      "          penalty='l2', random_state=42, solver='newton-cg', tol=0.0001,\n",
      "          verbose=0, warm_start=False) \n",
      "Score: 2.37 (+/- 0.21) [520761 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  8.7min finished\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(n_jobs=2, random_state=42, multi_class='auto', C=1000, solver='newton-cg')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'C':np.logspace(-3,3,7)\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=8,\n",
      "             normalize=True, precompute='auto', tol=None) \n",
      "Score: 2.16 (+/- 0.17) [  659 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "model = OrthogonalMatchingPursuit(n_nonzero_coefs=8, fit_intercept=True, normalize=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {\n",
    "    'n_nonzero_coefs': [None, 1, 2, 4, 6, 8, 10],\n",
    "    'fit_intercept': [True, False],\n",
    "    'normalize': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassiveAggressiveRegressor(C=0.1, average=False, early_stopping=False,\n",
      "              epsilon=0.1, fit_intercept=True, loss='epsilon_insensitive',\n",
      "              max_iter=1000, n_iter=None, n_iter_no_change=5,\n",
      "              random_state=42, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Score: 2.22 (+/- 0.19) [  740 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "model = PassiveAggressiveRegressor(random_state=42, C=0.1, fit_intercept=True, max_iter=1000, tol=0.001)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {\n",
    "    'C': [0.1, 0.2, 0.4, 0.8, 1.0],\n",
    "    'fit_intercept': [True, False],\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron(alpha=1e-05, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "      fit_intercept=True, max_iter=1000, n_iter=None, n_iter_no_change=5,\n",
      "      n_jobs=None, penalty='l2', random_state=42, shuffle=True, tol=0.001,\n",
      "      validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Score: 3.81 (+/- 1.07) [ 3463 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    3.5s finished\n"
     ]
    }
   ],
   "source": [
    "model = Perceptron(random_state=42, penalty='l2', alpha=1e-5, fit_intercept=True, max_iter=1000, tol=1e-3)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#penalty=None, alpha=0.0001, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, eta0=1.0, n_jobs=None, \n",
    "#random_state=0, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, class_weight=None, warm_start=False\n",
    "\n",
    "params = {\n",
    "    'penalty': [None, 'l2', 'l1', 'elasticnet'],\n",
    "    'alpha': np.logspace(-6, -1, 6),\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANSACRegressor(base_estimator=None, is_data_valid=None, is_model_valid=None,\n",
      "        loss='absolute_loss', max_skips=inf, max_trials=100,\n",
      "        min_samples=0.75, random_state=42, residual_threshold=None,\n",
      "        stop_n_inliers=inf, stop_probability=0.99, stop_score=inf) \n",
      "Score: 2.19 (+/- 0.18) [12368 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   12.4s finished\n"
     ]
    }
   ],
   "source": [
    "model = RANSACRegressor(random_state=42, min_samples=0.75)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#base_estimator=None, min_samples=None, residual_threshold=None, is_data_valid=None, is_model_valid=None, max_trials=100, \n",
    "#max_skips=inf, stop_n_inliers=inf, stop_score=inf, stop_probability=0.99, loss=’absolute_loss’, random_state=None\n",
    "\n",
    "params = {\n",
    "    'min_samples': [None, 0.1, 0.25, 0.5, 0.75, 1.0]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=0.1, copy_X=True, fit_intercept=False, max_iter=None,\n",
      "   normalize=True, random_state=42, solver='auto', tol=0.001) \n",
      "Score: 2.16 (+/- 0.17) [  355 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "model = Ridge(random_state=42, alpha=0.1, fit_intercept=False, normalize=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, solver=’auto’, random_state=None\n",
    "\n",
    "params = {\n",
    "    'alpha': np.logspace(-6, -1, 4),\n",
    "    'fit_intercept': [True, False],\n",
    "    'normalize': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor(alpha=1e-06, average=False, early_stopping=False, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='invscaling', loss='squared_loss', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, penalty=None, power_t=0.25,\n",
      "       random_state=42, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "       verbose=0, warm_start=False) \n",
      "Score: 2.24 (+/- 0.20) [ 7599 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    7.6s finished\n"
     ]
    }
   ],
   "source": [
    "model = SGDRegressor(random_state=42, alpha=1e-06, fit_intercept=True, penalty=None, tol=1e-3)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#loss=’squared_loss’, penalty=’l2’, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, \n",
    "#verbose=0, epsilon=0.1, random_state=None, learning_rate=’invscaling’, eta0=0.01, power_t=0.25, early_stopping=False, \n",
    "#validation_fraction=0.1, n_iter_no_change=5, warm_start=False, average=False\n",
    "\n",
    "params = {\n",
    "    'penalty': [None, 'l2', 'l1', 'elasticnet'],\n",
    "    'alpha': np.logspace(-6, -1, 4),\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheilSenRegressor(copy_X=True, fit_intercept=True, max_iter=300,\n",
      "         max_subpopulation=10000, n_jobs=2, n_subsamples=None,\n",
      "         random_state=42, tol=0.001, verbose=False) \n",
      "Score: 2.18 (+/- 0.17) [88550 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "model = TheilSenRegressor(random_state=42, n_jobs=2, fit_intercept=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#fit_intercept=True, copy_X=True, max_subpopulation=10000.0, n_subsamples=None, \n",
    "#max_iter=300, tol=0.001, random_state=None, n_jobs=None, verbose=False\n",
    "\n",
    "params = {\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor(criterion='mse', max_depth=4, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=0.25, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=42, splitter='best') \n",
      "Score: 2.42 (+/- 0.17) [  595 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(random_state=42, max_depth=4, min_samples_split=0.25)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#criterion=’mse’, splitter=’best’, max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, \n",
    "#min_impurity_decrease=0.0, min_impurity_split=None, presort=False\n",
    "\n",
    "params = dict(\n",
    "    max_depth=[4, 6, 8, 10, 12, 14],\n",
    "    min_samples_split=[0.25, 0.5, 0.75, 1.0]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianProcessRegressor(alpha=0.01, copy_X_train=True, kernel=None,\n",
      "             n_restarts_optimizer=0, normalize_y=True,\n",
      "             optimizer='fmin_l_bfgs_b', random_state=42) \n",
      "Score: 2.06 (+/- 0.16) [113911 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.9min finished\n"
     ]
    }
   ],
   "source": [
    "model = GaussianProcessRegressor(random_state=42, alpha=0.01, normalize_y=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#kernel=None, alpha=1e-10, optimizer=’fmin_l_bfgs_b’, n_restarts_optimizer=0,\n",
    "#normalize_y=False, copy_X_train=True, random_state=None\n",
    "\n",
    "params = dict(\n",
    "    alpha=np.logspace(-6, -1, 6),\n",
    "    normalize_y=[True, False]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KernelRidge(alpha=1, coef0=1, degree=3, gamma=None, kernel='linear',\n",
      "      kernel_params=None) \n",
      "Score: 2.17 (+/- 0.18) [62290 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.0min finished\n"
     ]
    }
   ],
   "source": [
    "model = KernelRidge()\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#alpha=1, kernel=’linear’, gamma=None, degree=3, coef0=1, kernel_params=None\n",
    "\n",
    "params = dict(\n",
    "    alpha=np.logspace(-6, -1, 4)\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=0.1) \n",
      "Score: 2.92 (+/- 0.21) [  742 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB(var_smoothing=0.1)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#priors=None, var_smoothing=1e-09\n",
    "\n",
    "params = dict(\n",
    "    var_smoothing=np.logspace(-9, -1, 5)\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=2, n_neighbors=13, p=2,\n",
      "          weights='distance') \n",
      "Score: 2.19 (+/- 0.18) [ 1407 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.4s finished\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsRegressor(n_jobs=2, n_neighbors=13, weights='distance')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#n_neighbors=5, weights=’uniform’, algorithm=’auto’, leaf_size=30, p=2, metric=’minkowski’,\n",
    "#metric_params=None, n_jobs=None\n",
    "\n",
    "params = {\n",
    "    'n_neighbors': [1, 3, 5, 7, 9, 11, 13],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False) \n",
      "Score: 2.29 (+/- 0.22) [18578 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   18.6s finished\n"
     ]
    }
   ],
   "source": [
    "model = SVR(gamma='auto', kernel='linear')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#kernel=’rbf’, degree=3, gamma=’auto_deprecated’, coef0=0.0, tol=0.001, C=1.0, \n",
    "#epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1\n",
    "\n",
    "params = {\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']#, 'precomputed']\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(50,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False) \n",
      "Score: 2.07 (+/- 0.14) [260216 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  4.3min finished\n"
     ]
    }
   ],
   "source": [
    "model = MLPRegressor(random_state=42, max_iter=500,\n",
    "                     activation='logistic', hidden_layer_sizes=(50,), solver='lbfgs')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#hidden_layer_sizes=(100, ), activation=’relu’, solver=’adam’, alpha=0.0001, batch_size=’auto’, \n",
    "#learning_rate=’constant’, learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, \n",
    "#random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, \n",
    "#early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10\n",
    "\n",
    "params = dict(\n",
    "    hidden_layer_sizes=[(100,), (50,), (50,2)],\n",
    "    activation=['identity', 'logistic', 'tanh', 'relu'],\n",
    "    solver=['lbfgs', 'sgd', 'adam']\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=7,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=2,\n",
      "           oob_score=False, random_state=42, verbose=0, warm_start=False) \n",
      "Score: 2.11 (+/- 0.18) [30721 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   30.7s finished\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(random_state=42, n_jobs=2, n_estimators=100, max_depth=7)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#n_estimators=’warn’, criterion=’mse’, max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#min_weight_fraction_leaf=0.0, max_features=’auto’, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, \n",
    "#verbose=0, warm_start=False\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [5, 10, 25, 50, 75, 100],\n",
    "    'max_depth': [None, 3, 5, 7, 9, 11, 13]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.05, loss='ls', max_depth=6, max_features=10,\n",
      "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "             min_impurity_split=None, min_samples_leaf=1,\n",
      "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "             n_estimators=100, n_iter_no_change=None, presort='auto',\n",
      "             random_state=42, subsample=0.4, tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Score: 2.11 (+/- 0.19) [22549 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   22.5s finished\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(random_state=42, learning_rate=0.05, n_estimators=100,\n",
    "                                  subsample=0.4, max_depth=6, max_features=10)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#loss=’ls’, learning_rate=0.1, n_estimators=100, subsample=1.0, criterion=’friedman_mse’, min_samples_split=2,\n",
    "#min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, \n",
    "#min_impurity_split=None, init=None, random_state=None, max_features=None, alpha=0.9, verbose=0, \n",
    "#max_leaf_nodes=None, warm_start=False, presort=’auto’, validation_fraction=0.1, n_iter_no_change=None, \n",
    "#tol=0.0001\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[100, 250, 500, 750, 1000],\n",
    "    max_features=[5, 7, 10],\n",
    "    max_depth=[4, 6, 8, 10, 12, 14],\n",
    "    learning_rate=[0.05, 0.1, 0.15, 0.2],\n",
    "    subsample=[0.4, 0.6, 0.8]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features=5, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "          min_impurity_split=None, min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=2,\n",
      "          oob_score=False, random_state=42, verbose=0, warm_start=False) \n",
      "Score: 2.16 (+/- 0.18) [54819 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   54.8s finished\n"
     ]
    }
   ],
   "source": [
    "model = ExtraTreesRegressor(random_state=42, n_jobs=2, n_estimators=200, max_features=5)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#n_estimators=’warn’, criterion=’mse’, max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#min_weight_fraction_leaf=0.0, max_features=’auto’, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#min_impurity_split=None, bootstrap=False, oob_score=False, n_jobs=None, random_state=None, verbose=0,\n",
    "#warm_start=False\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[10, 25, 50, 75, 100, 200],\n",
    "    max_features=['auto', 5, 7, 10]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingRegressor(base_estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best'),\n",
      "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=10, n_jobs=2, oob_score=False,\n",
      "         random_state=42, verbose=0, warm_start=False) \n",
      "Score: 2.23 (+/- 0.16) [ 6684 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    6.7s finished\n"
     ]
    }
   ],
   "source": [
    "model = BaggingRegressor(random_state=42, n_jobs=2, base_estimator=DecisionTreeRegressor())\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#base_estimator=None, n_estimators=10, max_samples=1.0, max_features=1.0, bootstrap=True, \n",
    "#bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=None, random_state=None, verbose=0\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[10, 25, 50, 75, 100, 200],\n",
    "    max_features=[0.25, 0.5, 0.75, 1.0]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best'),\n",
      "         learning_rate=1.0, loss='linear', n_estimators=100,\n",
      "         random_state=42) \n",
      "Score: 2.21 (+/- 0.18) [91656 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostRegressor(random_state=42, n_estimators=100, base_estimator=DecisionTreeRegressor())\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "# base_estimator=None, n_estimators=50, learning_rate=1.0, algorithm=’SAMME.R’, random_state=None\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[10, 25, 50, 75, 100, 200]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outros algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost\n",
    "\n",
    "- https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# https://machinelearningmastery.com/how-to-fix-futurewarning-messages-in-scikit-learn/\n",
    "\n",
    "# import warnings filter\n",
    "#from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "#simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# ignore all caught warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=5, min_child_weight=1, missing=None, n_estimators=50,\n",
      "       n_jobs=2, nthread=None, objective='reg:squarederror',\n",
      "       random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=None, subsample=1, verbosity=1) \n",
      "Score: 2.12 (+/- 0.19) [10499 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   10.5s finished\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "model = XGBRegressor(random_state=42, n_jobs=2, learning_rate=0.1,\n",
    "                     n_estimators=50, max_depth=5, objective='reg:squarederror')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#max_depth=3, learning_rate=0.1, n_estimators=100, verbosity=1, silent=None, objective='reg:squarederror',\n",
    "#booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, \n",
    "#colsample_bytree=1, colsample_bylevel=1, colsample_bynode=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, \n",
    "#base_score=0.5, random_state=0, seed=None, missing=None, importance_type='gain'\n",
    "\n",
    "params = dict(\n",
    "    max_depth=[3, 5, 7, 9],\n",
    "    n_estimators=[10, 25, 50, 75, 100, 200]\n",
    ")\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Learning Model\n",
    "\n",
    "- https://towardsdatascience.com/automate-stacking-in-python-fc3e7834772e\n",
    "- https://github.com/vecxoz/vecstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `stacking` not found.\n"
     ]
    }
   ],
   "source": [
    "?stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [regression]\n",
      "metric:       [mean_squared_error]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [3]\n",
      "\n",
      "model  0:     [RandomForestRegressor]\n",
      "    fold  0:  [4.73216718]\n",
      "    fold  1:  [4.48528372]\n",
      "    fold  2:  [5.02094836]\n",
      "    fold  3:  [4.10123267]\n",
      "    ----\n",
      "    MEAN:     [4.58490798] + [0.33752159]\n",
      "    FULL:     [4.58490798]\n",
      "\n",
      "model  1:     [GradientBoostingRegressor]\n",
      "    fold  0:  [4.66884884]\n",
      "    fold  1:  [4.65844942]\n",
      "    fold  2:  [5.12333226]\n",
      "    fold  3:  [4.17008911]\n",
      "    ----\n",
      "    MEAN:     [4.65517991] + [0.33714880]\n",
      "    FULL:     [4.65517991]\n",
      "\n",
      "model  2:     [XGBRegressor]\n",
      "    fold  0:  [4.83896669]\n",
      "    fold  1:  [4.61894690]\n",
      "    fold  2:  [5.15058295]\n",
      "    fold  3:  [4.13417700]\n",
      "    ----\n",
      "    MEAN:     [4.68566838] + [0.37021630]\n",
      "    FULL:     [4.68566838]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from vecstack import stacking\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Make train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize 1-st level models\n",
    "ensemble_models = [\n",
    "    RandomForestRegressor(random_state=42, n_jobs=2, n_estimators=100, max_depth=7),\n",
    "    GradientBoostingRegressor(random_state=42, learning_rate=0.05, n_estimators=100,\n",
    "                                  subsample=0.4, max_depth=6, max_features=10),\n",
    "    #ExtraTreesRegressor(random_state=42, n_jobs=2, n_estimators=100)\n",
    "    XGBRegressor(random_state=42, n_jobs=2, learning_rate=0.1,\n",
    "                     n_estimators=50, max_depth=5, objective='reg:squarederror')\n",
    "]\n",
    "\n",
    "# Compute stacking features\n",
    "S_train, S_test = stacking(ensemble_models, X_train, y_train, X_test,\n",
    "    regression=True, metric=mean_squared_error, n_folds=4, shuffle=True,\n",
    "    random_state=42, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[12.31833105, 11.69747812, 12.68404007],\n",
       "        [11.45626636, 11.17892388, 11.37965488],\n",
       "        [11.75404377, 11.84437972, 11.22117138],\n",
       "        ...,\n",
       "        [12.48817476, 12.57029237, 11.92391682],\n",
       "        [10.17736923,  9.53090679, 10.29664326],\n",
       "        [10.12971066, 10.67933643, 10.18423462]]),\n",
       " array([[ 9.85703878,  9.97297847,  9.95121884],\n",
       "        [ 5.85910624,  5.64034164,  5.69652641],\n",
       "        [ 6.6974868 ,  7.00318037,  6.79120958],\n",
       "        ...,\n",
       "        [11.84384918, 12.01627972, 11.88080597],\n",
       "        [ 6.19123322,  6.62303397,  6.48677218],\n",
       "        [ 7.26670572,  7.3058647 ,  7.26412404]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_train, S_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction score: [2.07896046]\n"
     ]
    }
   ],
   "source": [
    "# Initialize 2-nd level model\n",
    "model = XGBRegressor(random_state=42, n_jobs=2, learning_rate=0.1,\n",
    "                     n_estimators=50, max_depth=5, objective='reg:squarederror')\n",
    "\n",
    "# Fit 2-nd level model\n",
    "model = model.fit(S_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(S_test)\n",
    "\n",
    "# Final prediction score\n",
    "print('Final prediction score: [%.8f]' % mean_squared_error(y_test, y_pred) ** 0.5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# https://towardsdatascience.com/ensemble-learning-using-scikit-learn-85c4531ff86a\n",
    "\n",
    "# classe não disponível no pacote :P\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "model = VotingRegressor(\n",
    "    RandomForestRegressor(random_state=42, n_jobs=2, n_estimators=100, max_depth=7),\n",
    "    GradientBoostingRegressor(random_state=42),\n",
    "    ExtraTreesRegressor(random_state=42, n_jobs=2, n_estimators=100)\n",
    ")\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#estimators, weights=None, n_jobs=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação final entre os algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "# Generalized Linear Models\n",
    "models.append(('LinReg', LinearRegression(n_jobs=2, fit_intercept=False, normalize=True)))\n",
    "models.append(('LogReg', LogisticRegression(n_jobs=2, random_state=42, multi_class='auto', C=1000, solver='newton-cg')))\n",
    "models.append(('OMP', OrthogonalMatchingPursuit(n_nonzero_coefs=8, fit_intercept=True, normalize=True)))\n",
    "models.append(('PAR', PassiveAggressiveRegressor(random_state=42, C=0.1, fit_intercept=True, max_iter=1000, tol=0.001)))\n",
    "models.append(('PP', Perceptron(random_state=42, penalty='l2', alpha=1e-5, fit_intercept=True, max_iter=1000, tol=1e-3)))\n",
    "models.append(('RANSAC', RANSACRegressor(random_state=42, min_samples=0.75)))\n",
    "models.append(('Ridge', Ridge(random_state=42, alpha=0.1, fit_intercept=False, normalize=True)))\n",
    "models.append(('SGD', SGDRegressor(random_state=42, alpha=1e-06, fit_intercept=True, penalty=None, tol=1e-3)))\n",
    "models.append(('TSR', TheilSenRegressor(random_state=42, n_jobs=2, fit_intercept=True)))\n",
    "\n",
    "# Decision Trees\n",
    "models.append(('DTR', DecisionTreeRegressor(random_state=42, max_depth=4, min_samples_split=0.25)))\n",
    "\n",
    "# Gaussian Processes\n",
    "models.append(('GPR', GaussianProcessRegressor(random_state=42, alpha=0.01, normalize_y=True)))\n",
    "\n",
    "# Kernel Ridge Regression\n",
    "models.append(('KRR', KernelRidge()))\n",
    "\n",
    "# Naïve Bayes\n",
    "models.append(('GNB', GaussianNB(var_smoothing=0.1)))\n",
    "\n",
    "# Nearest Neighbors\n",
    "models.append(('kNN', KNeighborsRegressor(n_jobs=2, n_neighbors=13, weights='distance')))\n",
    "\n",
    "# Support Vector Machines\n",
    "models.append(('SVM', SVR(gamma='auto', kernel='linear')))\n",
    "\n",
    "# Neural network models\n",
    "models.append(('MLP', MLPRegressor(random_state=42, max_iter=500,\n",
    "                     activation='logistic', hidden_layer_sizes=(50,), solver='lbfgs')))\n",
    "\n",
    "# Ensemble Methods\n",
    "models.append(('RFR', RandomForestRegressor(random_state=42, n_jobs=2, n_estimators=100, max_depth=7)))\n",
    "models.append(('GBR', GradientBoostingRegressor(random_state=42, learning_rate=0.05, n_estimators=100,\n",
    "                                  subsample=0.4, max_depth=6, max_features=10)))\n",
    "models.append(('ETR', ExtraTreesRegressor(random_state=42, n_jobs=2, n_estimators=200, max_features=5)))\n",
    "models.append(('BDTR', BaggingRegressor(random_state=42, n_jobs=2, base_estimator=DecisionTreeRegressor())))\n",
    "models.append(('ABDTR', AdaBoostRegressor(random_state=42, n_estimators=100, base_estimator=DecisionTreeRegressor())))\n",
    "\n",
    "# XGBoost\n",
    "models.append(('XGBR', XGBRegressor(random_state=42, n_jobs=2, learning_rate=0.1,\n",
    "                                    n_estimators=50, max_depth=5, objective='reg:squarederror')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=2, normalize=True) \n",
      "Score: 2.16 (+/- 0.17) [  450 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  7.6min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='auto', n_jobs=2,\n",
      "          penalty='l2', random_state=42, solver='newton-cg', tol=0.0001,\n",
      "          verbose=0, warm_start=False) \n",
      "Score: 2.37 (+/- 0.21) [456814 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=8,\n",
      "             normalize=True, precompute='auto', tol=None) \n",
      "Score: 2.16 (+/- 0.17) [  540 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassiveAggressiveRegressor(C=0.1, average=False, early_stopping=False,\n",
      "              epsilon=0.1, fit_intercept=True, loss='epsilon_insensitive',\n",
      "              max_iter=1000, n_iter=None, n_iter_no_change=5,\n",
      "              random_state=42, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Score: 2.22 (+/- 0.19) [  818 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron(alpha=1e-05, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "      fit_intercept=True, max_iter=1000, n_iter=None, n_iter_no_change=5,\n",
      "      n_jobs=None, penalty='l2', random_state=42, shuffle=True, tol=0.001,\n",
      "      validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Score: 3.81 (+/- 1.07) [ 3457 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   12.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANSACRegressor(base_estimator=None, is_data_valid=None, is_model_valid=None,\n",
      "        loss='absolute_loss', max_skips=inf, max_trials=100,\n",
      "        min_samples=0.75, random_state=42, residual_threshold=None,\n",
      "        stop_n_inliers=inf, stop_probability=0.99, stop_score=inf) \n",
      "Score: 2.19 (+/- 0.18) [12108 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=0.1, copy_X=True, fit_intercept=False, max_iter=None,\n",
      "   normalize=True, random_state=42, solver='auto', tol=0.001) \n",
      "Score: 2.16 (+/- 0.17) [  358 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    7.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor(alpha=1e-06, average=False, early_stopping=False, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='invscaling', loss='squared_loss', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, penalty=None, power_t=0.25,\n",
      "       random_state=42, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
      "       verbose=0, warm_start=False) \n",
      "Score: 2.24 (+/- 0.20) [ 7573 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheilSenRegressor(copy_X=True, fit_intercept=True, max_iter=300,\n",
      "         max_subpopulation=10000, n_jobs=2, n_subsamples=None,\n",
      "         random_state=42, tol=0.001, verbose=False) \n",
      "Score: 2.18 (+/- 0.17) [88606 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor(criterion='mse', max_depth=4, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=0.25, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=42, splitter='best') \n",
      "Score: 2.42 (+/- 0.17) [  561 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianProcessRegressor(alpha=0.01, copy_X_train=True, kernel=None,\n",
      "             n_restarts_optimizer=0, normalize_y=True,\n",
      "             optimizer='fmin_l_bfgs_b', random_state=42) \n",
      "Score: 2.06 (+/- 0.16) [106398 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   51.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KernelRidge(alpha=1, coef0=1, degree=3, gamma=None, kernel='linear',\n",
      "      kernel_params=None) \n",
      "Score: 2.17 (+/- 0.18) [51932 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=0.1) \n",
      "Score: 2.92 (+/- 0.21) [  713 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=2, n_neighbors=13, p=2,\n",
      "          weights='distance') \n",
      "Score: 2.19 (+/- 0.18) [ 1326 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   18.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False) \n",
      "Score: 2.29 (+/- 0.22) [18587 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  4.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='logistic', alpha=0.0001, batch_size='auto',\n",
      "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(50,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False) \n",
      "Score: 2.07 (+/- 0.14) [257159 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   32.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=7,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=2,\n",
      "           oob_score=False, random_state=42, verbose=0, warm_start=False) \n",
      "Score: 2.11 (+/- 0.18) [32120 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   22.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.05, loss='ls', max_depth=6, max_features=10,\n",
      "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "             min_impurity_split=None, min_samples_leaf=1,\n",
      "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "             n_estimators=100, n_iter_no_change=None, presort='auto',\n",
      "             random_state=42, subsample=0.4, tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Score: 2.11 (+/- 0.19) [22549 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   52.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features=5, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "          min_impurity_split=None, min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=2,\n",
      "          oob_score=False, random_state=42, verbose=0, warm_start=False) \n",
      "Score: 2.16 (+/- 0.18) [52917 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingRegressor(base_estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best'),\n",
      "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
      "         max_samples=1.0, n_estimators=10, n_jobs=2, oob_score=False,\n",
      "         random_state=42, verbose=0, warm_start=False) \n",
      "Score: 2.23 (+/- 0.16) [ 6054 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best'),\n",
      "         learning_rate=1.0, loss='linear', n_estimators=100,\n",
      "         random_state=42) \n",
      "Score: 2.21 (+/- 0.18) [91761 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=5, min_child_weight=1, missing=None, n_estimators=50,\n",
      "       n_jobs=2, nthread=None, objective='reg:squarederror',\n",
      "       random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=None, subsample=1, verbosity=1) \n",
      "Score: 2.12 (+/- 0.19) [ 8563 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    8.6s finished\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "scores = []\n",
    "stddevs = []\n",
    "times = []\n",
    "\n",
    "for name, model in models:\n",
    "    score, stddev, elapsed = evaluate_model_cv(model, X=X, y=y)\n",
    "    results.append((score, stddev))\n",
    "    names.append(name)\n",
    "    scores.append(score)\n",
    "    stddevs.append(stddev)\n",
    "    times.append(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# comparar desempenhos dos algoritmos\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "fig.suptitle('Comparação dos Algoritmos')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Time (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GPR</td>\n",
       "      <td>2.064180</td>\n",
       "      <td>0.162498</td>\n",
       "      <td>106398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MLP</td>\n",
       "      <td>2.074386</td>\n",
       "      <td>0.135121</td>\n",
       "      <td>257159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RFR</td>\n",
       "      <td>2.110647</td>\n",
       "      <td>0.182089</td>\n",
       "      <td>32120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GBR</td>\n",
       "      <td>2.114125</td>\n",
       "      <td>0.185441</td>\n",
       "      <td>22549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBR</td>\n",
       "      <td>2.121650</td>\n",
       "      <td>0.191928</td>\n",
       "      <td>8563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ETR</td>\n",
       "      <td>2.159682</td>\n",
       "      <td>0.176824</td>\n",
       "      <td>52917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OMP</td>\n",
       "      <td>2.161869</td>\n",
       "      <td>0.172695</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>2.162257</td>\n",
       "      <td>0.174285</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>2.162596</td>\n",
       "      <td>0.172837</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KRR</td>\n",
       "      <td>2.173249</td>\n",
       "      <td>0.184312</td>\n",
       "      <td>51932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TSR</td>\n",
       "      <td>2.179362</td>\n",
       "      <td>0.165131</td>\n",
       "      <td>88606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>kNN</td>\n",
       "      <td>2.185862</td>\n",
       "      <td>0.184093</td>\n",
       "      <td>1326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RANSAC</td>\n",
       "      <td>2.189280</td>\n",
       "      <td>0.183554</td>\n",
       "      <td>12108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ABDTR</td>\n",
       "      <td>2.205942</td>\n",
       "      <td>0.183363</td>\n",
       "      <td>91761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PAR</td>\n",
       "      <td>2.216816</td>\n",
       "      <td>0.192804</td>\n",
       "      <td>818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BDTR</td>\n",
       "      <td>2.234895</td>\n",
       "      <td>0.164890</td>\n",
       "      <td>6054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SGD</td>\n",
       "      <td>2.238786</td>\n",
       "      <td>0.201706</td>\n",
       "      <td>7573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVM</td>\n",
       "      <td>2.285285</td>\n",
       "      <td>0.216068</td>\n",
       "      <td>18587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>2.371233</td>\n",
       "      <td>0.209825</td>\n",
       "      <td>456814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DTR</td>\n",
       "      <td>2.421294</td>\n",
       "      <td>0.170657</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GNB</td>\n",
       "      <td>2.915350</td>\n",
       "      <td>0.207296</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PP</td>\n",
       "      <td>3.810843</td>\n",
       "      <td>1.068366</td>\n",
       "      <td>3457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model     Score   Std Dev  Time (ms)\n",
       "10     GPR  2.064180  0.162498     106398\n",
       "15     MLP  2.074386  0.135121     257159\n",
       "16     RFR  2.110647  0.182089      32120\n",
       "17     GBR  2.114125  0.185441      22549\n",
       "21    XGBR  2.121650  0.191928       8563\n",
       "18     ETR  2.159682  0.176824      52917\n",
       "2      OMP  2.161869  0.172695        540\n",
       "6    Ridge  2.162257  0.174285        358\n",
       "0   LinReg  2.162596  0.172837        450\n",
       "11     KRR  2.173249  0.184312      51932\n",
       "8      TSR  2.179362  0.165131      88606\n",
       "13     kNN  2.185862  0.184093       1326\n",
       "5   RANSAC  2.189280  0.183554      12108\n",
       "20   ABDTR  2.205942  0.183363      91761\n",
       "3      PAR  2.216816  0.192804        818\n",
       "19    BDTR  2.234895  0.164890       6054\n",
       "7      SGD  2.238786  0.201706       7573\n",
       "14     SVM  2.285285  0.216068      18587\n",
       "1   LogReg  2.371233  0.209825     456814\n",
       "9      DTR  2.421294  0.170657        561\n",
       "12     GNB  2.915350  0.207296        713\n",
       "4       PP  3.810843  1.068366       3457"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame({'Model': names, 'Score': scores, 'Std Dev': stddevs, 'Time (ms)': times})\n",
    "results_df.sort_values(by='Score', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
