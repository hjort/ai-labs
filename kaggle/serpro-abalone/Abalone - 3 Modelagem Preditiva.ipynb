{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação dos pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar pacotes necessários\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir parâmetros extras\n",
    "#pd.set_option('precision', 2)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar pacotes usados na seleção do modelo e na medição da precisão\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# importar os pacotes necessários para os algoritmos de regressão\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "#from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lars\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import RadiusNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import NuSVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga dos dados de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2784, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>rings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>M</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>0.3285</td>\n",
       "      <td>0.1690</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>F</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.3205</td>\n",
       "      <td>0.5945</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>M</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.5795</td>\n",
       "      <td>0.1825</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>I</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.7865</td>\n",
       "      <td>0.3320</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3445</th>\n",
       "      <td>I</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.5780</td>\n",
       "      <td>0.2545</td>\n",
       "      <td>0.1305</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sex  length  diameter  height  whole_weight  shucked_weight  \\\n",
       "id                                                                 \n",
       "2758   M   0.535     0.430   0.155        0.7845          0.3285   \n",
       "1384   F   0.630     0.485   0.170        1.3205          0.5945   \n",
       "1131   M   0.565     0.435   0.150        0.9900          0.5795   \n",
       "3726   I   0.500     0.395   0.145        0.7865          0.3320   \n",
       "3445   I   0.495     0.400   0.145        0.5780          0.2545   \n",
       "\n",
       "      viscera_weight  shell_weight  rings  \n",
       "id                                         \n",
       "2758          0.1690        0.2450     10  \n",
       "1384          0.3450        0.3450      9  \n",
       "1131          0.1825        0.2060      8  \n",
       "3726          0.1815        0.2455      8  \n",
       "3445          0.1305        0.1645      8  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carregar arquivo de dados de treino\n",
    "data = pd.read_csv('abalone-train.csv', index_col='id')\n",
    "\n",
    "# mostrar tamanho\n",
    "print(data.shape)\n",
    "\n",
    "# mostrar alguns exemplos de registros\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2784 entries, 2758 to 852\n",
      "Data columns (total 3 columns):\n",
      "sex_F    2784 non-null uint8\n",
      "sex_I    2784 non-null uint8\n",
      "sex_M    2784 non-null uint8\n",
      "dtypes: uint8(3)\n",
      "memory usage: 29.9 KB\n"
     ]
    }
   ],
   "source": [
    "data_sex = pd.get_dummies(data['sex'], prefix='sex')\n",
    "\n",
    "cols = {}\n",
    "for col in data_sex.columns:\n",
    "    cols[col] = col.lower()\n",
    "data.rename(columns=cols, inplace=True)\n",
    "\n",
    "data_sex.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>rings</th>\n",
       "      <th>sex_F</th>\n",
       "      <th>sex_I</th>\n",
       "      <th>sex_M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>0.535</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>0.3285</td>\n",
       "      <td>0.1690</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>0.630</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.3205</td>\n",
       "      <td>0.5945</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>0.565</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.5795</td>\n",
       "      <td>0.1825</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.7865</td>\n",
       "      <td>0.3320</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3445</th>\n",
       "      <td>0.495</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.5780</td>\n",
       "      <td>0.2545</td>\n",
       "      <td>0.1305</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      length  diameter  height  whole_weight  shucked_weight  viscera_weight  \\\n",
       "id                                                                             \n",
       "2758   0.535     0.430   0.155        0.7845          0.3285          0.1690   \n",
       "1384   0.630     0.485   0.170        1.3205          0.5945          0.3450   \n",
       "1131   0.565     0.435   0.150        0.9900          0.5795          0.1825   \n",
       "3726   0.500     0.395   0.145        0.7865          0.3320          0.1815   \n",
       "3445   0.495     0.400   0.145        0.5780          0.2545          0.1305   \n",
       "\n",
       "      shell_weight  rings  sex_F  sex_I  sex_M  \n",
       "id                                              \n",
       "2758        0.2450     10      0      0      1  \n",
       "1384        0.3450      9      1      0      0  \n",
       "1131        0.2060      8      0      0      1  \n",
       "3726        0.2455      8      0      1      0  \n",
       "3445        0.1645      8      0      1      0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.join(data_sex)\n",
    "data.drop('sex', axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for sex in ['M', 'F', 'I']:\n",
    "    col = 'sex_' + sex\n",
    "    data[col] = data[col].astype('float')\n",
    "data['rings'] = data.rings.astype('float')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data.sex = data.sex.astype('category').cat.codes\n",
    "print(data.dtypes)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[3996 2624 1206 1763 3715 2710 3427 1422 2709 2863  170 1204 4148 1759\n",
      " 2623 1052 3628 3149 2201  294  480 2108 4145  168 2274  169 1823 2265\n",
      "  358  166 2368 3715 2334  375 1985 2210 2161 2088 2090 2623  277 2157\n",
      " 1193 1052 1428 3149 2201  294  480 2544 1418 2624 1199 1206 1763 1756\n",
      " 3007 1417 3715 3713 2710 3427 1754 1202 2863 1821 1426 3961 2675 1193\n",
      " 1052  673  181  497  417  442  672  572  483 3149  469 2201  314 2277\n",
      " 3914  256 3140  530 2199    6  166 2459 2275 2202  293 2335  593 3193\n",
      " 3930  744 2334  674  351  375  294 2180 2344  431  372    9  480  232\n",
      "   83  675  664  478  433   33 2101  278 2176  582  428 2108 2305  355\n",
      " 3392  501  628  811 3244 3319 2351 1763 3715 2334 3149 2201  294  480\n",
      " 2108  236  238 3149 2201  294  480 2108 1763 3715 2334 3427 1985 4148\n",
      " 1052 1428 3992 1417 3149 2201  294  480 2108  236 3149 2201  294  480\n",
      " 2108 2334 1428]\n"
     ]
    }
   ],
   "source": [
    "# excluir dados com valores inválidos\n",
    "outliers = np.concatenate((\n",
    "    data[data.height == 0.0].index,\n",
    "    data[(data['viscera_weight'] > 0.5) & (data['rings'] < 20 - 1.5)].index,\n",
    "    data[(data['viscera_weight'] < 0.5) & (data['rings'] > 25 - 1.5)].index,\n",
    "    data[(data['shell_weight'] > 0.6) & (data['rings'] < 25- 1.5)].index,\n",
    "    data[(data['shell_weight'] < 0.8) & (data['rings'] > 25- 1.5)].index,\n",
    "    data[(data['shucked_weight'] >= 1.0) & (data['rings'] < 20- 1.5)].index,\n",
    "    data[(data['shucked_weight'] < 1.0)  & (data['rings'] > 20- 1.5)].index,\n",
    "    data[(data['whole_weight'] >= 2.5) & (data['rings'] < 25- 1.5)].index,\n",
    "    data[(data['whole_weight'] < 2.5)  & (data['rings'] > 25- 1.5)].index,\n",
    "    data[(data['diameter'] < 0.1)  & (data['rings'] < 5- 1.5)].index,\n",
    "    data[(data['diameter'] < 0.6)  & (data['rings'] > 25- 1.5)].index,\n",
    "    data[(data['diameter'] >= 0.6) & (data['rings'] < 25- 1.5)].index,\n",
    "    data[(data['height'] > 0.4) & (data['rings'] < 15- 1.5)].index,\n",
    "    data[(data['height'] < 0.4) & (data['rings'] > 25- 1.5)].index,\n",
    "    data[(data['length'] < 0.1)  & (data['rings'] < 5- 1.5)].index,\n",
    "    data[(data['length'] < 0.8)  & (data['rings'] > 25- 1.5)].index,\n",
    "    data[(data['length'] >= 0.8) & (data['rings'] < 25- 1.5)].index\n",
    "), axis=0)\n",
    "\n",
    "print(type(outliers))\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>rings</th>\n",
       "      <th>sex_F</th>\n",
       "      <th>sex_I</th>\n",
       "      <th>sex_M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4145</th>\n",
       "      <td>0.670</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.200</td>\n",
       "      <td>1.7405</td>\n",
       "      <td>0.6205</td>\n",
       "      <td>0.2970</td>\n",
       "      <td>0.6570</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.705</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.220</td>\n",
       "      <td>1.9810</td>\n",
       "      <td>0.8175</td>\n",
       "      <td>0.3085</td>\n",
       "      <td>0.7600</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2544</th>\n",
       "      <td>0.730</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.165</td>\n",
       "      <td>2.0165</td>\n",
       "      <td>1.0685</td>\n",
       "      <td>0.4180</td>\n",
       "      <td>0.4350</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>0.705</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.215</td>\n",
       "      <td>2.1410</td>\n",
       "      <td>1.0465</td>\n",
       "      <td>0.3830</td>\n",
       "      <td>0.5280</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>0.765</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.180</td>\n",
       "      <td>2.3980</td>\n",
       "      <td>1.1280</td>\n",
       "      <td>0.5120</td>\n",
       "      <td>0.5335</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      length  diameter  height  whole_weight  shucked_weight  viscera_weight  \\\n",
       "id                                                                             \n",
       "4145   0.670     0.525   0.200        1.7405          0.6205          0.2970   \n",
       "168    0.705     0.560   0.220        1.9810          0.8175          0.3085   \n",
       "2544   0.730     0.570   0.165        2.0165          1.0685          0.4180   \n",
       "1418   0.705     0.555   0.215        2.1410          1.0465          0.3830   \n",
       "2624   0.765     0.585   0.180        2.3980          1.1280          0.5120   \n",
       "\n",
       "      shell_weight  rings  sex_F  sex_I  sex_M  \n",
       "id                                              \n",
       "4145        0.6570     11      0      0      1  \n",
       "168         0.7600     14      0      0      1  \n",
       "2544        0.4350     10      1      0      0  \n",
       "1418        0.5280     11      0      0      1  \n",
       "2624        0.5335     12      0      0      1  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.index.isin(outliers)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171 outliers to be dropped\n",
      "before: (2784, 11)\n",
      "after: (2672, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"%d outliers to be dropped\" % len(outliers))\n",
    "\n",
    "print(\"before:\", data.shape)\n",
    "data.drop(outliers, inplace=True)\n",
    "print(\"after:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma dos dados originais: (2672, 10) (2672,)\n"
     ]
    }
   ],
   "source": [
    "# definir dados de entrada\n",
    "\n",
    "X = data.drop(['rings'], axis=1) # tudo, exceto a coluna alvo\n",
    "y = data['rings'] # apenas a coluna alvo\n",
    "\n",
    "print('Forma dos dados originais:', X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento dos modelos preditivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "def root_mean_squared_error(ground_truth, predictions):\n",
    "    return mean_squared_error(ground_truth, predictions) ** 0.5\n",
    "\n",
    "RMSE = make_scorer(root_mean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_cv(model, X=X, y=y):\n",
    "  kfold = KFold(n_splits=10, random_state=42)\n",
    "  results = cross_val_score(model, X, y, cv=kfold, scoring=RMSE, verbose=1)\n",
    "  score = (-1) * results.mean()\n",
    "  stddev = results.std()\n",
    "  print(model, '\\nCross-Validation Score: %.2f (+/- %.2f)' % (score, stddev))\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faz o ajuste fino do modelo, calculando os melhores hiperparâmetros\n",
    "def fine_tune_model(model, params, X=X, y=y):\n",
    "  print('\\nFine Tuning Model:')\n",
    "  print(model, \"\\nparams:\", params)\n",
    "\n",
    "  kfold = KFold(n_splits=10, random_state=42)\n",
    "  grid = GridSearchCV(estimator=model, param_grid=params, scoring=RMSE, cv=kfold, verbose=1)\n",
    "  grid.fit(X, y)\n",
    "\n",
    "  print('\\nGrid Best Score: %.2f' % (grid.best_score_ * (-1)))\n",
    "  print('Best Params:', grid.best_params_)\n",
    " \n",
    "  return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação e ajuste fino de cada modelo preditivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=2, normalize=True) \n",
      "Cross-Validation Score: 1.92 (+/- 0.16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression(n_jobs=2, fit_intercept=False, normalize=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {'fit_intercept':[True, False], 'normalize':[True, False]}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(n_jobs=2, random_state=42, multi_class='auto', C=1000, solver='newton-cg')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'C':np.logspace(-3,3,7)\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=8,\n",
      "             normalize=True, precompute='auto', tol=None) \n",
      "Cross-Validation Score: 2.23 (+/- 0.17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.4s finished\n"
     ]
    }
   ],
   "source": [
    "model = OrthogonalMatchingPursuit(n_nonzero_coefs=8, fit_intercept=True, normalize=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {\n",
    "    'n_nonzero_coefs': [None, 1, 2, 4, 6, 8, 10],\n",
    "    'fit_intercept': [True, False],\n",
    "    'normalize': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassiveAggressiveRegressor(C=0.2, average=False, early_stopping=False,\n",
      "              epsilon=0.1, fit_intercept=True, loss='epsilon_insensitive',\n",
      "              max_iter=None, n_iter=None, n_iter_no_change=5,\n",
      "              random_state=42, shuffle=True, tol=None,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Cross-Validation Score: 2.42 (+/- 0.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "model = PassiveAggressiveRegressor(random_state=42, C=0.2, fit_intercept=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {\n",
    "    'C': [0.1, 0.2, 0.4, 0.8, 1.0],\n",
    "    'fit_intercept': [True, False],\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron(alpha=0.01, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "      fit_intercept=True, max_iter=None, n_iter=None, n_iter_no_change=5,\n",
      "      n_jobs=None, penalty='l1', random_state=42, shuffle=True, tol=None,\n",
      "      validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Cross-Validation Score: 3.61 (+/- 0.35)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    4.7s finished\n"
     ]
    }
   ],
   "source": [
    "model = Perceptron(random_state=42, penalty='l1', alpha=0.01, fit_intercept=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#penalty=None, alpha=0.0001, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, eta0=1.0, n_jobs=None, \n",
    "#random_state=0, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, class_weight=None, warm_start=False\n",
    "\n",
    "params = {\n",
    "    'penalty': [None, 'l2', 'l1', 'elasticnet'],\n",
    "    'alpha': np.logspace(-6, -1, 6),\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANSACRegressor(base_estimator=None, is_data_valid=None, is_model_valid=None,\n",
      "        loss='absolute_loss', max_skips=inf, max_trials=100,\n",
      "        min_samples=0.75, random_state=42, residual_threshold=None,\n",
      "        stop_n_inliers=inf, stop_probability=0.99, stop_score=inf) \n",
      "Cross-Validation Score: 2.24 (+/- 0.18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   27.0s finished\n"
     ]
    }
   ],
   "source": [
    "model = RANSACRegressor(random_state=42, min_samples=0.75)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#base_estimator=None, min_samples=None, residual_threshold=None, is_data_valid=None, is_model_valid=None, max_trials=100, \n",
    "#max_skips=inf, stop_n_inliers=inf, stop_score=inf, stop_probability=0.99, loss=’absolute_loss’, random_state=None\n",
    "\n",
    "params = {\n",
    "    'min_samples': [None, 0.1, 0.25, 0.5, 0.75, 1.0]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=0.1, copy_X=True, fit_intercept=False, max_iter=None,\n",
      "   normalize=True, random_state=42, solver='auto', tol=0.001) \n",
      "Cross-Validation Score: 2.23 (+/- 0.17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "model = Ridge(random_state=42, alpha=0.1, fit_intercept=False, normalize=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, solver=’auto’, random_state=None\n",
    "\n",
    "params = {\n",
    "    'alpha': np.logspace(-6, -1, 4),\n",
    "    'fit_intercept': [True, False],\n",
    "    'normalize': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor(alpha=1e-06, average=False, early_stopping=False, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "       learning_rate='invscaling', loss='squared_loss', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, penalty=None, power_t=0.25,\n",
      "       random_state=42, shuffle=True, tol=None, validation_fraction=0.1,\n",
      "       verbose=0, warm_start=False) \n",
      "Cross-Validation Score: 2.69 (+/- 0.21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "model = SGDRegressor(random_state=42, alpha=1e-06, fit_intercept=False, penalty=None)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#loss=’squared_loss’, penalty=’l2’, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, \n",
    "#verbose=0, epsilon=0.1, random_state=None, learning_rate=’invscaling’, eta0=0.01, power_t=0.25, early_stopping=False, \n",
    "#validation_fraction=0.1, n_iter_no_change=5, warm_start=False, average=False\n",
    "\n",
    "params = {\n",
    "    'penalty': [None, 'l2', 'l1', 'elasticnet'],\n",
    "    'alpha': np.logspace(-6, -1, 4),\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c51e55c61cf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTheilSenRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevaluate_model_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#fit_intercept=True, copy_X=True, max_subpopulation=10000.0, n_subsamples=None,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#max_iter=300, tol=0.001, random_state=None, n_jobs=None, verbose=False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-9c79abb102f7>\u001b[0m in \u001b[0;36mevaluate_model_cv\u001b[0;34m(model, X, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_model_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRMSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mstddev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 240\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/theil_sen.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    381\u001b[0m             indices = [random_state.choice(n_samples, size=n_subsamples,\n\u001b[1;32m    382\u001b[0m                                            replace=False)\n\u001b[0;32m--> 383\u001b[0;31m                        for _ in range(self.n_subpopulation_)]\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/theil_sen.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    381\u001b[0m             indices = [random_state.choice(n_samples, size=n_subsamples,\n\u001b[1;32m    382\u001b[0m                                            replace=False)\n\u001b[0;32m--> 383\u001b[0;31m                        for _ in range(self.n_subpopulation_)]\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = TheilSenRegressor(random_state=42, n_jobs=2, fit_intercept=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#fit_intercept=True, copy_X=True, max_subpopulation=10000.0, n_subsamples=None, \n",
    "#max_iter=300, tol=0.001, random_state=None, n_jobs=None, verbose=False\n",
    "\n",
    "params = {\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=2, n_neighbors=11, p=2,\n",
      "          weights='distance') \n",
      "Cross-Validation Score: 2.24 (+/- 0.21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    8.1s finished\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsRegressor(n_jobs=2, n_neighbors=11, weights='distance')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#n_neighbors=5, weights=’uniform’, algorithm=’auto’, leaf_size=30, p=2, metric=’minkowski’, metric_params=None, n_jobs=None\n",
    "\n",
    "params = {\n",
    "    'n_neighbors': [1, 3, 5, 7, 9, 11, 13],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False) \n",
      "Cross-Validation Score: 2.35 (+/- 0.23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   19.0s finished\n"
     ]
    }
   ],
   "source": [
    "model = SVR(gamma='auto', kernel='linear')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#kernel=’rbf’, degree=3, gamma=’auto_deprecated’, coef0=0.0, tol=0.001, C=1.0, \n",
    "#epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1\n",
    "\n",
    "params = {\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']#, 'precomputed']\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=7,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=2,\n",
      "           oob_score=False, random_state=42, verbose=0, warm_start=False) \n",
      "Cross-Validation Score: 2.20 (+/- 0.20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   29.4s finished\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(random_state=42, n_jobs=2, n_estimators=100, max_depth=7)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#n_estimators=’warn’, criterion=’mse’, max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#min_weight_fraction_leaf=0.0, max_features=’auto’, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [5, 10, 25, 50, 75, 100],\n",
    "    'max_depth': [None, 3, 5, 7, 9, 11, 13]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/classes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
      "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "             min_impurity_split=None, min_samples_leaf=1,\n",
      "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "             n_estimators=100, n_iter_no_change=None, presort='auto',\n",
      "             random_state=42, subsample=1.0, tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Cross-Validation Score: 2.22 (+/- 0.20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   10.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.2246574460647914"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(random_state=42)\n",
    "evaluate_model_cv(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=42, splitter='best') \n",
      "Cross-Validation Score: 3.11 (+/- 0.19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.1109542059076007"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(random_state=42)\n",
    "evaluate_model_cv(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianProcessRegressor(alpha=1e-10, copy_X_train=True, kernel=None,\n",
      "             n_restarts_optimizer=0, normalize_y=False,\n",
      "             optimizer='fmin_l_bfgs_b', random_state=None) \n",
      "Cross-Validation Score: 44.61 (+/- 51.76)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44.609203304259225"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GaussianProcessRegressor()\n",
    "evaluate_model_cv(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False) \n",
      "Cross-Validation Score: 2.20 (+/- 0.19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.201780707817829"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLPRegressor(random_state=42)\n",
    "evaluate_model_cv(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação final entre os algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression(random_state=42, solver='lbfgs', multi_class='auto', max_iter=500, C=100)))\n",
    "models.append(('DT', DecisionTreeClassifier(random_state=42, criterion='gini', max_depth=11)))\n",
    "models.append(('KNN', KNeighborsClassifier(n_neighbors=1)))\n",
    "models.append(('SVM', SVC(random_state=42, C=10, gamma=0.1, kernel='rbf')))\n",
    "models.append(('RF', RandomForestClassifier(random_state=42, max_features='auto', n_estimators=10)))\n",
    "models.append(('SGD', SGDClassifier(random_state=42, max_iter=100, tol=0.1)))\n",
    "models.append(('NN', Perceptron(random_state=42, max_iter=100, tol=0.01)))\n",
    "models.append(('NB', GaussianNB(priors=None, var_smoothing=1e-08)))\n",
    "models.append(('LSVM', LinearSVC(random_state=42, max_iter=1000, C=10)))\n",
    "models.append(('ABDT', AdaBoostClassifier(DecisionTreeClassifier(random_state=42), n_estimators=5)))\n",
    "models.append(('GB', GradientBoostingClassifier(random_state=42, max_depth=3)))\n",
    "models.append(('MLP', MLPClassifier(random_state=42, solver='lbfgs', alpha=0.1, hidden_layer_sizes=(15,))))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis(solver='svd')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.964762 (0.047581)\n",
      "DT: 0.972857 (0.044673)\n",
      "KNN: 0.971905 (0.046969)\n",
      "SVM: 0.985714 (0.028571)\n",
      "RF: 0.965238 (0.047239)\n",
      "SGD: 0.923333 (0.066648)\n",
      "NN: 0.936667 (0.067312)\n",
      "NB: 0.971905 (0.046969)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSVM: 0.957619 (0.056922)\n",
      "ABDT: 0.965714 (0.045466)\n",
      "GB: 0.972381 (0.045115)\n",
      "MLP: 0.978571 (0.045737)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: 0.923333 (0.059608)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "scores = []\n",
    "stddevs = []\n",
    "\n",
    "for name, model in models:\n",
    "  kfold = KFold(n_splits=10, random_state=42)\n",
    "  cv_results = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')\n",
    "  results.append(cv_results)\n",
    "  names.append(name)\n",
    "  scores.append(cv_results.mean() * 100)\n",
    "  stddevs.append(cv_results.std() * 100)\n",
    "  msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "  print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEVCAYAAAAM3jVmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3X98XHWd7/HXm1AS+Wlru/6ghdYV3ZCKYLO4uxYFUUF0RdQrdHUFHxG2e23YS+taIO6lW22VfUhdKWgWbEV0G0BdvdWLApogZoVr06UgWIGCIi24FsrvUgj1c/84J+V0mMnMJNNJMuf9fDzy6Mz59f1+zznznu/5npmpIgIzM8uHvca6AmZmVj8OfTOzHHHom5nliEPfzCxHHPpmZjni0DczyxGHvlVF0hWSPruHtv1hSdcPM/9YSZv3RNkTnaTzJX11rOth459D34qSdKOkRyU116vMiPj3iHhnpg4h6TX1Kl+JsyXdIelpSZslfUvS6+tVh5GKiOUR8fGxroeNfw59exFJM4FjgADeW6cy965HOWV8CfgH4GxgCvBa4HvAu8eyUuWMk31nE4RD34r5KHALcAVw+nALSvqUpIckPSjp49neuaSDJF0paauk+yV9WtJe6bwzJP2npC9KegRYkk7rT+fflBZxm6SnJJ2aKXORpD+k5X4sM/0KSV+W9MN0nf+U9ApJ/5petfxa0lEl2nEY8AlgXkT0RsSzEbE9vfr4fJXteUzSfZL+Kp3+QFrf0wvq2i3pBklPSvqppEMz87+UrveEpPWSjsnMWyLp25K+KekJ4Ix02jfT+S3pvEfSuqyT9PJ03qskrZW0TdImSWcWbPeatI1PSrpTUvtwx98mHoe+FfNR4N/TvxOGAqOQpBOBhcDbgdcAxxYsshI4CHg18NZ0ux/LzH8TcB/wcmBZdsWIeEv68A0RsX9EXJ0+f0W6zYOBDuBSSZMzq34I+DQwFXgWuBn4r/T5t4EVJdp8PLA5In5RYn6l7bkdeBmwBrgK+HOSffMR4BJJ+2eW/zDwmbRuG0j295B1wJEkVxxrgG9JasnMPzltz0sL1oPkjfogYEZal/nAM+m8q4DNwKuADwLLJb0ts+5702VeCqwFLhlmf9gE5NC33UiaCxwKXBMR64F7gb8psfiHgK9FxJ0RsR1YktlOE3AacF5EPBkRvwUuAv42s/6DEbEyIp6PiGeozCCwNCIGI+Ja4CngdZn5342I9RGxA/gusCMiroyIncDVQNGePkk4PlSq0Arb85uI+FqmrBlpXZ+NiOuB50jeAIb834i4KSKeBbqAv5Q0AyAivhkRj6T75iKguaCdN0fE9yLij0X23WDantdExM50fzyRbvvNwOKI2BERG4Cvkrx5DemPiGvTNnwDeEOpfWITk0PfCp0OXB8RD6fP11B6iOdVwAOZ59nHU4FJwP2ZafeT9NCLLV+pRyLi+czz7UC29/zfmcfPFHmeXXa37QKvHKbcStpTWBYRMVz5u9ofEU8B20j2KZI+KWmjpMclPUbSc59abN0ivgFcB1yVDrv9i6RJ6ba3RcSTw7Th95nH24EW3zNoLA5920XSS0h672+V9HtJvwfOAd4gqViP7yFgeub5jMzjh0l6nIdmph0CbMk8H08/8foTYPowY9iVtKdau/ZXOuwzBXgwHb//FMmxmBwRLwUeB5RZt+S+S6+C/jkiDgf+CngPSW/+QWCKpANq2AabYBz6lvU+YCdwOMl48pFAK/Azdh8CGHIN8DFJrZL2Bf5paEY6PHANsEzSAelNyoXAN6uoz3+TjJ/vcRFxD/BloEfJ9wH2SW+Inibp3Bq1p9BJkuZK2odkbP+WiHgAOAB4HtgK7C3pfwMHVrpRScdJen06JPUEyZvVH9Nt/xz4XNq2I0jui4ymDTbBOPQt63SSMfrfRcTvh/5IbuZ9uPAyPyJ+CFwM9AGbSD7xA8kNVIBO4GmSm7X9JENFq6uozxLg6+knUD40wjZV42yStl4KPEZyP+MU4Pvp/NG2p9Aa4AKSYZ05JDd7IRma+RFwN8nwyw6qGwp7BclN3ieAjcBPSYZ8AOYBM0l6/d8FLoiIH4+iDTbByP+JitWKpFbgDqC5YNzdCki6guTTQp8e67pYvrinb6Mi6RRJzenHJi8Evu/ANxu/HPo2Wn8H/IFkKGQn8PdjWx0zG46Hd8zMcsQ9fTOzHHHom5nliEPfzCxHHPpmZjni0DczyxGHvplZjjj0zcxyxKFvZpYjDn0zsxxx6JuZ5YhD38wsRxz6ZmY54tA3M8sRh76ZWY6Mu//lfurUqTFz5syxroaZ2YSyfv36hyNiWrnlxl3oz5w5k4GBgbGuhpnZhCLp/kqW8/COmVmOOPTNzHLEoW9mliMOfTOzHHHom5nlSNnQl7Ra0h8k3VFiviRdLGmTpNslvTEz73RJ96R/p9ey4mZmjaazs5OWlhYk0dLSQmdnZ83LqKSnfwVw4jDz3wUclv6dBXwFQNIU4ALgTcDRwAWSJo+msmZmjaqzs5Pu7m6WL1/O008/zfLly+nu7q558JcN/Yi4Cdg2zCInA1dG4hbgpZJeCZwA3BAR2yLiUeAGhn/zMDPLrcsvv5wLL7yQhQsXsu+++7Jw4UIuvPBCLr/88pqWU4svZx0MPJB5vjmdVmr6i0g6i+QqgUMOOaR0SUsOGlkNlzxe5fJ1KKeR2lLPcjIklZwXESPe7pQpU3j00UerWmfy5Mls2zZc36iIRjs2ft2M6nx+9tlnmT9//m7T5s+fz6JFi0a8zWJUyYtD0kzgBxExu8i8HwCfj4j+9PlPgMXAsUBLRHw2nf5PwDMR8YXhympvb49S38iVVPWLebyuU6961ctYt2est+V1/LoZrZaWFpYvX87ChQt3TVuxYgXnn38+O3bsKLu+pPUR0V5uuVr09LcAMzLPp6fTtpAEf3b6jTUoz8ys4Zx55pksXrwYSHr43d3dLF68+EW9/9GqReivBRZIuorkpu3jEfGQpOuA5Zmbt+8EzqtBeWZmDWflypUAnH/++SxatIjm5mbmz5+/a3qtlA19ST0kPfapkjaTfCJnEkBEdAPXAicBm4DtwMfSedskfQZYl25qaURUOehpZpYfK1eurHnIFyob+hExr8z8AD5RYt5qYPXIqmZmZrXmb+SameWIQ9/MLEcc+mZmOeLQNzPLEYe+mVmOOPTNzHLEoW9mliMOfTOzHHHom5nliEPfzCxHHPo2oUyZMgVJL/oDik6XxJQpU8a41mbjRy1+ZdOsbh599NER/Z66mSXc0zczyxGHvplZjjj0zcxyxKFvZpYjDn0zsxxx6JuZ5YhD38wsRxz6ZmY54tA3M8sRh76ZWY449M3McsShb2aWIw59M7McceibmeWIQ9/MLEcc+mZmOeLQNzPLEYe+mVmOOPTNzHLEoW9mliMOfTOzHHHom5nliEPfzCxHHPpmZjni0Dczy5GKQl/SiZLukrRJ0rlF5h8q6SeSbpd0o6TpmXk7JW1I/9bWsvJmZladvcstIKkJuBR4B7AZWCdpbUT8KrPYF4ArI+Lrkt4GfA7423TeMxFxZI3rbWZmI1BJT/9oYFNE3BcRzwFXAScXLHM40Js+7isy38zMxoFKQv9g4IHM883ptKzbgPenj08BDpD0svR5i6QBSbdIel+xAiSdlS4zsHXr1iqqv+dIqupv8uTJ47IMG998Dli9lR3eqdAngUsknQHcBGwBdqbzDo2ILZJeDfRK+mVE3JtdOSIuAy4DaG9vjxrVacQiildBUsl5tSqj1uXY+OVzwMZCJaG/BZiReT49nbZLRDxI2tOXtD/wgYh4LJ23Jf33Pkk3AkcBu4W+mZnVRyXDO+uAwyTNkrQPcBqw26dwJE2VNLSt84DV6fTJkpqHlgHeDGRvAJuZWR2VDf2IeB5YAFwHbASuiYg7JS2V9N50sWOBuyTdDbwcWJZObwUGJN1GcoP38wWf+jEzq4rvg4yOxtu4YXt7ewwMDBSdN5JxzlqOjdZrnHUijufW69jUY52xPs9qvb3xup9Huk49tjURSVofEe3llvM3cs3McsShb2aWIw59M7McceibmeWIQ9/MLEcc+mZmOeLQNzPLEYe+mVmOOPTNzHLEoW9mliO1+mllMyRVtfx4/U2UuOBAWHJQ9euYVavK8+yF9R4feZkRMa7+5syZE6Uk1a3OSNapx7bGspwFCxZEc3NzANHc3BwLFizYY2XVui31OAfG+jyr9fbq1Z6x3m97+nWzZs2aaGtri7322iva2tpizZo1o95mLfcZMBAVZKx7+jnT2dlJd3c3F154IfPnz6e7u5vFixcDsHLlyjGuXXnuhdtY6Onpoauri1WrVjF37lz6+/vp6OgAYN68eWNcuypV8s5Qz79yPf1q/yZPnlzFe+jwaICefnNzc1x00UW7Tbvooouiubl5j5RX67aMZHvVrlOPMuq5vXq9bhr59dnW1ha9vb27Tevt7Y22trZRbbeW5xoV9vQn1E8rl7Inf1J1uHHqWpZZz3Kefvpp9t13313Ttm/fzn777bdH9uF4+Mnhkfy0crUmT57Mtm3bql6v0jInwrFp5HKamprYsWMHkyZN2jVtcHCQlpYWdu7cOcyaw6vlueafVq6R4d4xJ2I5zc3NdHd37zatu7ub5ubmmpYzkZU7FsWmjybwy5U53jpmedTa2kp/f/9u0/r7+2ltbR3Vdivpmdf6XHPo58yZZ57J4sWLWbFiBdu3b2fFihUsXryYM888c6yrZjZudXV10dHRQV9fH4ODg/T19dHR0UFXV9dYV616I3mn2ZN/w43pl0KdxtobhT+9U9/yx6t6taVRytkTn96pJTymb+PBRBzTr9e2xlojjLWPRTnjlcf0zczsRRz6ZmY54tA3M8sRh76ZWY449M3McsShb2aWIw59M7McceibmeWIQ9/MLEcc+mZmOeLQNzPLEYe+mVmOOPTNzHLEoW9mliMOfTOzHHHom5nliEPfzCxHHPpmZjlSUehLOlHSXZI2STq3yPxDJf1E0u2SbpQ0PTPvdEn3pH+n17LyZmZWnbKhL6kJuBR4F3A4ME/S4QWLfQG4MiKOAJYCn0vXnQJcALwJOBq4QNLk2lXfzMyqUUlP/2hgU0TcFxHPAVcBJxcsczjQmz7uy8w/AbghIrZFxKPADcCJo6+2mZmNRCWhfzDwQOb55nRa1m3A+9PHpwAHSHpZhesi6SxJA5IGtm7dWmndzcysSrW6kftJ4K2SbgXeCmwBdla6ckRcFhHtEdE+bdq0GlXJzMwK7V3BMluAGZnn09Npu0TEg6Q9fUn7Ax+IiMckbQGOLVj3xlHU18zMRqGSnv464DBJsyTtA5wGrM0uIGmqpKFtnQesTh9fB7xT0uT0Bu4702lmZjYGyoZ+RDwPLCAJ643ANRFxp6Slkt6bLnYscJeku4GXA8vSdbcBnyF541gHLE2nmZnZGFBEjHUddtPe3h4DAwNVrSOJ8dYOS9T62Ixke7WsQyOda/VqS6OVM15JWh8R7eWW8zdyzcxyxKFvZpYjDn0zsxxx6JuZ5YhD38wsRxz6ZmY54tA3M8sRh76ZWY449M3McsShb2aWIw59M7McqeSnlc3GFUlVLT95sv+HTrMhDn2bUEr9oFbef2zLrFIe3jEzyxGHvplZjjj0zcxyxKFvZpYjDn0zsxxx6JuZ5YhD38wsRxz6ZmY54tA3M8sRh34Fenp6mD17Nk1NTcyePZuenp6xrpKZ2Yj4ZxjK6Onpoauri1WrVjF37lz6+/vp6OgAYN68eWNcOzOz6rinX8ayZctYtWoVxx13HJMmTeK4445j1apVLFu2bKyrZmZWNY23H6lqb2+PgYGBqtbZkz+21dTUxI4dO5g0adKuaYODg7S0tLBz5849UmYjqdcPoTVaOfWwJ9sy3C+h1rLMepUzEUhaHxHt5ZZzT7+M1tZW+vv7d5vW399Pa2vrGNXIbPyLiJJ/E7GcRuLQL6Orq4uOjg76+voYHBykr6+Pjo4Ourq6xrpqZmZV843cMoZu1nZ2drJx40ZaW1tZtmyZb+Ka2YTkMX3boxptrL2RzrVGaot5TN/MzIpw6I8j/hKY+RwYv+pxbOpy/Ie7+z0Wf3PmzIlqJc2Y2NasWROzZs2K3t7eeO6556K3tzdmzZoVa9asGeuqjUq9jk0jlFPvc6ARXjf1Uo9jM9oygIGoIGPHPOQL//Ia+m1tbdHb27vbtN7e3mhraxujGtVGI4Rxvcqp9znQCK+beqnHsRltGZWG/oS9kTvclzJg4n0xo5G+BDYWx6YRvmhUj3Og0V439VKPYzPaMhr+Rm65d7OJppG+BNZox6ZebanHOdBox6Ze6nFs6pYBlVwO1PNvJMM7jaBRx/TrhQYYqvA5MH7lbkwfOBG4C9gEnFtk/iFAH3ArcDtwUjp9JvAMsCH96y5XVl5DPyI56G1tbbHXXntFW1ubX+xVaITQj/A5MJ7V49iMpoxKQ7/smL6kJuBu4B3AZmAdMC8ifpVZ5jLg1oj4iqTDgWsjYqakmcAPImJ2pVceI/lylpm/aGR5V8sx/aOBTRFxX0Q8B1wFnFywTAAHpo8PAh6sprJmZlYflYT+wcADmeeb02lZS4CPSNoMXAt0ZubNknSrpJ9KOmY0lTUzs9Gp1ad35gFXRMR04CTgG5L2Ah4CDomIo4CFwBpJBxauLOksSQOSBrZu3VqjKpmZWaFKQn8LMCPzfHo6LasDuAYgIm4GWoCpEfFsRDySTl8P3Au8trCAiLgsItojon3atGnVt8LMzCpSSeivAw6TNEvSPsBpwNqCZX4HHA8gqZUk9LdKmpbeCEbSq4HDgPtqVXkzM6tO2d/Tj4jnJS0ArgOagNURcaekpSQfEVoLLAIul3QOyU3dMyIiJL0FWCppEPgjMD8itu2x1piZ2bAm7M8wmGX5I5uWdw3/MwxmZlY9h76ZWY449M3McsShb2aWIw59M7McceibmeWIQ9/MLEcc+mZmOeLQNzPLEYe+mVmOOPTNzHLEoW9mliMOfTOzHHHom5nliEPfzCxHHPpmZjni0DczyxGHvplZjjj0zcxyxKFvZpYjDn0zsxxx6JuZ5YhD38wsRxz6ZmY54tA3M8sRh76ZWY449M3McsShb2aWIw59M7McceibmeWIQ9/MLEcc+mZmOeLQNzPLEYe+mVmOOPTNzHLEoW9mliMOfTOzHKko9CWdKOkuSZsknVtk/iGS+iTdKul2SSdl5p2XrneXpBNqWXkzM6vO3uUWkNQEXAq8A9gMrJO0NiJ+lVns08A1EfEVSYcD1wIz08enAW3Aq4AfS3ptROysdUPMzKy8Snr6RwObIuK+iHgOuAo4uWCZAA5MHx8EPJg+Phm4KiKejYjfAJvS7ZmZ2RioJPQPBh7IPN+cTstaAnxE0maSXn5nFeuamVmd1OpG7jzgioiYDpwEfENSxduWdJakAUkDW7durVGVzMysUCXBvAWYkXk+PZ2W1QFcAxARNwMtwNQK1yUiLouI9ohonzZtWuW1NzOzqlQS+uuAwyTNkrQPyY3ZtQXL/A44HkBSK0nob02XO01Ss6RZwGHAL2pVeTMzq07ZT+9ExPOSFgDXAU3A6oi4U9JSYCAi1gKLgMslnUNyU/eMiAjgTknXAL8Cngc+4U/umJmNHSXZPH60t7fHwMDAWFfDJhhJjLdz2ayeJK2PiPZyy/kbuWZmOeLQNzPLEYe+mVmOOPTNzHLEoW9mliMOfbMK9PT0MHv2bJqampg9ezY9PT1jXSVrQPU4z8p+Tt8s73p6eujq6mLVqlXMnTuX/v5+Ojo6AJg3b94Y184aRd3Os4gYV39z5swJs2olp/Ke0dbWFr29vbtN6+3tjba2tj1WpuXPaM8zki/Lls1YfznLJixJJefV8rxuampix44dTJo0ade0wcFBWlpa2LnTXzC32hjteeYvZ1nDG643U0utra309/fvNq2/v5/W1taalmP5Vq/zzKFvVkZXVxcdHR309fUxODhIX18fHR0ddHV1jXXVrIHU6zzzjVyzMoZuonV2drJx40ZaW1tZtmyZb+JaTdXrPPOYvplZA/CYvpmZvYhD38wsRxz6ZmY54tA3M8sRh76ZWY6Mu0/vSNoK3F/lalOBh/dAdVzOxCjD5YzfMlxO/co4NCKmlVto3IX+SEgaqOSjSi6n/uU0UlsarZxGakujlbMny/DwjplZjjj0zcxypFFC/zKXM27LaaS2NFo5jdSWRitnj5XREGP6ZmZWmUbp6ZuZWQUmXOhLeqrItCWStkjaIOlXkkb1s3SSdqbbulPSbZIWSdpL0gnp9A2SnpJ0V/r4ymrrLukkSXdLOjSt/3ZJf1Ji2ZB0Ueb5JyUtGaacrrTut6f1u0DS5wqWOVLSxvTxbyX9rGD+Bkl3VNKuzDpD++0OSd+X9NJ0+kxJz2T23QZJ+1Sx3cL2vEnS3pKWS7ons82uzDpFj2GF5ZXc3+WOVTUqKGfonP61pK+Uq3+J18brJN2YbmejpMsk7SvpEUkHFiz7PUmnSjojrdvbM/Pel077YObxn6Xzssf3Nkk/l/S6dN6xkh6XdGv6erlJ0nvSeV2ZY7cz8/jsMu18uaQ1ku6TtF7SzZJOyZS1IT1Xfpw9TpVI2/XNzPO9JW2V9IP0+RmSLimy3m8l/TIt93pJrximjHIZdo+k/5B0eMEyUyUNSppfTZsKTbjQH8YXI+JI4GTg3yRNKrfCMJ6JiCMjog14B/Au4IKIuC6dfiQwAHw4ff7RajYu6XjgYuBdETH0nYSHgUUlVnkWeL+kqRVs+y+B9wBvjIgjgLcDfcCpBYueBmT/1+UDJM1ItzHS/7VhaL/NBrYBn8jMu3do36V/z1WywRLteQD4LPAq4PXp8TgGyB7zosewwnaU29/DHatqlCtn6Jw+HHg98NYRlHHx0HYiohVYGRHbgeuAU4YWknQQMBf4fjrplyTnyJB5wG2Zx/3pv0OGju8bgK8D52fm/SwijoqI1wFnA5dIOj4ilmVeT89kzo2LSzVGkoDvATdFxKsjYk5az+mZso5Mz5V17H4OVuJpYLakl6TP3wFsqXDd49JyB9i9/ZUaOk6HAVcDvZKyn7v/H8At7L7fq9ZIoQ9ARNwDbAcm12h7fwDOAhakJ9yoSHoLcDnwnoi4NzNrNXCqpClFVnue5MbOORUU8Urg4Yh4FiAiHo6Im4BHJb0ps9yH2D30r+GFN4Z5BfNG4mbg4FFuA4q0B3gMOBPojIgd6fQnI2JJsQ2M4BiW29/DHatqVHpc9wFagEdHUMYrgc1DTyLil+nDHnYP9VOA69I3BICfAUdLmiRpf+A1wIa0HnOBjoL1sw4sVdeI2AAsBRaMoC0AbwOei4juzDbvj4iV2YXS43xAqXqUcS3w7vTxSF4LN5HsrxGLiKuB64G/yUyeR9LZOFjS9KIrVqDhQl/SG4F70hd6TUTEfUATUNWlYhHNJL2U90XErwvmPUUSJv9QYt1LgQ+nPbLhXA/MUDJ09GVJQ73DXS9ySX8BbEvfIId8B3h/+viveaHHVzVJTcDxwNrM5D/NXL5fWsXmirXnNcDvIuLJSjcygmM43P4ud6yqMVw550jaADwE3J0GZrW+SNJj/KGkc5QOuZH09N8o6WXp88IrvwB+DJxAcvU8dCz/HPhRRNwNPCJpTjp96PjeCywEVgxTp/8C/mwEbQFoS9cv5Zh0n/2O5Kpw9QjKuAo4TVILcATw/6pc/z0kV0qjtWs/pVfhr4yIX7B7B61qjRT650i6i+QALRnjupQyCPycpJdUzMXA6ZIOKJwREU8AV5JcHpcUEU8Bc0h6tluBqyWdQXK5+EEl48KFL3CAR0iuBk4DNpJcLVXrJekL7hFgCnBDZl52eKfiS+5i7QGOzS4j6WNp4DwwNEQ1WhXs75LHqoblDA3v/AmwX3psqt3+14BW4Fsk++0WSc3p8NpaknNiKnAUyRtB1lUk50r2fHlzOn1o/tBQw9Dx/VPgfzH8Rw5HfcW8a0PSpel9hHXppKHhnRnA14B/qXabEXE7MJOkbddWsWpfev4fCHyu3MIVyO6nU0nCHnbf71VrpND/YjpmeCpwZfouXROSXg3sBEZ79fBHkmGVoyW9aMwvIh4D1lB6HPJfSd4w9huukIjYGRE3RsQFJJfRH4iIB4DfkIwLf4AkPAtdTdLzHOnQzjNpSB1KMiRR7XhqUUXa89fAIUOBGxFfS8t9nKQ3/yIjPIYl93cFx6oawx7XiBgEfgS8ZSQbj4gHI2J1RJxMMqQ0O501dPX3QeD/pOVk1/sFyb2EqWnPfp/0+Vcl/Rb4R5LzuTDE15ap61EkHYuRuBN4Y6aOnyC5qiz2mzPl6jGctcAXqO61cNzQPb70/Bit7H6aB5yR7ve1wBGSDhvJRhsp9AGIiP8guZFyei22l95I6QYuiRp8qSEdM303ySV9sR7/CuDvKPL/F0fENpJ3+1JXCkOf1sieDEfywg/Y9ZBc7t8XEZtftDJ8l6RnVNjjq0pEPE7Sc10kaVT/D3OJ9twFrCK5IdiSLtdEEkrFtjGiY1jB/i55rKpRrpx0fPrNwL3F5g9H0olDH2pIP1HyMl64MXkjcBjJG1epcDuXF25KzgR+GhGHRsTMtDf9G6Dw6mpuqbpKOgL4J5LOxUj0Ai2S/j4zbd8Sy5asRwVWA/+cuQdSV5I+ALwT6JH0WmD/iDg43e8zSa4kRtTbn4j/Mfq+krKBVWzscCmwRtLlEfHHEZQxNEwxiaRn9I0S5YxIRGyTdCJwk5JfFc3Oe1jSdyl9c+8ihr8Jtj+wMh27fR7YRDI0Askl/sVAZ4l6PQlcCDDae9YRcauk20lOzJ+VW34YpdrzOPAZ4A5JTwLPkHxq5MF0vVodw5L7u4JjNdpyzpH0EZI23A58ucw2ir02pgNfkrQjnfaPEfF7gIj4o6Rvk/TWf1psgxHxw8zTWSRvtlnfAc4jHdMn6fU/B3w8s8wxkm4lCec/AGdHxE/KtKWoiAhJ7wO+KOlTJEN+TwOLM2UN1ePxgnpUU85mktdKMWekdRjyF1VuvlSGDR3v/YA7gLdFxFZJ/5OkQ5b1HZIr86VVlu1v5JqZ5UnDDe+YmVlpDn0RCDsiAAAAKklEQVQzsxxx6JuZ5YhD38wsRxz6ZmY54tA3M8sRh76ZWY449M3McuT/A+/JhvbAwYIJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "      <th>Std Dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>98.571429</td>\n",
       "      <td>2.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLP</td>\n",
       "      <td>97.857143</td>\n",
       "      <td>4.573660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>97.285714</td>\n",
       "      <td>4.467316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GB</td>\n",
       "      <td>97.238095</td>\n",
       "      <td>4.511512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>97.190476</td>\n",
       "      <td>4.696938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NB</td>\n",
       "      <td>97.190476</td>\n",
       "      <td>4.696938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ABDT</td>\n",
       "      <td>96.571429</td>\n",
       "      <td>4.546559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF</td>\n",
       "      <td>96.523810</td>\n",
       "      <td>4.723896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>96.476190</td>\n",
       "      <td>4.758094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LSVM</td>\n",
       "      <td>95.761905</td>\n",
       "      <td>5.692219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NN</td>\n",
       "      <td>93.666667</td>\n",
       "      <td>6.731151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGD</td>\n",
       "      <td>92.333333</td>\n",
       "      <td>6.664796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LDA</td>\n",
       "      <td>92.333333</td>\n",
       "      <td>5.960756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model      Score   Std Dev\n",
       "3    SVM  98.571429  2.857143\n",
       "11   MLP  97.857143  4.573660\n",
       "1     DT  97.285714  4.467316\n",
       "10    GB  97.238095  4.511512\n",
       "2    KNN  97.190476  4.696938\n",
       "7     NB  97.190476  4.696938\n",
       "9   ABDT  96.571429  4.546559\n",
       "4     RF  96.523810  4.723896\n",
       "0     LR  96.476190  4.758094\n",
       "8   LSVM  95.761905  5.692219\n",
       "6     NN  93.666667  6.731151\n",
       "5    SGD  92.333333  6.664796\n",
       "12   LDA  92.333333  5.960756"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'Model': names, 'Score': scores, 'Std Dev': stddevs})\n",
    "results.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
