{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação dos pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar pacotes necessários\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir parâmetros extras\n",
    "#pd.set_option('precision', 2)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar pacotes usados na seleção do modelo e na medição da precisão\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# importar os pacotes necessários para os algoritmos de regressão\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "#from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lars\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import RadiusNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import NuSVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga dos dados de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2784, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>rings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>M</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>0.3285</td>\n",
       "      <td>0.1690</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>F</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.3205</td>\n",
       "      <td>0.5945</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>M</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.5795</td>\n",
       "      <td>0.1825</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>I</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.7865</td>\n",
       "      <td>0.3320</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3445</th>\n",
       "      <td>I</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.5780</td>\n",
       "      <td>0.2545</td>\n",
       "      <td>0.1305</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sex  length  diameter  height  whole_weight  shucked_weight  \\\n",
       "id                                                                 \n",
       "2758   M   0.535     0.430   0.155        0.7845          0.3285   \n",
       "1384   F   0.630     0.485   0.170        1.3205          0.5945   \n",
       "1131   M   0.565     0.435   0.150        0.9900          0.5795   \n",
       "3726   I   0.500     0.395   0.145        0.7865          0.3320   \n",
       "3445   I   0.495     0.400   0.145        0.5780          0.2545   \n",
       "\n",
       "      viscera_weight  shell_weight  rings  \n",
       "id                                         \n",
       "2758          0.1690        0.2450     10  \n",
       "1384          0.3450        0.3450      9  \n",
       "1131          0.1825        0.2060      8  \n",
       "3726          0.1815        0.2455      8  \n",
       "3445          0.1305        0.1645      8  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carregar arquivo de dados de treino\n",
    "data = pd.read_csv('abalone-train.csv', index_col='id')\n",
    "\n",
    "# mostrar tamanho\n",
    "print(data.shape)\n",
    "\n",
    "# mostrar alguns exemplos de registros\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2784 entries, 2758 to 852\n",
      "Data columns (total 3 columns):\n",
      "sex_F    2784 non-null uint8\n",
      "sex_I    2784 non-null uint8\n",
      "sex_M    2784 non-null uint8\n",
      "dtypes: uint8(3)\n",
      "memory usage: 29.9 KB\n"
     ]
    }
   ],
   "source": [
    "data_sex = pd.get_dummies(data['sex'], prefix='sex')\n",
    "\n",
    "cols = {}\n",
    "for col in data_sex.columns:\n",
    "    cols[col] = col.lower()\n",
    "data.rename(columns=cols, inplace=True)\n",
    "\n",
    "data_sex.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>rings</th>\n",
       "      <th>sex_F</th>\n",
       "      <th>sex_I</th>\n",
       "      <th>sex_M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>0.535</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>0.3285</td>\n",
       "      <td>0.1690</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>0.630</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.3205</td>\n",
       "      <td>0.5945</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>0.565</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.5795</td>\n",
       "      <td>0.1825</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.7865</td>\n",
       "      <td>0.3320</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3445</th>\n",
       "      <td>0.495</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.5780</td>\n",
       "      <td>0.2545</td>\n",
       "      <td>0.1305</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      length  diameter  height  whole_weight  shucked_weight  viscera_weight  \\\n",
       "id                                                                             \n",
       "2758   0.535     0.430   0.155        0.7845          0.3285          0.1690   \n",
       "1384   0.630     0.485   0.170        1.3205          0.5945          0.3450   \n",
       "1131   0.565     0.435   0.150        0.9900          0.5795          0.1825   \n",
       "3726   0.500     0.395   0.145        0.7865          0.3320          0.1815   \n",
       "3445   0.495     0.400   0.145        0.5780          0.2545          0.1305   \n",
       "\n",
       "      shell_weight  rings  sex_F  sex_I  sex_M  \n",
       "id                                              \n",
       "2758        0.2450     10      0      0      1  \n",
       "1384        0.3450      9      1      0      0  \n",
       "1131        0.2060      8      0      0      1  \n",
       "3726        0.2455      8      0      1      0  \n",
       "3445        0.1645      8      0      1      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.join(data_sex)\n",
    "data.drop('sex', axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for sex in ['M', 'F', 'I']:\n",
    "    col = 'sex_' + sex\n",
    "    data[col] = data[col].astype('float')\n",
    "data['rings'] = data.rings.astype('float')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data.sex = data.sex.astype('category').cat.codes\n",
    "print(data.dtypes)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma dos dados originais: (2784, 10) (2784,)\n"
     ]
    }
   ],
   "source": [
    "# definir dados de entrada\n",
    "\n",
    "X = data.drop(['rings'], axis=1) # tudo, exceto a coluna alvo\n",
    "y = data['rings'] # apenas a coluna alvo\n",
    "\n",
    "print('Forma dos dados originais:', X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento dos modelos preditivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "def root_mean_squared_error(ground_truth, predictions):\n",
    "    return mean_squared_error(ground_truth, predictions) ** 0.5\n",
    "\n",
    "RMSE = make_scorer(root_mean_squared_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_cv(model, X=X, y=y):\n",
    "  kfold = KFold(n_splits=10, random_state=42)\n",
    "  results = cross_val_score(model, X, y, cv=kfold, scoring=RMSE, verbose=1)\n",
    "  score = (-1) * results.mean()\n",
    "  stddev = results.std()\n",
    "  print(model, '\\nCross-Validation Score: %.2f (+/- %.2f)' % (score, stddev))\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faz o ajuste fino do modelo, calculando os melhores hiperparâmetros\n",
    "def fine_tune_model(model, params, X=X, y=y):\n",
    "  print('\\nFine Tuning Model:')\n",
    "  print(model, \"\\nparams:\", params)\n",
    "\n",
    "  kfold = KFold(n_splits=10, random_state=42)\n",
    "  grid = GridSearchCV(estimator=model, param_grid=params, scoring=RMSE, cv=kfold, verbose=1)\n",
    "  grid.fit(X, y)\n",
    "\n",
    "  print('\\nGrid Best Score: %.2f' % (grid.best_score_ * (-1)))\n",
    "  print('Best Params:', grid.best_params_)\n",
    " \n",
    "  return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação e ajuste fino de cada modelo preditivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=2, normalize=True) \n",
      "Cross-Validation Score: 2.21 (+/- 0.17)\n",
      "\n",
      "Fine Tuning Model:\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=2, normalize=True) \n",
      "params: {'fit_intercept': [True, False], 'normalize': [True, False]}\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "\n",
      "Grid Best Score: 2.21\n",
      "Best Params: {'fit_intercept': True, 'normalize': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=42, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=2, normalize=True),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'fit_intercept': [True, False], 'normalize': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(root_mean_squared_error, greater_is_better=False),\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression(n_jobs=2, fit_intercept=True, normalize=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {'fit_intercept':[True, False], 'normalize':[True, False]}\n",
    "fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7c90add64142>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevaluate_model_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m params = {\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'solver'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'saga'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-9c79abb102f7>\u001b[0m in \u001b[0;36mevaluate_model_cv\u001b[0;34m(model, X, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_model_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRMSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mstddev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 240\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1358\u001b[0m                       \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1360\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(n_jobs=2, random_state=42, multi_class='auto', C=1000, solver='newton-cg')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'C':np.logspace(-3,3,7)\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=8,\n",
      "             normalize=True, precompute='auto', tol=None) \n",
      "Cross-Validation Score: 2.21 (+/- 0.17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.3s finished\n"
     ]
    }
   ],
   "source": [
    "model = OrthogonalMatchingPursuit(n_nonzero_coefs=8, fit_intercept=True, normalize=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {\n",
    "    'n_nonzero_coefs': [None, 1, 2, 4, 6, 8, 10],\n",
    "    'fit_intercept': [True, False],\n",
    "    'normalize': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassiveAggressiveRegressor(C=0.2, average=False, early_stopping=False,\n",
      "              epsilon=0.1, fit_intercept=True, loss='epsilon_insensitive',\n",
      "              max_iter=None, n_iter=None, n_iter_no_change=5,\n",
      "              random_state=42, shuffle=True, tol=None,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Cross-Validation Score: 2.42 (+/- 0.24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "model = PassiveAggressiveRegressor(random_state=42, C=0.2, fit_intercept=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {\n",
    "    'C': [0.1, 0.2, 0.4, 0.8, 1.0],\n",
    "    'fit_intercept': [True, False],\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron(alpha=0.01, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "      fit_intercept=True, max_iter=None, n_iter=None, n_iter_no_change=5,\n",
      "      n_jobs=None, penalty='l1', random_state=42, shuffle=True, tol=None,\n",
      "      validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Cross-Validation Score: 3.61 (+/- 0.35)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    4.7s finished\n"
     ]
    }
   ],
   "source": [
    "model = Perceptron(random_state=42, penalty='l1', alpha=0.01, fit_intercept=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#penalty=None, alpha=0.0001, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, eta0=1.0, n_jobs=None, \n",
    "#random_state=0, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, class_weight=None, warm_start=False\n",
    "\n",
    "params = {\n",
    "    'penalty': [None, 'l2', 'l1', 'elasticnet'],\n",
    "    'alpha': np.logspace(-6, -1, 6),\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANSACRegressor(base_estimator=None, is_data_valid=None, is_model_valid=None,\n",
      "        loss='absolute_loss', max_skips=inf, max_trials=100,\n",
      "        min_samples=0.75, random_state=42, residual_threshold=None,\n",
      "        stop_n_inliers=inf, stop_probability=0.99, stop_score=inf) \n",
      "Cross-Validation Score: 2.24 (+/- 0.18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   27.0s finished\n"
     ]
    }
   ],
   "source": [
    "model = RANSACRegressor(random_state=42, min_samples=0.75)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#base_estimator=None, min_samples=None, residual_threshold=None, is_data_valid=None, is_model_valid=None, max_trials=100, \n",
    "#max_skips=inf, stop_n_inliers=inf, stop_score=inf, stop_probability=0.99, loss=’absolute_loss’, random_state=None\n",
    "\n",
    "params = {\n",
    "    'min_samples': [None, 0.1, 0.25, 0.5, 0.75, 1.0]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=0.1, copy_X=True, fit_intercept=False, max_iter=None,\n",
      "   normalize=True, random_state=42, solver='auto', tol=0.001) \n",
      "Cross-Validation Score: 2.21 (+/- 0.17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "model = Ridge(random_state=42, alpha=0.1, fit_intercept=False, normalize=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, solver=’auto’, random_state=None\n",
    "\n",
    "params = {\n",
    "    'alpha': np.logspace(-6, -1, 4),\n",
    "    'fit_intercept': [True, False],\n",
    "    'normalize': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor(alpha=1e-06, average=False, early_stopping=False, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=False, l1_ratio=0.15,\n",
      "       learning_rate='invscaling', loss='squared_loss', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, penalty=None, power_t=0.25,\n",
      "       random_state=42, shuffle=True, tol=None, validation_fraction=0.1,\n",
      "       verbose=0, warm_start=False) \n",
      "Cross-Validation Score: 2.69 (+/- 0.21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "model = SGDRegressor(random_state=42, alpha=1e-06, fit_intercept=False, penalty=None)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#loss=’squared_loss’, penalty=’l2’, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, \n",
    "#verbose=0, epsilon=0.1, random_state=None, learning_rate=’invscaling’, eta0=0.01, power_t=0.25, early_stopping=False, \n",
    "#validation_fraction=0.1, n_iter_no_change=5, warm_start=False, average=False\n",
    "\n",
    "params = {\n",
    "    'penalty': [None, 'l2', 'l1', 'elasticnet'],\n",
    "    'alpha': np.logspace(-6, -1, 4),\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TheilSenRegressor(copy_X=True, fit_intercept=True, max_iter=300,\n",
      "         max_subpopulation=10000, n_jobs=2, n_subsamples=None,\n",
      "         random_state=42, tol=0.001, verbose=False) \n",
      "Cross-Validation Score: 2.23 (+/- 0.17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  2.0min finished\n"
     ]
    }
   ],
   "source": [
    "model = TheilSenRegressor(random_state=42, n_jobs=2, fit_intercept=True)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#fit_intercept=True, copy_X=True, max_subpopulation=10000.0, n_subsamples=None, \n",
    "#max_iter=300, tol=0.001, random_state=None, n_jobs=None, verbose=False\n",
    "\n",
    "params = {\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=2, n_neighbors=11, p=2,\n",
      "          weights='distance') \n",
      "Cross-Validation Score: 2.24 (+/- 0.20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    8.9s finished\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsRegressor(n_jobs=2, n_neighbors=11, weights='distance')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#n_neighbors=5, weights=’uniform’, algorithm=’auto’, leaf_size=30, p=2, metric=’minkowski’, metric_params=None, n_jobs=None\n",
    "\n",
    "params = {\n",
    "    'n_neighbors': [1, 3, 5, 7, 9, 11, 13],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False) \n",
      "Cross-Validation Score: 2.34 (+/- 0.23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   19.7s finished\n"
     ]
    }
   ],
   "source": [
    "model = SVR(gamma='auto', kernel='linear')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#kernel=’rbf’, degree=3, gamma=’auto_deprecated’, coef0=0.0, tol=0.001, C=1.0, \n",
    "#epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1\n",
    "\n",
    "params = {\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']#, 'precomputed']\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=7,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=2,\n",
      "           oob_score=False, random_state=42, verbose=0, warm_start=False) \n",
      "Cross-Validation Score: 2.18 (+/- 0.20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   45.1s finished\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(random_state=42, n_jobs=2, n_estimators=100, max_depth=7)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#n_estimators=’warn’, criterion=’mse’, max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#min_weight_fraction_leaf=0.0, max_features=’auto’, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [5, 10, 25, 50, 75, 100],\n",
    "    'max_depth': [None, 3, 5, 7, 9, 11, 13]\n",
    "}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/classes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
      "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "             min_impurity_split=None, min_samples_leaf=1,\n",
      "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "             n_estimators=100, n_iter_no_change=None, presort='auto',\n",
      "             random_state=42, subsample=1.0, tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Cross-Validation Score: 2.22 (+/- 0.20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   10.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.2246574460647914"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(random_state=42)\n",
    "evaluate_model_cv(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=42, splitter='best') \n",
      "Cross-Validation Score: 3.11 (+/- 0.19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.1109542059076007"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(random_state=42)\n",
    "evaluate_model_cv(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianProcessRegressor(alpha=1e-10, copy_X_train=True, kernel=None,\n",
      "             n_restarts_optimizer=0, normalize_y=False,\n",
      "             optimizer='fmin_l_bfgs_b', random_state=None) \n",
      "Cross-Validation Score: 44.61 (+/- 51.76)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44.609203304259225"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GaussianProcessRegressor()\n",
    "evaluate_model_cv(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False) \n",
      "Cross-Validation Score: 2.20 (+/- 0.19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  3.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.201780707817829"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLPRegressor(random_state=42)\n",
    "evaluate_model_cv(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='auto',\n",
      "          n_jobs=None, penalty='l2', random_state=42, solver='lbfgs',\n",
      "          tol=0.0001, verbose=0, warm_start=False) \n",
      "Cross-Validation Score: 96.48 (4.76) %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    7.1s finished\n"
     ]
    }
   ],
   "source": [
    "# A) Logistic Regression\n",
    "model = LogisticRegression(random_state=42, solver='lbfgs', multi_class='auto', max_iter=500, C=100)\n",
    "#TODO: testar LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {'solver':['liblinear', 'lbfgs'], 'C':np.logspace(-3,3,7)}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=11,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best') \n",
      "Cross-Validation Score: 97.29 (4.47) %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "# B) Decision Tree\n",
    "model = DecisionTreeClassifier(random_state=42, criterion='gini', max_depth=11)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {'criterion':['gini','entropy'], 'max_depth':[3,5,7,11]}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
      "           weights='uniform') \n",
      "Cross-Validation Score: 97.19 (4.70) %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "# C) K-Nearest Neighbours\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {'n_neighbors':[1, 3, 5, 7, 9]}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=42, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "Cross-Validation Score: 98.57 (2.86) %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "# D) Support Vector Machine (SVM)\n",
    "model = SVC(random_state=42, C=10, gamma=0.1, kernel='rbf')\n",
    "# SVC(kernel='linear', C=1)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {'C':[0.001, 0.01, 0.1, 1, 10, 100], 'gamma':[0.001, 0.01, 0.1, 1, 10, 100], 'kernel':['linear', 'rbf']}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False) \n",
      "Cross-Validation Score: 96.52 (4.72) %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.2s finished\n"
     ]
    }
   ],
   "source": [
    "# E) Random Forest\n",
    "model = RandomForestClassifier(random_state=42, max_features='auto', n_estimators=10)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {'n_estimators':[10, 50, 100, 500], 'max_features':['auto', 'sqrt', 'log2']}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=100,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=42, shuffle=True, tol=0.1,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Cross-Validation Score: 92.33 (6.66) %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "# F) Stochastic Gradient Descent (SGD)\n",
    "model = SGDClassifier(random_state=42, max_iter=100, tol=0.1)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {'max_iter':[100, 200, 350, 500, 1000], 'tol':[0.1, 0.01]}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "      fit_intercept=True, max_iter=100, n_iter=None, n_iter_no_change=5,\n",
      "      n_jobs=None, penalty=None, random_state=42, shuffle=True, tol=0.01,\n",
      "      validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Cross-Validation Score: 93.67 (6.73) %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "# G) Perceptron\n",
    "model = Perceptron(random_state=42, max_iter=100, tol=0.01)\n",
    "# Perceptron(eta0=1, random_state=1)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {'max_iter':[100, 200, 350, 500, 1000], 'tol':[0.1, 0.01, 0.001]}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=1e-08) \n",
      "Cross-Validation Score: 97.19 (4.70) %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "# H) Naïve Bayes\n",
    "model = GaussianNB(priors=None, var_smoothing=1e-08)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {'priors': [None], 'var_smoothing': [1e-8, 1e-7, 1e-6, 1e-5, 1e-4]}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0) \n",
      "Cross-Validation Score: 95.76 (5.69) %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.2s finished\n"
     ]
    }
   ],
   "source": [
    "# I) Linear SVM\n",
    "model = LinearSVC(random_state=42, max_iter=1000, C=10)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {'C':[0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R',\n",
      "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best'),\n",
      "          learning_rate=1.0, n_estimators=5, random_state=None) \n",
      "Cross-Validation Score: 95.19 (4.34) %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "# J) Ada Boost\n",
    "model = AdaBoostClassifier(DecisionTreeClassifier(random_state=42), n_estimators=5)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {'n_estimators':[1,3,5,7,11]}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=42,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False) \n",
      "Cross-Validation Score: 97.24 (4.51) %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   33.5s finished\n"
     ]
    }
   ],
   "source": [
    "# K) Gradient Boosting\n",
    "model = GradientBoostingClassifier(random_state=42, max_depth=3)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "'''\n",
    "params = {\n",
    "    \"learning_rate\":[0.01, 0.05, 0.1],\n",
    "    \"max_depth\":[3, 5, 7],\n",
    "    \"max_features\":[\"log2\", \"sqrt\"],\n",
    "    \"criterion\":[\"friedman_mse\", \"mae\"],\n",
    "    \"subsample\":[0.5, 0.75, 1.0],\n",
    "}\n",
    "'''\n",
    "\n",
    "params = {'max_depth':[3, 5, 7]}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# L) Ridge\n",
    "model = Ridge(random_state=42, alpha=1)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#params = {'alpha':[1,0.1,0.01,0.001,0.0001,0]}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(15,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False) \n",
      "Cross-Validation Score: 97.86 (4.57) %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   10.3s finished\n"
     ]
    }
   ],
   "source": [
    "# M) Multi-Layer Perceptron (MLP)\n",
    "model = MLPClassifier(random_state=42, solver='lbfgs', alpha=0.1, hidden_layer_sizes=(15,))\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {'alpha':[1,0.1,0.01,0.001,0.0001,0]}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
      "              solver='svd', store_covariance=False, tol=0.0001) \n",
      "Cross-Validation Score: 92.33 (5.96) %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.3s finished\n"
     ]
    }
   ],
   "source": [
    "# N) Linear Discriminant Analysis (LDA)\n",
    "model = LinearDiscriminantAnalysis(solver='svd')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {'solver':['svd', 'lsqr']} #, 'eigen']}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação final entre os algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression(random_state=42, solver='lbfgs', multi_class='auto', max_iter=500, C=100)))\n",
    "models.append(('DT', DecisionTreeClassifier(random_state=42, criterion='gini', max_depth=11)))\n",
    "models.append(('KNN', KNeighborsClassifier(n_neighbors=1)))\n",
    "models.append(('SVM', SVC(random_state=42, C=10, gamma=0.1, kernel='rbf')))\n",
    "models.append(('RF', RandomForestClassifier(random_state=42, max_features='auto', n_estimators=10)))\n",
    "models.append(('SGD', SGDClassifier(random_state=42, max_iter=100, tol=0.1)))\n",
    "models.append(('NN', Perceptron(random_state=42, max_iter=100, tol=0.01)))\n",
    "models.append(('NB', GaussianNB(priors=None, var_smoothing=1e-08)))\n",
    "models.append(('LSVM', LinearSVC(random_state=42, max_iter=1000, C=10)))\n",
    "models.append(('ABDT', AdaBoostClassifier(DecisionTreeClassifier(random_state=42), n_estimators=5)))\n",
    "models.append(('GB', GradientBoostingClassifier(random_state=42, max_depth=3)))\n",
    "models.append(('MLP', MLPClassifier(random_state=42, solver='lbfgs', alpha=0.1, hidden_layer_sizes=(15,))))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis(solver='svd')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.964762 (0.047581)\n",
      "DT: 0.972857 (0.044673)\n",
      "KNN: 0.971905 (0.046969)\n",
      "SVM: 0.985714 (0.028571)\n",
      "RF: 0.965238 (0.047239)\n",
      "SGD: 0.923333 (0.066648)\n",
      "NN: 0.936667 (0.067312)\n",
      "NB: 0.971905 (0.046969)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSVM: 0.957619 (0.056922)\n",
      "ABDT: 0.965714 (0.045466)\n",
      "GB: 0.972381 (0.045115)\n",
      "MLP: 0.978571 (0.045737)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: 0.923333 (0.059608)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "scores = []\n",
    "stddevs = []\n",
    "\n",
    "for name, model in models:\n",
    "  kfold = KFold(n_splits=10, random_state=42)\n",
    "  cv_results = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')\n",
    "  results.append(cv_results)\n",
    "  names.append(name)\n",
    "  scores.append(cv_results.mean() * 100)\n",
    "  stddevs.append(cv_results.std() * 100)\n",
    "  msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "  print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "      <th>Std Dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>98.571429</td>\n",
       "      <td>2.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLP</td>\n",
       "      <td>97.857143</td>\n",
       "      <td>4.573660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>97.285714</td>\n",
       "      <td>4.467316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GB</td>\n",
       "      <td>97.238095</td>\n",
       "      <td>4.511512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>97.190476</td>\n",
       "      <td>4.696938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NB</td>\n",
       "      <td>97.190476</td>\n",
       "      <td>4.696938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ABDT</td>\n",
       "      <td>96.571429</td>\n",
       "      <td>4.546559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF</td>\n",
       "      <td>96.523810</td>\n",
       "      <td>4.723896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>96.476190</td>\n",
       "      <td>4.758094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LSVM</td>\n",
       "      <td>95.761905</td>\n",
       "      <td>5.692219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NN</td>\n",
       "      <td>93.666667</td>\n",
       "      <td>6.731151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGD</td>\n",
       "      <td>92.333333</td>\n",
       "      <td>6.664796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LDA</td>\n",
       "      <td>92.333333</td>\n",
       "      <td>5.960756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model      Score   Std Dev\n",
       "3    SVM  98.571429  2.857143\n",
       "11   MLP  97.857143  4.573660\n",
       "1     DT  97.285714  4.467316\n",
       "10    GB  97.238095  4.511512\n",
       "2    KNN  97.190476  4.696938\n",
       "7     NB  97.190476  4.696938\n",
       "9   ABDT  96.571429  4.546559\n",
       "4     RF  96.523810  4.723896\n",
       "0     LR  96.476190  4.758094\n",
       "8   LSVM  95.761905  5.692219\n",
       "6     NN  93.666667  6.731151\n",
       "5    SGD  92.333333  6.664796\n",
       "12   LDA  92.333333  5.960756"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'Model': names, 'Score': scores, 'Std Dev': stddevs})\n",
    "results.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
