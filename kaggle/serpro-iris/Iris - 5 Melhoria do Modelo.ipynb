{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação dos pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar pacotes necessários\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# definir parâmetros extras\n",
    "#pd.set_option('precision', 2)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar pacotes usados na seleção do modelo e na medição da precisão\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# importar os pacotes necessários para os algoritmos de classificação\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga dos dados de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm          Species\n",
       "Id                                                                           \n",
       "47            5.1           3.8            1.6           0.2      Iris-setosa\n",
       "37            5.5           3.5            1.3           0.2      Iris-setosa\n",
       "50            5.0           3.3            1.4           0.2      Iris-setosa\n",
       "79            6.0           2.9            4.5           1.5  Iris-versicolor\n",
       "44            5.0           3.5            1.6           0.6      Iris-setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carregar arquivo de dados de treino\n",
    "data = pd.read_csv('iris-train.csv', index_col='Id')\n",
    "\n",
    "# mostrar alguns exemplos de registros\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma dos dados originais: (100, 4) (100,)\n"
     ]
    }
   ],
   "source": [
    "# definir dados de entrada\n",
    "\n",
    "#X = data.drop(['Species'], axis=1) # tudo, exceto a coluna alvo\n",
    "X = data[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\n",
    "y = data['Species'] # apenas a coluna alvo\n",
    "\n",
    "print('Forma dos dados originais:', X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
       "Id                                                          \n",
       "47            5.1           3.8            1.6           0.2\n",
       "37            5.5           3.5            1.3           0.2\n",
       "50            5.0           3.3            1.4           0.2\n",
       "79            6.0           2.9            4.5           1.5\n",
       "44            5.0           3.5            1.6           0.6"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformações nos dados"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y.values)\n",
    "\n",
    "y = encoder.transform(y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# normalizar os valores numéricos\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#scaler = MinMaxScaler()\n",
    "scaler = StandardScaler()\n",
    "#X_norm = X.copy()\n",
    "#X_norm[X_norm.columns] = scaler.fit_transform(X_norm[X_norm.columns])\n",
    "X_norm = pd.DataFrame(scaler.fit_transform(X.values), columns=X.columns, index=X.index)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_norm = (X - np.min(X)) / (np.max(X) - np.min(X))\n",
    "X_norm.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# remover apenas um atributo\n",
    "X_part = X.drop(['PetalLengthCm'], axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "X_pca = pd.DataFrame(pca.fit_transform(X.values), columns=['pc1','pc2','pc3'], index=X.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação dos dados de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma dos dados separados: (70, 4) (30, 4) (70,) (30,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
       "Id                                                           \n",
       "67             5.6           3.0            4.5           1.5\n",
       "130            7.2           3.0            5.8           1.6\n",
       "99             5.1           2.5            3.0           1.1\n",
       "4              4.6           3.1            1.5           0.2\n",
       "46             4.8           3.0            1.4           0.3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separar dados para fins de treino (70%) e de teste (30%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print('Forma dos dados separados:', X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# separar dados normalizados para fins de treino (70%) e de teste (30%)\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_norm, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print('Forma dos dados normalizados separados:', X_train2.shape, X_test2.shape, y_train2.shape, y_test2.shape)\n",
    "\n",
    "X_train2.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# separar dados parciais para fins de treino (70%) e de teste (30%)\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X_part, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print('Forma dos dados parciais separados:', X_train3.shape, X_test3.shape, y_train3.shape, y_test3.shape)\n",
    "\n",
    "X_train3.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# separar dados em PCA para fins de treino (70%) e de teste (30%)\n",
    "\n",
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print('Forma dos dados em PCA separados:', X_train4.shape, X_test4.shape, y_train4.shape, y_test4.shape)\n",
    "\n",
    "X_train4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento dos modelos preditivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_cv(model, X=X, y=y):\n",
    "  kfold = KFold(n_splits=10, random_state=42)\n",
    "  results = cross_val_score(model, X, y, cv=kfold, scoring='accuracy', verbose=1)\n",
    "  score = results.mean() * 100\n",
    "  stddev = results.std() * 100\n",
    "  print(model, '\\nCross-Validation Score: %.2f (%.2f) %%' % (score, stddev))\n",
    "  return score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# treina o modelo especificado e avalia a sua respectiva precisão\n",
    "def fit_and_evaluate(model, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "  # treinar o modelo\n",
    "  model.fit(X_train, y_train)\n",
    "\n",
    "  # calcular precisão (forma simples)\n",
    "  score = model.score(X_test, y_test) * 100\n",
    "  print(model, '\\nModel Score: %.2f %%' % score)\n",
    "\n",
    "  # exibir matriz de confusão\n",
    "  y_pred = model.predict(X_test)\n",
    "  cm = confusion_matrix(y_test, y_pred)\n",
    "  print('Confusion Matrix:\\n', cm)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# treina e avalia o modelo especificado usando os dados de treino e teste\n",
    "def evaluate_model_simple(model):\n",
    "  fit_and_evaluate(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "  #print('\\nNormalized:')\n",
    "  #fit_and_evaluate(model, X_train2, y_train2, X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faz o ajuste fino do modelo, calculando os melhores hiperparâmetros\n",
    "def fine_tune_model(model, params, X=X, y=y):\n",
    "  print('\\nFine Tuning Model:')\n",
    "  print(model, \"\\nparams:\", params)\n",
    "\n",
    "  kfold = KFold(n_splits=10, random_state=42)\n",
    "  grid = GridSearchCV(estimator=model, param_grid=params, scoring='accuracy', cv=kfold, verbose=1)\n",
    "  grid.fit(X, y)\n",
    "\n",
    "  print('\\nGrid Score: %.2f %%' % (grid.best_score_ * 100))\n",
    "  print('Best Params:', grid.best_params_)\n",
    " \n",
    "  return grid"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def fine_tune_model_all_data(model, params):\n",
    "    \n",
    "  print('\\n=> Using Original Data')\n",
    "  fine_tune_model(model, params, X, y, X_train, y_train)\n",
    "    \n",
    "  #print('\\n=> Using Scaled Data')\n",
    "  #fine_tune_model(model, params, X_train2, y_train2)\n",
    "    \n",
    "  #print('\\n=> Using Partial Data')\n",
    "  #fine_tune_model(model, params, X_train3, y_train3)\n",
    "    \n",
    "  #print('\\n=> Using PCA-Decomposed Data')\n",
    "  #fine_tune_model(model, params, X_train4, y_train4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação e ajuste fino de cada modelo preditivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='auto',\n",
      "          n_jobs=None, penalty='l2', random_state=42, solver='lbfgs',\n",
      "          tol=0.0001, verbose=0, warm_start=False) \n",
      "Cross-Validation Score: 98.00 (4.00) %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "# A) Logistic Regression\n",
    "model = LogisticRegression(random_state=42, solver='lbfgs', multi_class='auto', max_iter=500, C=10)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {'solver':['liblinear', 'lbfgs'], 'C':np.logspace(-3,3,7)}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best') \n",
      "Cross-Validation Score: 97.00 (4.58) %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# B) Decision Tree\n",
    "model = DecisionTreeClassifier(random_state=42, max_depth=5, criterion='entropy')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {'criterion':['gini','entropy'], 'max_depth':[3,5,7,11]}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
      "           weights='uniform') \n",
      "Cross-Validation Score: 99.00 (3.00) %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# C) K-Nearest Neighbours\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {'n_neighbors':[1, 3, 5, 7, 9]}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=42, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "Cross-Validation Score: 99.00 (3.00) %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# D) Support Vector Machine (SVM)\n",
    "model = SVC(random_state=42, C=1, gamma=0.001, kernel='linear')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {'C':[0.001, 0.01, 0.1, 1, 10, 100], 'gamma':[0.001, 0.01, 0.1, 1, 10, 100], 'kernel':['linear', 'rbf']}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False) \n",
      "Cross-Validation Score: 97.00 (4.58) %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "# E) Random Forest\n",
    "model = RandomForestClassifier(random_state=42, max_features='auto', n_estimators=100)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {'n_estimators':[10, 50, 100, 500], 'max_features':['auto', 'sqrt', 'log2']}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=100,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=42, shuffle=True, tol=0.01,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Cross-Validation Score: 78.00 (17.78) %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# F) Stochastic Gradient Descent (SGD)\n",
    "model = SGDClassifier(random_state=42, max_iter=100, tol=0.01)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {'max_iter':[100, 200, 350, 500, 1000], 'tol':[0.1, 0.01]}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "      fit_intercept=True, max_iter=100, n_iter=None, n_iter_no_change=5,\n",
      "      n_jobs=None, penalty=None, random_state=42, shuffle=True, tol=0.01,\n",
      "      validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Cross-Validation Score: 76.00 (17.44) %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# G) Perceptron\n",
    "model = Perceptron(random_state=42, max_iter=100, tol=0.01)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {'max_iter':[100, 200, 350, 500, 1000], 'tol':[0.1, 0.01, 0.001]}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=1e-08) \n",
      "Cross-Validation Score: 96.00 (4.90) %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# H) Naïve Bayes\n",
    "model = GaussianNB(priors=None, var_smoothing=1e-08)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {'priors': [None], 'var_smoothing': [1e-8, 1e-7, 1e-6, 1e-5, 1e-4]}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0) \n",
      "Cross-Validation Score: 96.00 (4.90) %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/dados/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/dados/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/dados/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/dados/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/dados/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/dados/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/dados/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/dados/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/dados/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/dados/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# I) Linear SVM\n",
    "model = LinearSVC(random_state=42, max_iter=1000, C=1)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {'C':[0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R',\n",
      "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best'),\n",
      "          learning_rate=1.0, n_estimators=1, random_state=None) \n",
      "Cross-Validation Score: 97.00 (4.58) %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# J) Ada Boost\n",
    "model = AdaBoostClassifier(DecisionTreeClassifier(random_state=42), n_estimators=1)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {'n_estimators':[1,3,5,7,11]}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=5,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=42,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False) \n",
      "Cross-Validation Score: 97.00 (4.58) %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "# K) Gradient Boosting\n",
    "model = GradientBoostingClassifier(random_state=42, max_depth=5)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "'''\n",
    "params = {\n",
    "    \"learning_rate\":[0.01, 0.05, 0.1],\n",
    "    \"max_depth\":[3, 5, 7],\n",
    "    \"max_features\":[\"log2\", \"sqrt\"],\n",
    "    \"criterion\":[\"friedman_mse\", \"mae\"],\n",
    "    \"subsample\":[0.5, 0.75, 1.0],\n",
    "}\n",
    "'''\n",
    "\n",
    "params = {'max_depth':[3, 5, 7]}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# L) Ridge\n",
    "model = Ridge(random_state=42, alpha=1)\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "#params = {'alpha':[1,0.1,0.01,0.001,0.0001,0]}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(15,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False) \n",
      "Cross-Validation Score: 99.00 (3.00) %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "# M) Multi-Layer Perceptron (MLP)\n",
    "model = MLPClassifier(random_state=42, solver='lbfgs', alpha=1, hidden_layer_sizes=(15,))\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {'alpha':[1,0.1,0.01,0.001,0.0001,0]}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
      "              solver='svd', store_covariance=False, tol=0.0001) \n",
      "Cross-Validation Score: 98.00 (4.00) %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.2s finished\n"
     ]
    }
   ],
   "source": [
    "# N) Linear Discriminant Analysis (LDA)\n",
    "model = LinearDiscriminantAnalysis(solver='svd')\n",
    "evaluate_model_cv(model)\n",
    "\n",
    "params = {'solver':['svd', 'lsqr', 'eigen']}\n",
    "#fine_tune_model(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação final entre os algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression(random_state=42, solver='lbfgs', multi_class='auto', max_iter=500, C=10)))\n",
    "models.append(('DT', DecisionTreeClassifier(random_state=42, max_depth=5, criterion='entropy')))\n",
    "models.append(('KNN', KNeighborsClassifier(n_neighbors=3)))\n",
    "models.append(('SVM', SVC(random_state=42, C=1, gamma=0.001, kernel='linear')))\n",
    "models.append(('RF', RandomForestClassifier(random_state=42, max_features='auto', n_estimators=100)))\n",
    "models.append(('SGD', SGDClassifier(random_state=42, max_iter=100, tol=0.01)))\n",
    "models.append(('NN', Perceptron(random_state=42, max_iter=100, tol=0.01)))\n",
    "models.append(('NB', GaussianNB(priors=None, var_smoothing=1e-08)))\n",
    "models.append(('LSVM', LinearSVC(random_state=42, max_iter=1000, C=1)))\n",
    "models.append(('ABDT', AdaBoostClassifier(DecisionTreeClassifier(random_state=42), n_estimators=1)))\n",
    "models.append(('GB', GradientBoostingClassifier(random_state=42, max_depth=5)))\n",
    "models.append(('MLP', MLPClassifier(random_state=42, solver='lbfgs', alpha=1, hidden_layer_sizes=(15,))))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis(solver='svd')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.980000 (0.040000)\n",
      "DT: 0.970000 (0.045826)\n",
      "KNN: 0.990000 (0.030000)\n",
      "SVM: 0.990000 (0.030000)\n",
      "RF: 0.970000 (0.045826)\n",
      "SGD: 0.780000 (0.177764)\n",
      "NN: 0.760000 (0.174356)\n",
      "NB: 0.960000 (0.048990)\n",
      "LSVM: 0.960000 (0.048990)\n",
      "ABDT: 0.970000 (0.045826)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dados/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/dados/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/dados/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/dados/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/dados/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/dados/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/dados/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/dados/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/dados/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/dados/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB: 0.970000 (0.045826)\n",
      "MLP: 0.990000 (0.030000)\n",
      "LDA: 0.980000 (0.040000)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "scores = []\n",
    "stddevs = []\n",
    "\n",
    "for name, model in models:\n",
    "  kfold = KFold(n_splits=10, random_state=42)\n",
    "  cv_results = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')\n",
    "  results.append(cv_results)\n",
    "  names.append(name)\n",
    "  scores.append(cv_results.mean() * 100)\n",
    "  stddevs.append(cv_results.std() * 100)\n",
    "  msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "  print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "      <th>Std Dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLP</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>98.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LDA</td>\n",
       "      <td>98.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>97.0</td>\n",
       "      <td>4.582576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF</td>\n",
       "      <td>97.0</td>\n",
       "      <td>4.582576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ABDT</td>\n",
       "      <td>97.0</td>\n",
       "      <td>4.582576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GB</td>\n",
       "      <td>97.0</td>\n",
       "      <td>4.582576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NB</td>\n",
       "      <td>96.0</td>\n",
       "      <td>4.898979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LSVM</td>\n",
       "      <td>96.0</td>\n",
       "      <td>4.898979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGD</td>\n",
       "      <td>78.0</td>\n",
       "      <td>17.776389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NN</td>\n",
       "      <td>76.0</td>\n",
       "      <td>17.435596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Score    Std Dev\n",
       "2    KNN   99.0   3.000000\n",
       "3    SVM   99.0   3.000000\n",
       "11   MLP   99.0   3.000000\n",
       "0     LR   98.0   4.000000\n",
       "12   LDA   98.0   4.000000\n",
       "1     DT   97.0   4.582576\n",
       "4     RF   97.0   4.582576\n",
       "9   ABDT   97.0   4.582576\n",
       "10    GB   97.0   4.582576\n",
       "7     NB   96.0   4.898979\n",
       "8   LSVM   96.0   4.898979\n",
       "5    SGD   78.0  17.776389\n",
       "6     NN   76.0  17.435596"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'Model': names, 'Score': scores, 'Std Dev': stddevs})\n",
    "results.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificação contra os dados reais (resultados esperados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
       "Id                                                           \n",
       "72             6.1           2.8            4.0           1.3\n",
       "78             6.7           3.0            5.0           1.7\n",
       "139            6.0           3.0            4.8           1.8\n",
       "135            6.1           2.6            5.6           1.4\n",
       "27             5.0           3.4            1.6           0.4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carregar arquivo de dados de teste\n",
    "test_data = pd.read_csv('iris-test.csv', index_col='Id')\n",
    "\n",
    "# mostrar alguns exemplos de registros\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregar arquivo de dados de teste\n",
    "real_data = pd.read_csv('iris-solution.csv', index_col='Id')\n",
    "\n",
    "# mostrar alguns exemplos de registros\n",
    "real_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='auto',\n",
      "          n_jobs=None, penalty='l2', random_state=42, solver='lbfgs',\n",
      "          tol=0.0001, verbose=0, warm_start=False) \n",
      "Model Score: 92.00 %\n",
      "Confusion Matrix:\n",
      " [[15  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  2 16]] \n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best') \n",
      "Model Score: 86.00 %\n",
      "Confusion Matrix:\n",
      " [[15  0  0]\n",
      " [ 0 13  4]\n",
      " [ 0  3 15]] \n",
      "\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
      "           weights='uniform') \n",
      "Model Score: 94.00 %\n",
      "Confusion Matrix:\n",
      " [[15  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  1 17]] \n",
      "\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=42, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "Model Score: 92.00 %\n",
      "Confusion Matrix:\n",
      " [[15  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  2 16]] \n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False) \n",
      "Model Score: 94.00 %\n",
      "Confusion Matrix:\n",
      " [[15  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  1 17]] \n",
      "\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=100,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=42, shuffle=True, tol=0.01,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Model Score: 62.00 %\n",
      "Confusion Matrix:\n",
      " [[15  0  0]\n",
      " [14  3  0]\n",
      " [ 4  1 13]] \n",
      "\n",
      "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "      fit_intercept=True, max_iter=100, n_iter=None, n_iter_no_change=5,\n",
      "      n_jobs=None, penalty=None, random_state=42, shuffle=True, tol=0.01,\n",
      "      validation_fraction=0.1, verbose=0, warm_start=False) \n",
      "Model Score: 66.00 %\n",
      "Confusion Matrix:\n",
      " [[15  0  0]\n",
      " [15  0  2]\n",
      " [ 0  0 18]] \n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-08) \n",
      "Model Score: 88.00 %\n",
      "Confusion Matrix:\n",
      " [[15  0  0]\n",
      " [ 0 12  5]\n",
      " [ 0  1 17]] \n",
      "\n",
      "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=42, tol=0.0001,\n",
      "     verbose=0) \n",
      "Model Score: 94.00 %\n",
      "Confusion Matrix:\n",
      " [[15  0  0]\n",
      " [ 0 14  3]\n",
      " [ 0  0 18]] \n",
      "\n",
      "AdaBoostClassifier(algorithm='SAMME.R',\n",
      "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best'),\n",
      "          learning_rate=1.0, n_estimators=1, random_state=None) \n",
      "Model Score: 86.00 %\n",
      "Confusion Matrix:\n",
      " [[15  0  0]\n",
      " [ 0 13  4]\n",
      " [ 0  3 15]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=5,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=42,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False) \n",
      "Model Score: 90.00 %\n",
      "Confusion Matrix:\n",
      " [[15  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  3 15]] \n",
      "\n",
      "MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(15,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=42, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False) \n",
      "Model Score: 92.00 %\n",
      "Confusion Matrix:\n",
      " [[15  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  2 16]] \n",
      "\n",
      "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
      "              solver='svd', store_covariance=False, tol=0.0001) \n",
      "Model Score: 96.00 %\n",
      "Confusion Matrix:\n",
      " [[15  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  0 18]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = []\n",
    "scores = []\n",
    "for name, model in models:\n",
    "  X_train, X_test, y_train, y_test = X, test_data, y, real_data\n",
    "\n",
    "  # treinar o modelo\n",
    "  model.fit(X_train, y_train)\n",
    "\n",
    "  # calcular precisão (forma simples)\n",
    "  score = model.score(X_test, y_test) * 100\n",
    "  print(model, '\\nModel Score: %.2f %%' % score)\n",
    "\n",
    "  # exibir matriz de confusão\n",
    "  y_pred = model.predict(X_test)\n",
    "  cm = confusion_matrix(y_test, y_pred)\n",
    "  print('Confusion Matrix:\\n', cm, '\\n')\n",
    "    \n",
    "  names.append(name)\n",
    "  scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LDA</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LSVM</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLP</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ABDT</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GB</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NB</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NN</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGD</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Score\n",
       "12   LDA   96.0\n",
       "2    KNN   94.0\n",
       "4     RF   94.0\n",
       "8   LSVM   94.0\n",
       "0     LR   92.0\n",
       "3    SVM   92.0\n",
       "11   MLP   92.0\n",
       "9   ABDT   90.0\n",
       "10    GB   90.0\n",
       "7     NB   88.0\n",
       "1     DT   86.0\n",
       "6     NN   66.0\n",
       "5    SGD   62.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'Model': names, 'Score': scores})\n",
    "results.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
