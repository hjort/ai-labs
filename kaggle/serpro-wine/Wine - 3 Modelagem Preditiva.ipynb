{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação dos pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar pacotes necessários\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir parâmetros extras\n",
    "pd.set_option('precision', 4)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixo_arquivos = ''\n",
    "#prefixo_arquivos = 'https://github.com/hjort/ai-labs/raw/master/kaggle/serpro-wine/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3265, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carregar arquivo de dados de treino\n",
    "train_data = pd.read_csv(prefixo_arquivos + 'wine-train.csv', index_col='wine')\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1633, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carregar arquivo de dados de teste\n",
    "test_data = pd.read_csv(prefixo_arquivos + 'wine-test.csv', index_col='wine')\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4898, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>density</th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>ph</th>\n",
       "      <th>quality</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>volatile_acidity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wine</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3472</th>\n",
       "      <td>10.5</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>6.7</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>bad</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3455</th>\n",
       "      <td>12.2</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.9893</td>\n",
       "      <td>7.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.90</td>\n",
       "      <td>bad</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.38</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3322</th>\n",
       "      <td>12.5</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.9899</td>\n",
       "      <td>5.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.48</td>\n",
       "      <td>good</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.52</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>12.8</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.9887</td>\n",
       "      <td>5.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.34</td>\n",
       "      <td>good</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.38</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.9967</td>\n",
       "      <td>6.8</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3.05</td>\n",
       "      <td>bad</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.38</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      alcohol  chlorides  citric_acid  density  fixed_acidity  \\\n",
       "wine                                                            \n",
       "3472     10.5      0.045         0.36   0.9928            6.7   \n",
       "3455     12.2      0.031         0.24   0.9893            7.3   \n",
       "3322     12.5      0.039         0.30   0.9899            5.7   \n",
       "4896     12.8      0.022         0.30   0.9887            5.5   \n",
       "2123      9.0      0.076         0.27   0.9967            6.8   \n",
       "\n",
       "      free_sulfur_dioxide    ph quality  residual_sugar  sulphates  \\\n",
       "wine                                                                 \n",
       "3472                 24.0  3.30     bad             2.0       0.59   \n",
       "3455                 29.0  2.90     bad             0.9       0.38   \n",
       "3322                 30.0  3.48    good             1.8       0.52   \n",
       "4896                 20.0  3.34    good             1.1       0.38   \n",
       "2123                 47.0  3.05     bad            10.7       0.38   \n",
       "\n",
       "      total_sulfur_dioxide  volatile_acidity  \n",
       "wine                                          \n",
       "3472                 131.0              0.16  \n",
       "3455                  86.0              0.23  \n",
       "3322                 105.0              0.26  \n",
       "4896                 110.0              0.29  \n",
       "2123                 154.0              0.25  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unir ambos os dados de treino e teste\n",
    "data = pd.concat([train_data, test_data])\n",
    "print(data.shape)\n",
    "\n",
    "# mostrar alguns exemplos de registros\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformações nos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorizar os valores dos sexos\n",
    "data['quality'].fillna('unknown', inplace=True)\n",
    "data['quality'] = data['quality'].map({'good': 1, 'bad': 0, 'unknown': -1}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>density</th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>ph</th>\n",
       "      <th>quality</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>volatile_acidity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wine</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3472</th>\n",
       "      <td>10.5</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>6.7</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3455</th>\n",
       "      <td>12.2</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.9893</td>\n",
       "      <td>7.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.38</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3322</th>\n",
       "      <td>12.5</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.9899</td>\n",
       "      <td>5.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.48</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.52</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>12.8</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.9887</td>\n",
       "      <td>5.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.34</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.38</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.9967</td>\n",
       "      <td>6.8</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.38</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      alcohol  chlorides  citric_acid  density  fixed_acidity  \\\n",
       "wine                                                            \n",
       "3472     10.5      0.045         0.36   0.9928            6.7   \n",
       "3455     12.2      0.031         0.24   0.9893            7.3   \n",
       "3322     12.5      0.039         0.30   0.9899            5.7   \n",
       "4896     12.8      0.022         0.30   0.9887            5.5   \n",
       "2123      9.0      0.076         0.27   0.9967            6.8   \n",
       "\n",
       "      free_sulfur_dioxide    ph  quality  residual_sugar  sulphates  \\\n",
       "wine                                                                  \n",
       "3472                 24.0  3.30        0             2.0       0.59   \n",
       "3455                 29.0  2.90        0             0.9       0.38   \n",
       "3322                 30.0  3.48        1             1.8       0.52   \n",
       "4896                 20.0  3.34        1             1.1       0.38   \n",
       "2123                 47.0  3.05        0            10.7       0.38   \n",
       "\n",
       "      total_sulfur_dioxide  volatile_acidity  \n",
       "wine                                          \n",
       "3472                 131.0              0.16  \n",
       "3455                  86.0              0.23  \n",
       "3322                 105.0              0.26  \n",
       "4896                 110.0              0.29  \n",
       "2123                 154.0              0.25  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['alcohol', 'chlorides', 'citric_acid', 'density', 'fixed_acidity',\n",
       "       'free_sulfur_dioxide', 'ph', 'quality', 'residual_sugar',\n",
       "       'sulphates', 'total_sulfur_dioxide', 'volatile_acidity'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
     ]
    }
   ],
   "source": [
    "# realizar normalização nos dados numéricos contínuos\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "print(scaler)\n",
    "\n",
    "cols = ['alcohol', 'chlorides', 'citric_acid', 'density', 'fixed_acidity', 'free_sulfur_dioxide',\n",
    "        'ph', 'residual_sugar', 'sulphates', 'total_sulfur_dioxide', 'volatile_acidity']\n",
    "\n",
    "#for col in cols:\n",
    "data.loc[:,cols] = scaler.fit_transform(data.loc[:,cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>density</th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>ph</th>\n",
       "      <th>quality</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>volatile_acidity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wine</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3472</th>\n",
       "      <td>0.4032</td>\n",
       "      <td>0.1068</td>\n",
       "      <td>0.2169</td>\n",
       "      <td>0.1105</td>\n",
       "      <td>0.2788</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>0.5273</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.4302</td>\n",
       "      <td>0.2831</td>\n",
       "      <td>0.0784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3455</th>\n",
       "      <td>0.6774</td>\n",
       "      <td>0.0653</td>\n",
       "      <td>0.1446</td>\n",
       "      <td>0.0414</td>\n",
       "      <td>0.3365</td>\n",
       "      <td>0.0941</td>\n",
       "      <td>0.1636</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.1787</td>\n",
       "      <td>0.1471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3322</th>\n",
       "      <td>0.7258</td>\n",
       "      <td>0.0890</td>\n",
       "      <td>0.1807</td>\n",
       "      <td>0.0548</td>\n",
       "      <td>0.1827</td>\n",
       "      <td>0.0976</td>\n",
       "      <td>0.6909</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.3488</td>\n",
       "      <td>0.2227</td>\n",
       "      <td>0.1765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>0.7742</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.1807</td>\n",
       "      <td>0.0305</td>\n",
       "      <td>0.1635</td>\n",
       "      <td>0.0627</td>\n",
       "      <td>0.5636</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2343</td>\n",
       "      <td>0.2059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>0.1613</td>\n",
       "      <td>0.1988</td>\n",
       "      <td>0.1627</td>\n",
       "      <td>0.1849</td>\n",
       "      <td>0.2885</td>\n",
       "      <td>0.1568</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1549</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.3364</td>\n",
       "      <td>0.1667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      alcohol  chlorides  citric_acid  density  fixed_acidity  \\\n",
       "wine                                                            \n",
       "3472   0.4032     0.1068       0.2169   0.1105         0.2788   \n",
       "3455   0.6774     0.0653       0.1446   0.0414         0.3365   \n",
       "3322   0.7258     0.0890       0.1807   0.0548         0.1827   \n",
       "4896   0.7742     0.0386       0.1807   0.0305         0.1635   \n",
       "2123   0.1613     0.1988       0.1627   0.1849         0.2885   \n",
       "\n",
       "      free_sulfur_dioxide      ph  quality  residual_sugar  sulphates  \\\n",
       "wine                                                                    \n",
       "3472               0.0767  0.5273        0          0.0215     0.4302   \n",
       "3455               0.0941  0.1636        0          0.0046     0.1860   \n",
       "3322               0.0976  0.6909        1          0.0184     0.3488   \n",
       "4896               0.0627  0.5636        1          0.0077     0.1860   \n",
       "2123               0.1568  0.3000        0          0.1549     0.1860   \n",
       "\n",
       "      total_sulfur_dioxide  volatile_acidity  \n",
       "wine                                          \n",
       "3472                0.2831            0.0784  \n",
       "3455                0.1787            0.1471  \n",
       "3322                0.2227            0.1765  \n",
       "4896                0.2343            0.2059  \n",
       "2123                0.3364            0.1667  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem preditiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar os pacotes necessários para os algoritmos de classificação\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# avalia o desempenho do modelo, retornando o valor da precisão\n",
    "def evaluate_classification_model(model, X, y):\n",
    "    start = datetime.now()\n",
    "    kfold = KFold(n_splits=10, random_state=42)\n",
    "    results = cross_val_score(model, X, y, cv=kfold, scoring='accuracy', verbose=1)\n",
    "    end = datetime.now()\n",
    "    elapsed = int((end - start).total_seconds() * 1000)\n",
    "    score = 100.0 * results.mean()\n",
    "    stddev = 100.0 * results.std()\n",
    "    print(model, '\\nScore: %.2f (+/- %.2f) [%5s ms]' % (score, stddev, elapsed))\n",
    "    return score, stddev, elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# faz o ajuste fino do modelo, calculando os melhores hiperparâmetros\n",
    "def fine_tune_model(model, params, X, y):\n",
    "    print('\\nFine Tuning Model:')\n",
    "    print(model, \"\\nparams:\", params)\n",
    "    kfold = KFold(n_splits=10, random_state=42)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=params, scoring='accuracy', cv=kfold, verbose=1)\n",
    "    grid.fit(X, y)\n",
    "    print('\\nGrid Best Score: %.2f' % (grid.best_score_ * 100.0))\n",
    "    print('Best Params:', grid.best_params_)\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma dos dados de treino: (3265, 11) (3265,)\n"
     ]
    }
   ],
   "source": [
    "# definir dados de treino\n",
    "train_data = data[data.quality >= 0]\n",
    "\n",
    "# selecionar atributos para o modelo\n",
    "cols = ['alcohol', 'chlorides', 'citric_acid', 'density', 'fixed_acidity', 'free_sulfur_dioxide',\n",
    "        'ph', 'residual_sugar', 'sulphates', 'total_sulfur_dioxide', 'volatile_acidity']\n",
    "\n",
    "X_train = train_data[cols]\n",
    "y_train = train_data['quality']\n",
    "\n",
    "print('Forma dos dados de treino:', X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>density</th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>ph</th>\n",
       "      <th>quality</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>volatile_acidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alcohol</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.3581</td>\n",
       "      <td>-0.0808</td>\n",
       "      <td>-0.7774</td>\n",
       "      <td>-0.1191</td>\n",
       "      <td>-0.2621</td>\n",
       "      <td>0.1185</td>\n",
       "      <td>0.3935</td>\n",
       "      <td>-0.4650</td>\n",
       "      <td>-0.0085</td>\n",
       "      <td>-0.4566</td>\n",
       "      <td>0.0664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chlorides</th>\n",
       "      <td>-0.3581</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1128</td>\n",
       "      <td>0.2525</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.1097</td>\n",
       "      <td>-0.0942</td>\n",
       "      <td>-0.1902</td>\n",
       "      <td>0.0897</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.2036</td>\n",
       "      <td>0.0714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citric_acid</th>\n",
       "      <td>-0.0808</td>\n",
       "      <td>0.1128</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1575</td>\n",
       "      <td>0.2772</td>\n",
       "      <td>0.1033</td>\n",
       "      <td>-0.1517</td>\n",
       "      <td>-0.0366</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0710</td>\n",
       "      <td>0.1388</td>\n",
       "      <td>-0.1391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density</th>\n",
       "      <td>-0.7774</td>\n",
       "      <td>0.2525</td>\n",
       "      <td>0.1575</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2649</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>-0.0875</td>\n",
       "      <td>-0.2851</td>\n",
       "      <td>0.8480</td>\n",
       "      <td>0.0717</td>\n",
       "      <td>0.5420</td>\n",
       "      <td>0.0359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fixed_acidity</th>\n",
       "      <td>-0.1191</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.2772</td>\n",
       "      <td>0.2649</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.0358</td>\n",
       "      <td>-0.4209</td>\n",
       "      <td>-0.0804</td>\n",
       "      <td>0.0994</td>\n",
       "      <td>-0.0127</td>\n",
       "      <td>0.1106</td>\n",
       "      <td>-0.0087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <td>-0.2621</td>\n",
       "      <td>0.1097</td>\n",
       "      <td>0.1033</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>-0.0358</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>-0.0372</td>\n",
       "      <td>0.3302</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.6324</td>\n",
       "      <td>-0.0936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ph</th>\n",
       "      <td>0.1185</td>\n",
       "      <td>-0.0942</td>\n",
       "      <td>-0.1517</td>\n",
       "      <td>-0.0875</td>\n",
       "      <td>-0.4209</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0992</td>\n",
       "      <td>-0.1847</td>\n",
       "      <td>0.1396</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>-0.0388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <td>0.3935</td>\n",
       "      <td>-0.1902</td>\n",
       "      <td>-0.0366</td>\n",
       "      <td>-0.2851</td>\n",
       "      <td>-0.0804</td>\n",
       "      <td>-0.0372</td>\n",
       "      <td>0.0992</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.1219</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>-0.1669</td>\n",
       "      <td>-0.0670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residual_sugar</th>\n",
       "      <td>-0.4650</td>\n",
       "      <td>0.0897</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.8480</td>\n",
       "      <td>0.0994</td>\n",
       "      <td>0.3302</td>\n",
       "      <td>-0.1847</td>\n",
       "      <td>-0.1219</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.0151</td>\n",
       "      <td>0.4217</td>\n",
       "      <td>0.0672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sulphates</th>\n",
       "      <td>-0.0085</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0710</td>\n",
       "      <td>0.0717</td>\n",
       "      <td>-0.0127</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.1396</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>-0.0151</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>-0.0258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <td>-0.4566</td>\n",
       "      <td>0.2036</td>\n",
       "      <td>0.1388</td>\n",
       "      <td>0.5420</td>\n",
       "      <td>0.1106</td>\n",
       "      <td>0.6324</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>-0.1669</td>\n",
       "      <td>0.4217</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volatile_acidity</th>\n",
       "      <td>0.0664</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>-0.1391</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>-0.0087</td>\n",
       "      <td>-0.0936</td>\n",
       "      <td>-0.0388</td>\n",
       "      <td>-0.0670</td>\n",
       "      <td>0.0672</td>\n",
       "      <td>-0.0258</td>\n",
       "      <td>0.0883</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      alcohol  chlorides  citric_acid  density  fixed_acidity  \\\n",
       "alcohol                1.0000    -0.3581      -0.0808  -0.7774        -0.1191   \n",
       "chlorides             -0.3581     1.0000       0.1128   0.2525         0.0142   \n",
       "citric_acid           -0.0808     0.1128       1.0000   0.1575         0.2772   \n",
       "density               -0.7774     0.2525       0.1575   1.0000         0.2649   \n",
       "fixed_acidity         -0.1191     0.0142       0.2772   0.2649         1.0000   \n",
       "free_sulfur_dioxide   -0.2621     0.1097       0.1033   0.3196        -0.0358   \n",
       "ph                     0.1185    -0.0942      -0.1517  -0.0875        -0.4209   \n",
       "quality                0.3935    -0.1902      -0.0366  -0.2851        -0.0804   \n",
       "residual_sugar        -0.4650     0.0897       0.1040   0.8480         0.0994   \n",
       "sulphates             -0.0085     0.0124       0.0710   0.0717        -0.0127   \n",
       "total_sulfur_dioxide  -0.4566     0.2036       0.1388   0.5420         0.1106   \n",
       "volatile_acidity       0.0664     0.0714      -0.1391   0.0359        -0.0087   \n",
       "\n",
       "                      free_sulfur_dioxide      ph  quality  residual_sugar  \\\n",
       "alcohol                           -0.2621  0.1185   0.3935         -0.4650   \n",
       "chlorides                          0.1097 -0.0942  -0.1902          0.0897   \n",
       "citric_acid                        0.1033 -0.1517  -0.0366          0.1040   \n",
       "density                            0.3196 -0.0875  -0.2851          0.8480   \n",
       "fixed_acidity                     -0.0358 -0.4209  -0.0804          0.0994   \n",
       "free_sulfur_dioxide                1.0000  0.0078  -0.0372          0.3302   \n",
       "ph                                 0.0078  1.0000   0.0992         -0.1847   \n",
       "quality                           -0.0372  0.0992   1.0000         -0.1219   \n",
       "residual_sugar                     0.3302 -0.1847  -0.1219          1.0000   \n",
       "sulphates                          0.0530  0.1396   0.0229         -0.0151   \n",
       "total_sulfur_dioxide               0.6324  0.0069  -0.1669          0.4217   \n",
       "volatile_acidity                  -0.0936 -0.0388  -0.0670          0.0672   \n",
       "\n",
       "                      sulphates  total_sulfur_dioxide  volatile_acidity  \n",
       "alcohol                 -0.0085               -0.4566            0.0664  \n",
       "chlorides                0.0124                0.2036            0.0714  \n",
       "citric_acid              0.0710                0.1388           -0.1391  \n",
       "density                  0.0717                0.5420            0.0359  \n",
       "fixed_acidity           -0.0127                0.1106           -0.0087  \n",
       "free_sulfur_dioxide      0.0530                0.6324           -0.0936  \n",
       "ph                       0.1396                0.0069           -0.0388  \n",
       "quality                  0.0229               -0.1669           -0.0670  \n",
       "residual_sugar          -0.0151                0.4217            0.0672  \n",
       "sulphates                1.0000                0.1217           -0.0258  \n",
       "total_sulfur_dioxide     0.1217                1.0000            0.0883  \n",
       "volatile_acidity        -0.0258                0.0883            1.0000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma dos dados de teste: (1633, 11)\n"
     ]
    }
   ],
   "source": [
    "# definir dados de teste\n",
    "test_data = data[data.quality < 0]\n",
    "\n",
    "X_test = test_data[cols]\n",
    "\n",
    "print('Forma dos dados de teste:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "models = []\n",
    "scores = []\n",
    "stddevs = []\n",
    "times = []\n",
    "\n",
    "def add_model_info(name, model, score, stddev, elapsed):\n",
    "    names.append(name)\n",
    "    models.append((name, model))\n",
    "    scores.append(score)\n",
    "    stddevs.append(stddev)\n",
    "    times.append(elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação e ajuste fino de cada modelo preditivo\n",
    "\n",
    "-  https://scikit-learn.org/stable/modules/classes.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalized Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) \n",
      "Score: 78.65 (+/- 2.22) [ 2314 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.3s finished\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=42, solver='newton-cg', C=0.1, multi_class='auto', max_iter=500)\n",
    "\n",
    "params = dict(\n",
    "    solver=['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    C=np.logspace(-3, 3, 7)\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('LR', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=0.25,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=42, splitter='best') \n",
      "Score: 79.11 (+/- 1.92) [  834 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=42, criterion='entropy', max_depth=6, min_samples_split=0.25)\n",
    "\n",
    "#criterion=’mse’, splitter=’best’, max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, \n",
    "#min_impurity_decrease=0.0, min_impurity_split=None, presort=False\n",
    "\n",
    "params = dict(\n",
    "    criterion=['gini','entropy'],\n",
    "    max_depth=[4, 6, 8, 10, 12, 14],\n",
    "    min_samples_split=[0.25, 0.5, 0.75, 1.0]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('DT', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
      "                           solver='lsqr', store_covariance=False, tol=0.0001) \n",
      "Score: 80.09 (+/- 1.44) [  890 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "model = LinearDiscriminantAnalysis(solver='lsqr')\n",
    "\n",
    "#solver=’svd’, shrinkage=None, priors=None,\n",
    "#n_components=None, store_covariance=False, tol=0.0001\n",
    "\n",
    "params = dict(\n",
    "    solver=['svd', 'lsqr'] #, 'eigen']\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('LDA', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=1e-08) \n",
      "Score: 72.59 (+/- 1.96) [  446 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB(priors=None, var_smoothing=1e-8)\n",
    "\n",
    "#priors=None, var_smoothing=1e-09\n",
    "\n",
    "params = dict(\n",
    "    priors=[None],\n",
    "    var_smoothing=[1e-8, 1e-7, 1e-6, 1e-5, 1e-4]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('NB', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=11, p=2,\n",
      "                     weights='uniform') \n",
      "Score: 81.20 (+/- 1.83) [ 2323 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.3s finished\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=11, weights='uniform')\n",
    "\n",
    "#n_neighbors=5, weights=’uniform’, algorithm=’auto’, leaf_size=30, p=2, metric=’minkowski’,\n",
    "#metric_params=None, n_jobs=None\n",
    "\n",
    "params = dict(\n",
    "    n_neighbors=[1, 3, 5, 7, 9, 11, 13],\n",
    "    weights=['uniform', 'distance']\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('KNN', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
      "    verbose=False) \n",
      "Score: 78.25 (+/- 2.17) [20388 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   20.4s finished\n"
     ]
    }
   ],
   "source": [
    "model = SVC(random_state=42, C=10, gamma=0.1, kernel='rbf')\n",
    "\n",
    "#kernel=’rbf’, degree=3, gamma=’auto_deprecated’, coef0=0.0, tol=0.001, C=1.0, \n",
    "#epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1\n",
    "\n",
    "params = dict(\n",
    "    C=[0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    gamma=[0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    kernel=['linear', 'rbf']\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('SVM', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='logistic', alpha=1, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=42, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False) \n",
      "Score: 80.03 (+/- 1.67) [116053 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.9min finished\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(random_state=42, solver='lbfgs', alpha=1, hidden_layer_sizes=(100,), activation='logistic')\n",
    "                \n",
    "#hidden_layer_sizes=(100, ), activation=’relu’, solver=’adam’, alpha=0.0001, batch_size=’auto’, \n",
    "#learning_rate=’constant’, learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, \n",
    "#random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, \n",
    "#early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10\n",
    "\n",
    "params = dict(\n",
    "    alpha=[1,0.1,0.01,0.001,0.0001,0],\n",
    "    hidden_layer_sizes=[(100,), (50,), (50,2), (5,5,2), (10,5,2)],\n",
    "    activation=['identity', 'logistic', 'tanh', 'relu'],\n",
    "    solver=['lbfgs', 'sgd', 'adam']\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('MLP', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R',\n",
      "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
      "                                                         criterion='gini',\n",
      "                                                         max_depth=None,\n",
      "                                                         max_features=None,\n",
      "                                                         max_leaf_nodes=None,\n",
      "                                                         min_impurity_decrease=0.0,\n",
      "                                                         min_impurity_split=None,\n",
      "                                                         min_samples_leaf=1,\n",
      "                                                         min_samples_split=2,\n",
      "                                                         min_weight_fraction_leaf=0.0,\n",
      "                                                         presort=False,\n",
      "                                                         random_state=42,\n",
      "                                                         splitter='best'),\n",
      "                   learning_rate=1.0, n_estimators=50, random_state=42) \n",
      "Score: 80.95 (+/- 2.39) [ 2037 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.0s finished\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier(DecisionTreeClassifier(random_state=42), random_state=42, n_estimators=50)\n",
    "\n",
    "#base_estimator=None, n_estimators=50, learning_rate=1.0,\n",
    "#algorithm=’SAMME.R’, random_state=None\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[10, 25, 50, 100]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('ABDT', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
      "                  max_features=0.8, max_samples=0.25, n_estimators=100,\n",
      "                  n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                  warm_start=False) \n",
      "Score: 84.29 (+/- 1.57) [33024 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   33.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "model = BaggingClassifier(random_state=42, n_estimators=100,\n",
    "                          max_samples=0.25, max_features=0.8)\n",
    "\n",
    "#base_estimator=None, n_estimators=10, max_samples=1.0, max_features=1.0,\n",
    "#bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False,\n",
    "#n_jobs=None, random_state=None, verbose=0\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[10, 50, 100, 500],\n",
    "    max_samples=[0.25, 0.5, 0.75, 1.0],\n",
    "    max_features=[0.7, 0.8, 0.9, 1.0]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('BC', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                     max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=0.25,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                     n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                     warm_start=False) \n",
      "Score: 78.22 (+/- 2.16) [13497 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   13.5s finished\n"
     ]
    }
   ],
   "source": [
    "model = ExtraTreesClassifier(random_state=42, n_estimators=100, max_depth=7, \n",
    "                             min_samples_split=0.25, max_features='auto')\n",
    "\n",
    "#n_estimators=’warn’, criterion=’gini’, max_depth=None, min_samples_split=2,\n",
    "#min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=’auto’, \n",
    "#max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, \n",
    "#bootstrap=False, oob_score=False, n_jobs=None, random_state=None, verbose=0,\n",
    "#warm_start=False, class_weight=None\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[10, 50, 100, 500],\n",
    "    max_depth=[None, 3, 7, 11],\n",
    "    min_samples_split=[0.25, 0.5],\n",
    "    max_features=['auto', 0.7, 0.85, 1.0]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('ET', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=4,\n",
      "                           max_features=0.75, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=42, subsample=0.6, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False) \n",
      "Score: 83.58 (+/- 1.86) [26575 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   26.6s finished\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(random_state=42, n_estimators=100, max_features=0.75,\n",
    "                                   max_depth=4, learning_rate=0.1, subsample=0.6)\n",
    "\n",
    "#loss=’ls’, learning_rate=0.1, n_estimators=100, subsample=1.0, criterion=’friedman_mse’, min_samples_split=2,\n",
    "#min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, \n",
    "#min_impurity_split=None, init=None, random_state=None, max_features=None, alpha=0.9, verbose=0, \n",
    "#max_leaf_nodes=None, warm_start=False, presort=’auto’, validation_fraction=0.1, n_iter_no_change=None, \n",
    "#tol=0.0001\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[100, 250, 500],\n",
    "    max_features=[0.75, 0.85, 1.0],\n",
    "    max_depth=[4, 6, 8, 10],\n",
    "    learning_rate=[0.05, 0.1, 0.15],\n",
    "    subsample=[0.4, 0.6, 0.8]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('GB', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False) \n",
      "Score: 81.62 (+/- 1.51) [25028 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   25.0s finished\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42, n_estimators=100, max_features='auto', max_depth=5)\n",
    "\n",
    "#n_estimators=’warn’, criterion=’mse’, max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#min_weight_fraction_leaf=0.0, max_features=’auto’, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, \n",
    "#verbose=0, warm_start=False\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[10, 50, 100, 500],\n",
    "    max_features=['auto', 'sqrt', 'log2'],\n",
    "    max_depth=[None, 3, 5, 7, 9, 11, 13]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('RF', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outros algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost\n",
    "\n",
    "- https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1) \n",
      "Score: 82.57 (+/- 1.80) [15027 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   15.0s finished\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(max_depth=3, n_estimators=100)\n",
    "\n",
    "#max_depth=3, learning_rate=0.1, n_estimators=100, verbosity=1, silent=None, objective='reg:squarederror',\n",
    "#booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, \n",
    "#colsample_bytree=1, colsample_bylevel=1, colsample_bynode=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, \n",
    "#base_score=0.5, random_state=0, seed=None, missing=None, importance_type='gain'\n",
    "\n",
    "params = dict(\n",
    "    max_depth=[3, 5, 7, 9],\n",
    "    n_estimators=[50, 75, 100, 200]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('XGB', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Abaixo é criado um classificador MLP com 20 neurônios na camada intermediária e dropout de 50%. Foi utilizada a função de ativação sigmoid, a função de loss mean squared error e o otimizador RMSProp. O treinamento é realizado por 200 épocas com batch size de 64.\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=X_train.shape[1], activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mse', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hist = model.fit(X_train, y_train, batch_size=64, nb_epoch=200, verbose=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def plot_line(loss, ylabel, xlabel='Epochs'):\n",
    "    fig = plt.figure()\n",
    "    plt.plot(loss)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_line(hist.history['acc'], 'accuracy')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_line(hist.history['loss'], 'loss')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "loss, accuracy = model.evaluate(v_X, v_y)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prefixo_arquivo = 'submissions/titanic-submission'\n",
    "sufixo_arquivo = '07jul'\n",
    "name = 'mlptf'\n",
    "\n",
    "print(model, '\\n')\n",
    "\n",
    "# executar previsão usando o modelo\n",
    "y_pred = model.predict(X_test).ravel()\n",
    "vfunc = np.vectorize(lambda x: 'yes' if x > 0.5 else 'no')\n",
    "\n",
    "# gerar dados de envio (submissão)\n",
    "submission = pd.DataFrame({\n",
    "  'person': X_test.index,\n",
    "  'survived': vfunc(y_pred)\n",
    "})\n",
    "submission.set_index('person', inplace=True)\n",
    "\n",
    "# gerar arquivo CSV para o envio\n",
    "filename = '%s-p-%s-%s.csv' % (prefixo_arquivo, sufixo_arquivo, name.lower())\n",
    "submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM\n",
    "\n",
    "- https://github.com/microsoft/LightGBM\n",
    "- https://lightgbm.readthedocs.io/en/latest/\n",
    "- https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "model = LGBMClassifier(random_state=42, objective='binary', metric='binary_logloss',\n",
    "                      boosting_type='goss', n_estimators=50, max_depth=11)\n",
    "\n",
    "params = dict(\n",
    "    boosting_type=['gbdt', 'dart', 'goss'], #rf\n",
    "    objective=['binary'],\n",
    "    metric=['binary_logloss'],\n",
    "    #bagging_freq=[1, 5, 10],\n",
    "    #bagging_fraction=[0.25, 0.5],\n",
    "    n_estimators=[50, 75, 100, 200],\n",
    "    max_depth=[3, 5, 7, 9, 11]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('LGBM', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "d_train = lgb.Dataset(X_train.values, label=y_train.values)\n",
    "\n",
    "params = {}\n",
    "params['random_state'] = 42\n",
    "params['objective'] = 'binary'\n",
    "params['boosting_type'] = 'goss' # gbdt, rf, dart, goss\n",
    "\n",
    "#params['learning_rate'] = 0.003\n",
    "#params['metric'] = 'binary_logloss'\n",
    "#params['sub_feature'] = 0.5\n",
    "#params['num_leaves'] = 10\n",
    "#params['min_data'] = 50\n",
    "#params['max_depth'] = 10\n",
    "\n",
    "#model = lgb.train(params, d_train, 100)\n",
    "model = lgb.cv(params, d_train, 100, nfold=10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prefixo_arquivo = 'submissions/titanic-submission'\n",
    "sufixo_arquivo = '08jul'\n",
    "name = 'lgbm_' + params['boosting_type']\n",
    "\n",
    "print(model, '\\n')\n",
    "\n",
    "# executar previsão usando o modelo\n",
    "y_pred = clf.predict(X_test.values)\n",
    "vfunc = np.vectorize(lambda x: 'yes' if x > 0.5 else 'no')\n",
    "\n",
    "# gerar dados de envio (submissão)\n",
    "submission = pd.DataFrame({\n",
    "  'person': X_test.index,\n",
    "  'survived': vfunc(y_pred)\n",
    "})\n",
    "submission.set_index('person', inplace=True)\n",
    "\n",
    "# gerar arquivo CSV para o envio\n",
    "filename = '%s-p-%s-%s.csv' % (prefixo_arquivo, sufixo_arquivo, name.lower())\n",
    "submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Learning Model\n",
    "\n",
    "- https://towardsdatascience.com/automate-stacking-in-python-fc3e7834772e\n",
    "- https://github.com/vecxoz/vecstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier(estimators=[('RF',\n",
      "                              RandomForestClassifier(bootstrap=True,\n",
      "                                                     class_weight=None,\n",
      "                                                     criterion='gini',\n",
      "                                                     max_depth=5,\n",
      "                                                     max_features='auto',\n",
      "                                                     max_leaf_nodes=None,\n",
      "                                                     min_impurity_decrease=0.0,\n",
      "                                                     min_impurity_split=None,\n",
      "                                                     min_samples_leaf=1,\n",
      "                                                     min_samples_split=2,\n",
      "                                                     min_weight_fraction_leaf=0.0,\n",
      "                                                     n_estimators=100,\n",
      "                                                     n_jobs=None,\n",
      "                                                     oob_score=False,\n",
      "                                                     random_state=42, verbose=0,\n",
      "                                                     w...\n",
      "                                                         max_leaf_nodes=None,\n",
      "                                                         min_impurity_decrease=0.0,\n",
      "                                                         min_impurity_split=None,\n",
      "                                                         min_samples_leaf=1,\n",
      "                                                         min_samples_split=2,\n",
      "                                                         min_weight_fraction_leaf=0.0,\n",
      "                                                         n_estimators=100,\n",
      "                                                         n_iter_no_change=None,\n",
      "                                                         presort='auto',\n",
      "                                                         random_state=42,\n",
      "                                                         subsample=0.6,\n",
      "                                                         tol=0.0001,\n",
      "                                                         validation_fraction=0.1,\n",
      "                                                         verbose=0,\n",
      "                                                         warm_start=False))],\n",
      "                 flatten_transform=True, n_jobs=-1, voting='hard',\n",
      "                 weights=(2, 1, 1)) \n",
      "Score: 81.87 (+/- 1.54) [89509 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "estimators =  [\n",
    "    ('RF', RandomForestClassifier(random_state=42, n_estimators=100, max_features='auto', max_depth=5)),\n",
    "    ('BC', BaggingClassifier(random_state=42, n_estimators=100, max_samples=0.25, max_features=0.8)),\n",
    "    ('GB', GradientBoostingClassifier(random_state=42, max_depth=4, max_features=0.75,\n",
    "                                   n_estimators=100, learning_rate=0.1, subsample=0.6)),\n",
    "#    ('XGB', XGBClassifier(max_depth=3, n_estimators=100)),\n",
    "]\n",
    "model = VotingClassifier(estimators, n_jobs=-1, weights=(2,1,1))\n",
    "\n",
    "#estimators, weights=None, n_jobs=None\n",
    "\n",
    "params = dict(\n",
    "    weights=[(1,1,1), (2,1,1), (3,1,1), (3,2,1), (2,2,1), (2,1,2), (5,4,3), (1,2,1), (1,1,2), ]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('VC', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = SGDClassifier(random_state=42, max_iter=100, tol=0.1)\n",
    "\n",
    "params = {'max_iter':[100, 200, 350, 500, 1000], 'tol':[0.1, 0.01]}\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = Perceptron(random_state=42, max_iter=100, tol=0.01)\n",
    "\n",
    "params = dict(\n",
    "    max_iter=[100, 200, 350, 500, 1000],\n",
    "    tol=[0.1, 0.01, 0.001]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = LinearSVC(random_state=42, max_iter=1000, C=10)\n",
    "\n",
    "params = dict(\n",
    "    C=[0.001, 0.01, 0.1, 1, 10, 100]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliar importância dos atributos no modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alcohol</th>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density</th>\n",
       "      <td>0.134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residual_sugar</th>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chlorides</th>\n",
       "      <td>0.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ph</th>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volatile_acidity</th>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sulphates</th>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citric_acid</th>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fixed_acidity</th>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      importance\n",
       "feature                         \n",
       "alcohol                    0.150\n",
       "density                    0.134\n",
       "residual_sugar             0.090\n",
       "chlorides                  0.089\n",
       "ph                         0.088\n",
       "volatile_acidity           0.083\n",
       "free_sulfur_dioxide        0.080\n",
       "total_sulfur_dioxide       0.079\n",
       "sulphates                  0.072\n",
       "citric_acid                0.068\n",
       "fixed_acidity              0.068"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42, max_features='auto', n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "importances = pd.DataFrame({'feature': X_train.columns,\n",
    "                            'importance': np.round(model.feature_importances_, 3)})\n",
    "importances = importances.sort_values('importance', ascending=False).set_index('feature')\n",
    "importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xb5d6cbcc>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação final entre os algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Score</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Time (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BC</td>\n",
       "      <td>84.2870</td>\n",
       "      <td>1.5661</td>\n",
       "      <td>33024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GB</td>\n",
       "      <td>83.5829</td>\n",
       "      <td>1.8555</td>\n",
       "      <td>26575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGB</td>\n",
       "      <td>82.5723</td>\n",
       "      <td>1.8022</td>\n",
       "      <td>15027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>VC</td>\n",
       "      <td>81.8688</td>\n",
       "      <td>1.5363</td>\n",
       "      <td>89509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RF</td>\n",
       "      <td>81.6238</td>\n",
       "      <td>1.5070</td>\n",
       "      <td>25028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>81.1950</td>\n",
       "      <td>1.8325</td>\n",
       "      <td>2323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ABDT</td>\n",
       "      <td>80.9483</td>\n",
       "      <td>2.3943</td>\n",
       "      <td>2037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LDA</td>\n",
       "      <td>80.0910</td>\n",
       "      <td>1.4418</td>\n",
       "      <td>890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLP</td>\n",
       "      <td>80.0298</td>\n",
       "      <td>1.6675</td>\n",
       "      <td>116053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>79.1120</td>\n",
       "      <td>1.9210</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>78.6518</td>\n",
       "      <td>2.2223</td>\n",
       "      <td>2314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>78.2543</td>\n",
       "      <td>2.1684</td>\n",
       "      <td>20388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ET</td>\n",
       "      <td>78.2238</td>\n",
       "      <td>2.1612</td>\n",
       "      <td>13497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB</td>\n",
       "      <td>72.5881</td>\n",
       "      <td>1.9565</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Algorithm    Score  Std Dev  Time (ms)\n",
       "8         BC  84.2870   1.5661      33024\n",
       "10        GB  83.5829   1.8555      26575\n",
       "12       XGB  82.5723   1.8022      15027\n",
       "13        VC  81.8688   1.5363      89509\n",
       "11        RF  81.6238   1.5070      25028\n",
       "4        KNN  81.1950   1.8325       2323\n",
       "7       ABDT  80.9483   2.3943       2037\n",
       "2        LDA  80.0910   1.4418        890\n",
       "6        MLP  80.0298   1.6675     116053\n",
       "1         DT  79.1120   1.9210        834\n",
       "0         LR  78.6518   2.2223       2314\n",
       "5        SVM  78.2543   2.1684      20388\n",
       "9         ET  78.2238   2.1612      13497\n",
       "3         NB  72.5881   1.9565        446"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'Algorithm': names, 'Score': scores, 'Std Dev': stddevs, 'Time (ms)': times})\n",
    "results.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerar arquivos com resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar diretório para os arquivos de envio\n",
    "!test -d submissions || mkdir submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) \n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=0.25,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=42, splitter='best') \n",
      "\n",
      "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
      "                           solver='lsqr', store_covariance=False, tol=0.0001) \n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-08) \n",
      "\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=11, p=2,\n",
      "                     weights='uniform') \n",
      "\n",
      "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
      "    verbose=False) \n",
      "\n",
      "MLPClassifier(activation='logistic', alpha=1, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=42, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False) \n",
      "\n",
      "AdaBoostClassifier(algorithm='SAMME.R',\n",
      "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
      "                                                         criterion='gini',\n",
      "                                                         max_depth=None,\n",
      "                                                         max_features=None,\n",
      "                                                         max_leaf_nodes=None,\n",
      "                                                         min_impurity_decrease=0.0,\n",
      "                                                         min_impurity_split=None,\n",
      "                                                         min_samples_leaf=1,\n",
      "                                                         min_samples_split=2,\n",
      "                                                         min_weight_fraction_leaf=0.0,\n",
      "                                                         presort=False,\n",
      "                                                         random_state=42,\n",
      "                                                         splitter='best'),\n",
      "                   learning_rate=1.0, n_estimators=50, random_state=42) \n",
      "\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
      "                  max_features=0.8, max_samples=0.25, n_estimators=100,\n",
      "                  n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                  warm_start=False) \n",
      "\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                     max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=0.25,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                     n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                     warm_start=False) \n",
      "\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=4,\n",
      "                           max_features=0.75, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=42, subsample=0.6, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False) \n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False) \n",
      "\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1) \n",
      "\n",
      "VotingClassifier(estimators=[('RF',\n",
      "                              RandomForestClassifier(bootstrap=True,\n",
      "                                                     class_weight=None,\n",
      "                                                     criterion='gini',\n",
      "                                                     max_depth=5,\n",
      "                                                     max_features='auto',\n",
      "                                                     max_leaf_nodes=None,\n",
      "                                                     min_impurity_decrease=0.0,\n",
      "                                                     min_impurity_split=None,\n",
      "                                                     min_samples_leaf=1,\n",
      "                                                     min_samples_split=2,\n",
      "                                                     min_weight_fraction_leaf=0.0,\n",
      "                                                     n_estimators=100,\n",
      "                                                     n_jobs=None,\n",
      "                                                     oob_score=False,\n",
      "                                                     random_state=42, verbose=0,\n",
      "                                                     w...\n",
      "                                                         max_leaf_nodes=None,\n",
      "                                                         min_impurity_decrease=0.0,\n",
      "                                                         min_impurity_split=None,\n",
      "                                                         min_samples_leaf=1,\n",
      "                                                         min_samples_split=2,\n",
      "                                                         min_weight_fraction_leaf=0.0,\n",
      "                                                         n_estimators=100,\n",
      "                                                         n_iter_no_change=None,\n",
      "                                                         presort='auto',\n",
      "                                                         random_state=42,\n",
      "                                                         subsample=0.6,\n",
      "                                                         tol=0.0001,\n",
      "                                                         validation_fraction=0.1,\n",
      "                                                         verbose=0,\n",
      "                                                         warm_start=False))],\n",
      "                 flatten_transform=True, n_jobs=-1, voting='hard',\n",
      "                 weights=(2, 1, 1)) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prefixo_arquivo = 'submissions/wine-submission'\n",
    "sufixo_arquivo = '18ago'\n",
    "\n",
    "for name, model in models:\n",
    "    print(model, '\\n')\n",
    "    \n",
    "    # treinar o modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # executar previsão usando o modelo\n",
    "    y_pred = model.predict(X_test)\n",
    "    vfunc = np.vectorize(lambda x: 'good' if x > 0 else 'bad')\n",
    "\n",
    "    # gerar dados de envio (submissão)\n",
    "    submission = pd.DataFrame({\n",
    "      'wine': X_test.index,\n",
    "      'quality': vfunc(y_pred)\n",
    "    })\n",
    "    submission.set_index('wine', inplace=True)\n",
    "\n",
    "    # gerar arquivo CSV para o envio\n",
    "    filename = '%s-p-%s-%s.csv' % (prefixo_arquivo, sufixo_arquivo, name.lower())\n",
    "    submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> submissions/wine-submission-p-18ago-abdt.csv <==\r\n",
      "wine,quality\r\n",
      "1214,bad\r\n",
      "727,bad\r\n",
      "481,bad\r\n",
      "1308,bad\r\n",
      "4087,bad\r\n",
      "619,bad\r\n",
      "4669,bad\r\n",
      "874,bad\r\n",
      "2337,bad\r\n",
      "\r\n",
      "==> submissions/wine-submission-p-18ago-bc.csv <==\r\n",
      "wine,quality\r\n",
      "1214,bad\r\n",
      "727,bad\r\n",
      "481,bad\r\n",
      "1308,bad\r\n",
      "4087,bad\r\n",
      "619,bad\r\n",
      "4669,bad\r\n",
      "874,bad\r\n",
      "2337,bad\r\n",
      "\r\n",
      "==> submissions/wine-submission-p-18ago-dt.csv <==\r\n",
      "wine,quality\r\n",
      "1214,bad\r\n",
      "727,bad\r\n",
      "481,bad\r\n",
      "1308,bad\r\n",
      "4087,bad\r\n",
      "619,bad\r\n",
      "4669,bad\r\n",
      "874,bad\r\n",
      "2337,bad\r\n",
      "\r\n",
      "==> submissions/wine-submission-p-18ago-et.csv <==\r\n",
      "wine,quality\r\n",
      "1214,bad\r\n",
      "727,bad\r\n",
      "481,bad\r\n",
      "1308,bad\r\n",
      "4087,bad\r\n",
      "619,bad\r\n",
      "4669,bad\r\n",
      "874,bad\r\n",
      "2337,bad\r\n",
      "\r\n",
      "==> submissions/wine-submission-p-18ago-gb.csv <==\r\n",
      "wine,quality\r\n",
      "1214,bad\r\n",
      "727,bad\r\n",
      "481,bad\r\n",
      "1308,bad\r\n",
      "4087,bad\r\n",
      "619,bad\r\n",
      "4669,bad\r\n",
      "874,bad\r\n",
      "2337,bad\r\n",
      "\r\n",
      "==> submissions/wine-submission-p-18ago-knn.csv <==\r\n",
      "wine,quality\r\n",
      "1214,bad\r\n",
      "727,bad\r\n",
      "481,bad\r\n",
      "1308,bad\r\n",
      "4087,bad\r\n",
      "619,bad\r\n",
      "4669,bad\r\n",
      "874,bad\r\n",
      "2337,bad\r\n",
      "\r\n",
      "==> submissions/wine-submission-p-18ago-lda.csv <==\r\n",
      "wine,quality\r\n",
      "1214,bad\r\n",
      "727,bad\r\n",
      "481,bad\r\n",
      "1308,bad\r\n",
      "4087,bad\r\n",
      "619,bad\r\n",
      "4669,bad\r\n",
      "874,bad\r\n",
      "2337,bad\r\n",
      "\r\n",
      "==> submissions/wine-submission-p-18ago-lr.csv <==\r\n",
      "wine,quality\r\n",
      "1214,bad\r\n",
      "727,bad\r\n",
      "481,bad\r\n",
      "1308,bad\r\n",
      "4087,bad\r\n",
      "619,bad\r\n",
      "4669,bad\r\n",
      "874,bad\r\n",
      "2337,bad\r\n",
      "\r\n",
      "==> submissions/wine-submission-p-18ago-mlp.csv <==\r\n",
      "wine,quality\r\n",
      "1214,bad\r\n",
      "727,bad\r\n",
      "481,bad\r\n",
      "1308,bad\r\n",
      "4087,bad\r\n",
      "619,bad\r\n",
      "4669,bad\r\n",
      "874,bad\r\n",
      "2337,bad\r\n",
      "\r\n",
      "==> submissions/wine-submission-p-18ago-nb.csv <==\r\n",
      "wine,quality\r\n",
      "1214,bad\r\n",
      "727,bad\r\n",
      "481,good\r\n",
      "1308,bad\r\n",
      "4087,bad\r\n",
      "619,bad\r\n",
      "4669,good\r\n",
      "874,bad\r\n",
      "2337,bad\r\n",
      "\r\n",
      "==> submissions/wine-submission-p-18ago-rf.csv <==\r\n",
      "wine,quality\r\n",
      "1214,bad\r\n",
      "727,bad\r\n",
      "481,bad\r\n",
      "1308,bad\r\n",
      "4087,bad\r\n",
      "619,bad\r\n",
      "4669,bad\r\n",
      "874,bad\r\n",
      "2337,bad\r\n",
      "\r\n",
      "==> submissions/wine-submission-p-18ago-svm.csv <==\r\n",
      "wine,quality\r\n",
      "1214,bad\r\n",
      "727,bad\r\n",
      "481,bad\r\n",
      "1308,bad\r\n",
      "4087,bad\r\n",
      "619,bad\r\n",
      "4669,bad\r\n",
      "874,bad\r\n",
      "2337,bad\r\n",
      "\r\n",
      "==> submissions/wine-submission-p-18ago-vc.csv <==\r\n",
      "wine,quality\r\n",
      "1214,bad\r\n",
      "727,bad\r\n",
      "481,bad\r\n",
      "1308,bad\r\n",
      "4087,bad\r\n",
      "619,bad\r\n",
      "4669,bad\r\n",
      "874,bad\r\n",
      "2337,bad\r\n",
      "\r\n",
      "==> submissions/wine-submission-p-18ago-xgb.csv <==\r\n",
      "wine,quality\r\n",
      "1214,bad\r\n",
      "727,bad\r\n",
      "481,bad\r\n",
      "1308,bad\r\n",
      "4087,bad\r\n",
      "619,bad\r\n",
      "4669,bad\r\n",
      "874,bad\r\n",
      "2337,bad\r\n"
     ]
    }
   ],
   "source": [
    "!head submissions/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
