{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação dos pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar pacotes necessários\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir parâmetros extras\n",
    "pd.set_option('precision', 4)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixo_arquivos = ''\n",
    "#prefixo_arquivos = 'https://github.com/hjort/ai-labs/raw/master/kaggle/serpro-wine/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3265, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carregar arquivo de dados de treino\n",
    "train_data = pd.read_csv(prefixo_arquivos + 'wine-train.csv', index_col='wine')\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1633, 11)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carregar arquivo de dados de teste\n",
    "test_data = pd.read_csv(prefixo_arquivos + 'wine-test.csv', index_col='wine')\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4898, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>density</th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>ph</th>\n",
       "      <th>quality</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>volatile_acidity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wine</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>9.1</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>7.4</td>\n",
       "      <td>48.5</td>\n",
       "      <td>3.14</td>\n",
       "      <td>good</td>\n",
       "      <td>12.8</td>\n",
       "      <td>0.49</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>9.1</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>6.6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.12</td>\n",
       "      <td>bad</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.35</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3346</th>\n",
       "      <td>10.6</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>6.7</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.12</td>\n",
       "      <td>bad</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0.50</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308</th>\n",
       "      <td>10.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.9954</td>\n",
       "      <td>6.4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.20</td>\n",
       "      <td>bad</td>\n",
       "      <td>12.6</td>\n",
       "      <td>0.43</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>12.1</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>5.6</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.21</td>\n",
       "      <td>good</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.43</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      alcohol  chlorides  citric_acid  density  fixed_acidity  \\\n",
       "wine                                                            \n",
       "2169      9.1      0.053         0.30   0.9986            7.4   \n",
       "1382      9.1      0.045         0.16   0.9940            6.6   \n",
       "3346     10.6      0.057         0.24   0.9952            6.7   \n",
       "3308     10.6      0.039         0.28   0.9954            6.4   \n",
       "3167     12.1      0.034         0.40   0.9914            5.6   \n",
       "\n",
       "      free_sulfur_dioxide    ph quality  residual_sugar  sulphates  \\\n",
       "wine                                                                 \n",
       "2169                 48.5  3.14    good            12.8       0.49   \n",
       "1382                 28.0  3.12     bad             3.1       0.35   \n",
       "3346                 64.0  3.12     bad            10.3       0.50   \n",
       "3308                 19.0  3.20     bad            12.6       0.43   \n",
       "3167                 36.0  3.21    good             6.1       0.43   \n",
       "\n",
       "      total_sulfur_dioxide  volatile_acidity  \n",
       "wine                                          \n",
       "2169                 229.0              0.19  \n",
       "1382                  92.0              0.56  \n",
       "3346                 185.0              0.18  \n",
       "3308                 124.0              0.35  \n",
       "3167                 118.0              0.28  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unir ambos os dados de treino e teste\n",
    "data = pd.concat([train_data, test_data])\n",
    "print(data.shape)\n",
    "\n",
    "# mostrar alguns exemplos de registros\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformações nos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorizar os valores dos sexos\n",
    "data['quality'].fillna('unknown', inplace=True)\n",
    "data['quality'] = data['quality'].map({'good': 1, 'bad': 0, 'unknown': -1}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>density</th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>ph</th>\n",
       "      <th>quality</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>volatile_acidity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wine</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>9.1</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>7.4</td>\n",
       "      <td>48.5</td>\n",
       "      <td>3.14</td>\n",
       "      <td>1</td>\n",
       "      <td>12.8</td>\n",
       "      <td>0.49</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>9.1</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>6.6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.35</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3346</th>\n",
       "      <td>10.6</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>6.7</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0.50</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308</th>\n",
       "      <td>10.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.9954</td>\n",
       "      <td>6.4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>0.43</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>12.1</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>5.6</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.21</td>\n",
       "      <td>1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.43</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      alcohol  chlorides  citric_acid  density  fixed_acidity  \\\n",
       "wine                                                            \n",
       "2169      9.1      0.053         0.30   0.9986            7.4   \n",
       "1382      9.1      0.045         0.16   0.9940            6.6   \n",
       "3346     10.6      0.057         0.24   0.9952            6.7   \n",
       "3308     10.6      0.039         0.28   0.9954            6.4   \n",
       "3167     12.1      0.034         0.40   0.9914            5.6   \n",
       "\n",
       "      free_sulfur_dioxide    ph  quality  residual_sugar  sulphates  \\\n",
       "wine                                                                  \n",
       "2169                 48.5  3.14        1            12.8       0.49   \n",
       "1382                 28.0  3.12        0             3.1       0.35   \n",
       "3346                 64.0  3.12        0            10.3       0.50   \n",
       "3308                 19.0  3.20        0            12.6       0.43   \n",
       "3167                 36.0  3.21        1             6.1       0.43   \n",
       "\n",
       "      total_sulfur_dioxide  volatile_acidity  \n",
       "wine                                          \n",
       "2169                 229.0              0.19  \n",
       "1382                  92.0              0.56  \n",
       "3346                 185.0              0.18  \n",
       "3308                 124.0              0.35  \n",
       "3167                 118.0              0.28  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['alcohol', 'chlorides', 'citric_acid', 'density', 'fixed_acidity',\n",
       "       'free_sulfur_dioxide', 'ph', 'quality', 'residual_sugar',\n",
       "       'sulphates', 'total_sulfur_dioxide', 'volatile_acidity'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
     ]
    }
   ],
   "source": [
    "# realizar normalização nos dados numéricos contínuos\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "print(scaler)\n",
    "\n",
    "cols = ['alcohol', 'chlorides', 'citric_acid', 'density', 'fixed_acidity', 'free_sulfur_dioxide',\n",
    "        'ph', 'residual_sugar', 'sulphates', 'total_sulfur_dioxide', 'volatile_acidity']\n",
    "\n",
    "#for col in cols:\n",
    "data.loc[:,cols] = scaler.fit_transform(data.loc[:,cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>density</th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>ph</th>\n",
       "      <th>quality</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>volatile_acidity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wine</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>0.1774</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.1807</td>\n",
       "      <td>0.2215</td>\n",
       "      <td>0.3462</td>\n",
       "      <td>0.1620</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1871</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.5104</td>\n",
       "      <td>0.1078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>0.1774</td>\n",
       "      <td>0.1068</td>\n",
       "      <td>0.0964</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.2692</td>\n",
       "      <td>0.0906</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.1512</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.4706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3346</th>\n",
       "      <td>0.4194</td>\n",
       "      <td>0.1424</td>\n",
       "      <td>0.1446</td>\n",
       "      <td>0.1558</td>\n",
       "      <td>0.2788</td>\n",
       "      <td>0.2160</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1488</td>\n",
       "      <td>0.3256</td>\n",
       "      <td>0.4084</td>\n",
       "      <td>0.0980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308</th>\n",
       "      <td>0.4194</td>\n",
       "      <td>0.0890</td>\n",
       "      <td>0.1687</td>\n",
       "      <td>0.1596</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0592</td>\n",
       "      <td>0.4364</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1840</td>\n",
       "      <td>0.2442</td>\n",
       "      <td>0.2668</td>\n",
       "      <td>0.2647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>0.6613</td>\n",
       "      <td>0.0742</td>\n",
       "      <td>0.2410</td>\n",
       "      <td>0.0835</td>\n",
       "      <td>0.1731</td>\n",
       "      <td>0.1185</td>\n",
       "      <td>0.4455</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0844</td>\n",
       "      <td>0.2442</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>0.1961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      alcohol  chlorides  citric_acid  density  fixed_acidity  \\\n",
       "wine                                                            \n",
       "2169   0.1774     0.1306       0.1807   0.2215         0.3462   \n",
       "1382   0.1774     0.1068       0.0964   0.1328         0.2692   \n",
       "3346   0.4194     0.1424       0.1446   0.1558         0.2788   \n",
       "3308   0.4194     0.0890       0.1687   0.1596         0.2500   \n",
       "3167   0.6613     0.0742       0.2410   0.0835         0.1731   \n",
       "\n",
       "      free_sulfur_dioxide      ph  quality  residual_sugar  sulphates  \\\n",
       "wine                                                                    \n",
       "2169               0.1620  0.3818        1          0.1871     0.3140   \n",
       "1382               0.0906  0.3636        0          0.0383     0.1512   \n",
       "3346               0.2160  0.3636        0          0.1488     0.3256   \n",
       "3308               0.0592  0.4364        0          0.1840     0.2442   \n",
       "3167               0.1185  0.4455        1          0.0844     0.2442   \n",
       "\n",
       "      total_sulfur_dioxide  volatile_acidity  \n",
       "wine                                          \n",
       "2169                0.5104            0.1078  \n",
       "1382                0.1926            0.4706  \n",
       "3346                0.4084            0.0980  \n",
       "3308                0.2668            0.2647  \n",
       "3167                0.2529            0.1961  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem preditiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar os pacotes necessários para os algoritmos de classificação\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# avalia o desempenho do modelo, retornando o valor da precisão\n",
    "def evaluate_classification_model(model, X, y):\n",
    "    start = datetime.now()\n",
    "    kfold = KFold(n_splits=10, random_state=42)\n",
    "    results = cross_val_score(model, X, y, cv=kfold, scoring='accuracy', verbose=1)\n",
    "    end = datetime.now()\n",
    "    elapsed = int((end - start).total_seconds() * 1000)\n",
    "    score = 100.0 * results.mean()\n",
    "    stddev = 100.0 * results.std()\n",
    "    print(model, '\\nScore: %.2f (+/- %.2f) [%5s ms]' % (score, stddev, elapsed))\n",
    "    return score, stddev, elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# faz o ajuste fino do modelo, calculando os melhores hiperparâmetros\n",
    "def fine_tune_model(model, params, X, y):\n",
    "    print('\\nFine Tuning Model:')\n",
    "    print(model, \"\\nparams:\", params)\n",
    "    kfold = KFold(n_splits=10, random_state=42)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=params, scoring='accuracy', cv=kfold, verbose=1)\n",
    "    grid.fit(X, y)\n",
    "    print('\\nGrid Best Score: %.2f' % (grid.best_score_ * 100.0))\n",
    "    print('Best Params:', grid.best_params_)\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma dos dados de treino: (3265, 11) (3265,)\n"
     ]
    }
   ],
   "source": [
    "# definir dados de treino\n",
    "train_data = data[data.quality >= 0]\n",
    "\n",
    "# selecionar atributos para o modelo\n",
    "cols = ['alcohol', 'chlorides', 'citric_acid', 'density', 'fixed_acidity', 'free_sulfur_dioxide',\n",
    "        'ph', 'residual_sugar', 'sulphates', 'total_sulfur_dioxide', 'volatile_acidity']\n",
    "\n",
    "X_train = train_data[cols]\n",
    "y_train = train_data['quality']\n",
    "\n",
    "print('Forma dos dados de treino:', X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>density</th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>ph</th>\n",
       "      <th>quality</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>volatile_acidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alcohol</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.3630</td>\n",
       "      <td>-0.0445</td>\n",
       "      <td>-0.8026</td>\n",
       "      <td>-0.1331</td>\n",
       "      <td>-0.2207</td>\n",
       "      <td>0.1321</td>\n",
       "      <td>0.3858</td>\n",
       "      <td>-0.4598</td>\n",
       "      <td>-0.0198</td>\n",
       "      <td>-0.4452</td>\n",
       "      <td>0.0617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chlorides</th>\n",
       "      <td>-0.3630</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0764</td>\n",
       "      <td>0.2717</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.1061</td>\n",
       "      <td>-0.0942</td>\n",
       "      <td>-0.1860</td>\n",
       "      <td>0.1089</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.2039</td>\n",
       "      <td>0.0816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citric_acid</th>\n",
       "      <td>-0.0445</td>\n",
       "      <td>0.0764</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>0.0871</td>\n",
       "      <td>-0.1624</td>\n",
       "      <td>-0.0272</td>\n",
       "      <td>0.0889</td>\n",
       "      <td>0.0778</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>-0.1458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density</th>\n",
       "      <td>-0.8026</td>\n",
       "      <td>0.2717</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2806</td>\n",
       "      <td>0.2829</td>\n",
       "      <td>-0.1080</td>\n",
       "      <td>-0.2889</td>\n",
       "      <td>0.8328</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>0.0079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fixed_acidity</th>\n",
       "      <td>-0.1331</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>0.2806</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.0365</td>\n",
       "      <td>-0.4286</td>\n",
       "      <td>-0.0735</td>\n",
       "      <td>0.0885</td>\n",
       "      <td>-0.0256</td>\n",
       "      <td>0.1117</td>\n",
       "      <td>-0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <td>-0.2207</td>\n",
       "      <td>0.1061</td>\n",
       "      <td>0.0871</td>\n",
       "      <td>0.2829</td>\n",
       "      <td>-0.0365</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.0025</td>\n",
       "      <td>-0.0215</td>\n",
       "      <td>0.2897</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>0.6091</td>\n",
       "      <td>-0.0971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ph</th>\n",
       "      <td>0.1321</td>\n",
       "      <td>-0.0942</td>\n",
       "      <td>-0.1624</td>\n",
       "      <td>-0.1080</td>\n",
       "      <td>-0.4286</td>\n",
       "      <td>-0.0025</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0932</td>\n",
       "      <td>-0.1947</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>-0.0094</td>\n",
       "      <td>-0.0302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <td>0.3858</td>\n",
       "      <td>-0.1860</td>\n",
       "      <td>-0.0272</td>\n",
       "      <td>-0.2889</td>\n",
       "      <td>-0.0735</td>\n",
       "      <td>-0.0215</td>\n",
       "      <td>0.0932</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.1203</td>\n",
       "      <td>0.0407</td>\n",
       "      <td>-0.1610</td>\n",
       "      <td>-0.0725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residual_sugar</th>\n",
       "      <td>-0.4598</td>\n",
       "      <td>0.1089</td>\n",
       "      <td>0.0889</td>\n",
       "      <td>0.8328</td>\n",
       "      <td>0.0885</td>\n",
       "      <td>0.2897</td>\n",
       "      <td>-0.1947</td>\n",
       "      <td>-0.1203</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.0392</td>\n",
       "      <td>0.3993</td>\n",
       "      <td>0.0449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sulphates</th>\n",
       "      <td>-0.0198</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.0778</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>-0.0256</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.0407</td>\n",
       "      <td>-0.0392</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>-0.0328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <td>-0.4452</td>\n",
       "      <td>0.2039</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>0.1117</td>\n",
       "      <td>0.6091</td>\n",
       "      <td>-0.0094</td>\n",
       "      <td>-0.1610</td>\n",
       "      <td>0.3993</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volatile_acidity</th>\n",
       "      <td>0.0617</td>\n",
       "      <td>0.0816</td>\n",
       "      <td>-0.1458</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>-0.0971</td>\n",
       "      <td>-0.0302</td>\n",
       "      <td>-0.0725</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>-0.0328</td>\n",
       "      <td>0.0886</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      alcohol  chlorides  citric_acid  density  fixed_acidity  \\\n",
       "alcohol                1.0000    -0.3630      -0.0445  -0.8026        -0.1331   \n",
       "chlorides             -0.3630     1.0000       0.0764   0.2717         0.0183   \n",
       "citric_acid           -0.0445     0.0764       1.0000   0.1333         0.2872   \n",
       "density               -0.8026     0.2717       0.1333   1.0000         0.2806   \n",
       "fixed_acidity         -0.1331     0.0183       0.2872   0.2806         1.0000   \n",
       "free_sulfur_dioxide   -0.2207     0.1061       0.0871   0.2829        -0.0365   \n",
       "ph                     0.1321    -0.0942      -0.1624  -0.1080        -0.4286   \n",
       "quality                0.3858    -0.1860      -0.0272  -0.2889        -0.0735   \n",
       "residual_sugar        -0.4598     0.1089       0.0889   0.8328         0.0885   \n",
       "sulphates             -0.0198     0.0175       0.0778   0.0630        -0.0256   \n",
       "total_sulfur_dioxide  -0.4452     0.2039       0.1041   0.5372         0.1117   \n",
       "volatile_acidity       0.0617     0.0816      -0.1458   0.0079        -0.0125   \n",
       "\n",
       "                      free_sulfur_dioxide      ph  quality  residual_sugar  \\\n",
       "alcohol                           -0.2207  0.1321   0.3858         -0.4598   \n",
       "chlorides                          0.1061 -0.0942  -0.1860          0.1089   \n",
       "citric_acid                        0.0871 -0.1624  -0.0272          0.0889   \n",
       "density                            0.2829 -0.1080  -0.2889          0.8328   \n",
       "fixed_acidity                     -0.0365 -0.4286  -0.0735          0.0885   \n",
       "free_sulfur_dioxide                1.0000 -0.0025  -0.0215          0.2897   \n",
       "ph                                -0.0025  1.0000   0.0932         -0.1947   \n",
       "quality                           -0.0215  0.0932   1.0000         -0.1203   \n",
       "residual_sugar                     0.2897 -0.1947  -0.1203          1.0000   \n",
       "sulphates                          0.0630  0.1622   0.0407         -0.0392   \n",
       "total_sulfur_dioxide               0.6091 -0.0094  -0.1610          0.3993   \n",
       "volatile_acidity                  -0.0971 -0.0302  -0.0725          0.0449   \n",
       "\n",
       "                      sulphates  total_sulfur_dioxide  volatile_acidity  \n",
       "alcohol                 -0.0198               -0.4452            0.0617  \n",
       "chlorides                0.0175                0.2039            0.0816  \n",
       "citric_acid              0.0778                0.1041           -0.1458  \n",
       "density                  0.0630                0.5372            0.0079  \n",
       "fixed_acidity           -0.0256                0.1117           -0.0125  \n",
       "free_sulfur_dioxide      0.0630                0.6091           -0.0971  \n",
       "ph                       0.1622               -0.0094           -0.0302  \n",
       "quality                  0.0407               -0.1610           -0.0725  \n",
       "residual_sugar          -0.0392                0.3993            0.0449  \n",
       "sulphates                1.0000                0.1343           -0.0328  \n",
       "total_sulfur_dioxide     0.1343                1.0000            0.0886  \n",
       "volatile_acidity        -0.0328                0.0886            1.0000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma dos dados de teste: (1633, 11)\n"
     ]
    }
   ],
   "source": [
    "# definir dados de teste\n",
    "test_data = data[data.quality < 0]\n",
    "\n",
    "X_test = test_data[cols]\n",
    "\n",
    "print('Forma dos dados de teste:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "models = []\n",
    "scores = []\n",
    "stddevs = []\n",
    "times = []\n",
    "\n",
    "def add_model_info(name, model, score, stddev, elapsed):\n",
    "    names.append(name)\n",
    "    models.append((name, model))\n",
    "    scores.append(score)\n",
    "    stddevs.append(stddev)\n",
    "    times.append(elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação e ajuste fino de cada modelo preditivo\n",
    "\n",
    "-  https://scikit-learn.org/stable/modules/classes.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalized Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) \n",
      "Score: 78.71 (+/- 2.15) [ 1708 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.7s finished\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=42, solver='newton-cg', C=0.1, multi_class='auto', max_iter=500)\n",
    "\n",
    "params = dict(\n",
    "    solver=['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    C=np.logspace(-3, 3, 7)\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('LR', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=0.25,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=42, splitter='best') \n",
      "Score: 79.48 (+/- 2.40) [  751 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=42, criterion='entropy', max_depth=6, min_samples_split=0.25)\n",
    "\n",
    "#criterion=’mse’, splitter=’best’, max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, \n",
    "#min_impurity_decrease=0.0, min_impurity_split=None, presort=False\n",
    "\n",
    "params = dict(\n",
    "    criterion=['gini','entropy'],\n",
    "    max_depth=[4, 6, 8, 10, 12, 14],\n",
    "    min_samples_split=[0.25, 0.5, 0.75, 1.0]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('DT', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
      "                           solver='lsqr', store_covariance=False, tol=0.0001) \n",
      "Score: 80.12 (+/- 2.47) [  902 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "model = LinearDiscriminantAnalysis(solver='lsqr')\n",
    "\n",
    "#solver=’svd’, shrinkage=None, priors=None,\n",
    "#n_components=None, store_covariance=False, tol=0.0001\n",
    "\n",
    "params = dict(\n",
    "    solver=['svd', 'lsqr'] #, 'eigen']\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('LDA', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=1e-08) \n",
      "Score: 71.94 (+/- 2.40) [  332 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB(priors=None, var_smoothing=1e-8)\n",
    "\n",
    "#priors=None, var_smoothing=1e-09\n",
    "\n",
    "params = dict(\n",
    "    priors=[None],\n",
    "    var_smoothing=[1e-8, 1e-7, 1e-6, 1e-5, 1e-4]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('NB', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=11, p=2,\n",
      "                     weights='uniform') \n",
      "Score: 80.83 (+/- 2.34) [ 2785 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    2.8s finished\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=11, weights='uniform')\n",
    "\n",
    "#n_neighbors=5, weights=’uniform’, algorithm=’auto’, leaf_size=30, p=2, metric=’minkowski’,\n",
    "#metric_params=None, n_jobs=None\n",
    "\n",
    "params = dict(\n",
    "    n_neighbors=[1, 3, 5, 7, 9, 11, 13],\n",
    "    weights=['uniform', 'distance']\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('KNN', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
      "    verbose=False) \n",
      "Score: 78.16 (+/- 2.08) [17290 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   17.3s finished\n"
     ]
    }
   ],
   "source": [
    "model = SVC(random_state=42, C=10, gamma=0.1, kernel='rbf')\n",
    "\n",
    "#kernel=’rbf’, degree=3, gamma=’auto_deprecated’, coef0=0.0, tol=0.001, C=1.0, \n",
    "#epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1\n",
    "\n",
    "params = dict(\n",
    "    C=[0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    gamma=[0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    kernel=['linear', 'rbf']\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('SVM', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='logistic', alpha=1, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=42, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False) \n",
      "Score: 80.67 (+/- 2.23) [119693 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  2.0min finished\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(random_state=42, solver='lbfgs', alpha=1, hidden_layer_sizes=(100,), activation='logistic')\n",
    "                \n",
    "#hidden_layer_sizes=(100, ), activation=’relu’, solver=’adam’, alpha=0.0001, batch_size=’auto’, \n",
    "#learning_rate=’constant’, learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, \n",
    "#random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, \n",
    "#early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10\n",
    "\n",
    "params = dict(\n",
    "    alpha=[1,0.1,0.01,0.001,0.0001,0],\n",
    "    hidden_layer_sizes=[(100,), (50,), (50,2), (5,5,2), (10,5,2)],\n",
    "    activation=['identity', 'logistic', 'tanh', 'relu'],\n",
    "    solver=['lbfgs', 'sgd', 'adam']\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('MLP', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R',\n",
      "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
      "                                                         criterion='gini',\n",
      "                                                         max_depth=None,\n",
      "                                                         max_features=None,\n",
      "                                                         max_leaf_nodes=None,\n",
      "                                                         min_impurity_decrease=0.0,\n",
      "                                                         min_impurity_split=None,\n",
      "                                                         min_samples_leaf=1,\n",
      "                                                         min_samples_split=2,\n",
      "                                                         min_weight_fraction_leaf=0.0,\n",
      "                                                         presort=False,\n",
      "                                                         random_state=42,\n",
      "                                                         splitter='best'),\n",
      "                   learning_rate=1.0, n_estimators=50, random_state=42) \n",
      "Score: 81.87 (+/- 1.39) [ 1599 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.6s finished\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier(DecisionTreeClassifier(random_state=42), random_state=42, n_estimators=50)\n",
    "\n",
    "#base_estimator=None, n_estimators=50, learning_rate=1.0,\n",
    "#algorithm=’SAMME.R’, random_state=None\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[10, 25, 50, 100]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('ABDT', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
      "                  max_features=0.8, max_samples=0.25, n_estimators=100,\n",
      "                  n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                  warm_start=False) \n",
      "Score: 84.99 (+/- 2.52) [27008 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   27.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "model = BaggingClassifier(random_state=42, n_estimators=100,\n",
    "                          max_samples=0.25, max_features=0.8)\n",
    "\n",
    "#base_estimator=None, n_estimators=10, max_samples=1.0, max_features=1.0,\n",
    "#bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False,\n",
    "#n_jobs=None, random_state=None, verbose=0\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[10, 50, 100, 500],\n",
    "    max_samples=[0.25, 0.5, 0.75, 1.0],\n",
    "    max_features=[0.7, 0.8, 0.9, 1.0]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('BC', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                     max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=0.25,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                     n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                     warm_start=False) \n",
      "Score: 78.22 (+/- 2.03) [11415 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   11.4s finished\n"
     ]
    }
   ],
   "source": [
    "model = ExtraTreesClassifier(random_state=42, n_estimators=100, max_depth=7, \n",
    "                             min_samples_split=0.25, max_features='auto')\n",
    "\n",
    "#n_estimators=’warn’, criterion=’gini’, max_depth=None, min_samples_split=2,\n",
    "#min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=’auto’, \n",
    "#max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, \n",
    "#bootstrap=False, oob_score=False, n_jobs=None, random_state=None, verbose=0,\n",
    "#warm_start=False, class_weight=None\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[10, 50, 100, 500],\n",
    "    max_depth=[None, 3, 7, 11],\n",
    "    min_samples_split=[0.25, 0.5],\n",
    "    max_features=['auto', 0.7, 0.85, 1.0]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('ET', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=4,\n",
      "                           max_features=0.75, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=42, subsample=0.6, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False) \n",
      "Score: 84.47 (+/- 2.18) [22950 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   22.9s finished\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(random_state=42, n_estimators=100, max_features=0.75,\n",
    "                                   max_depth=4, learning_rate=0.1, subsample=0.6)\n",
    "\n",
    "#loss=’ls’, learning_rate=0.1, n_estimators=100, subsample=1.0, criterion=’friedman_mse’, min_samples_split=2,\n",
    "#min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, \n",
    "#min_impurity_split=None, init=None, random_state=None, max_features=None, alpha=0.9, verbose=0, \n",
    "#max_leaf_nodes=None, warm_start=False, presort=’auto’, validation_fraction=0.1, n_iter_no_change=None, \n",
    "#tol=0.0001\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[100, 250, 500],\n",
    "    max_features=[0.75, 0.85, 1.0],\n",
    "    max_depth=[4, 6, 8, 10],\n",
    "    learning_rate=[0.05, 0.1, 0.15],\n",
    "    subsample=[0.4, 0.6, 0.8]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('GB', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False) \n",
      "Score: 82.73 (+/- 2.77) [21402 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   21.4s finished\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42, n_estimators=100, max_features='auto', max_depth=5)\n",
    "\n",
    "#n_estimators=’warn’, criterion=’mse’, max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#min_weight_fraction_leaf=0.0, max_features=’auto’, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "#min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, \n",
    "#verbose=0, warm_start=False\n",
    "\n",
    "params = dict(\n",
    "    n_estimators=[10, 50, 100, 500],\n",
    "    max_features=['auto', 'sqrt', 'log2'],\n",
    "    max_depth=[None, 3, 5, 7, 9, 11, 13]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('RF', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outros algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost\n",
    "\n",
    "- https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1) \n",
      "Score: 83.49 (+/- 2.99) [14708 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:   14.7s finished\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(max_depth=3, n_estimators=100)\n",
    "\n",
    "#max_depth=3, learning_rate=0.1, n_estimators=100, verbosity=1, silent=None, objective='reg:squarederror',\n",
    "#booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, \n",
    "#colsample_bytree=1, colsample_bylevel=1, colsample_bynode=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, \n",
    "#base_score=0.5, random_state=0, seed=None, missing=None, importance_type='gain'\n",
    "\n",
    "params = dict(\n",
    "    max_depth=[3, 5, 7, 9],\n",
    "    n_estimators=[50, 75, 100, 200]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('XGB', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Abaixo é criado um classificador MLP com 20 neurônios na camada intermediária e dropout de 50%. Foi utilizada a função de ativação sigmoid, a função de loss mean squared error e o otimizador RMSProp. O treinamento é realizado por 200 épocas com batch size de 64.\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=X_train.shape[1], activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mse', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hist = model.fit(X_train, y_train, batch_size=64, nb_epoch=200, verbose=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def plot_line(loss, ylabel, xlabel='Epochs'):\n",
    "    fig = plt.figure()\n",
    "    plt.plot(loss)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_line(hist.history['acc'], 'accuracy')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_line(hist.history['loss'], 'loss')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "loss, accuracy = model.evaluate(v_X, v_y)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prefixo_arquivo = 'submissions/titanic-submission'\n",
    "sufixo_arquivo = '07jul'\n",
    "name = 'mlptf'\n",
    "\n",
    "print(model, '\\n')\n",
    "\n",
    "# executar previsão usando o modelo\n",
    "y_pred = model.predict(X_test).ravel()\n",
    "vfunc = np.vectorize(lambda x: 'yes' if x > 0.5 else 'no')\n",
    "\n",
    "# gerar dados de envio (submissão)\n",
    "submission = pd.DataFrame({\n",
    "  'person': X_test.index,\n",
    "  'survived': vfunc(y_pred)\n",
    "})\n",
    "submission.set_index('person', inplace=True)\n",
    "\n",
    "# gerar arquivo CSV para o envio\n",
    "filename = '%s-p-%s-%s.csv' % (prefixo_arquivo, sufixo_arquivo, name.lower())\n",
    "submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM\n",
    "\n",
    "- https://github.com/microsoft/LightGBM\n",
    "- https://lightgbm.readthedocs.io/en/latest/\n",
    "- https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "model = LGBMClassifier(random_state=42, objective='binary', metric='binary_logloss',\n",
    "                      boosting_type='goss', n_estimators=50, max_depth=11)\n",
    "\n",
    "params = dict(\n",
    "    boosting_type=['gbdt', 'dart', 'goss'], #rf\n",
    "    objective=['binary'],\n",
    "    metric=['binary_logloss'],\n",
    "    #bagging_freq=[1, 5, 10],\n",
    "    #bagging_fraction=[0.25, 0.5],\n",
    "    n_estimators=[50, 75, 100, 200],\n",
    "    max_depth=[3, 5, 7, 9, 11]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('LGBM', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "d_train = lgb.Dataset(X_train.values, label=y_train.values)\n",
    "\n",
    "params = {}\n",
    "params['random_state'] = 42\n",
    "params['objective'] = 'binary'\n",
    "params['boosting_type'] = 'goss' # gbdt, rf, dart, goss\n",
    "\n",
    "#params['learning_rate'] = 0.003\n",
    "#params['metric'] = 'binary_logloss'\n",
    "#params['sub_feature'] = 0.5\n",
    "#params['num_leaves'] = 10\n",
    "#params['min_data'] = 50\n",
    "#params['max_depth'] = 10\n",
    "\n",
    "#model = lgb.train(params, d_train, 100)\n",
    "model = lgb.cv(params, d_train, 100, nfold=10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prefixo_arquivo = 'submissions/titanic-submission'\n",
    "sufixo_arquivo = '08jul'\n",
    "name = 'lgbm_' + params['boosting_type']\n",
    "\n",
    "print(model, '\\n')\n",
    "\n",
    "# executar previsão usando o modelo\n",
    "y_pred = clf.predict(X_test.values)\n",
    "vfunc = np.vectorize(lambda x: 'yes' if x > 0.5 else 'no')\n",
    "\n",
    "# gerar dados de envio (submissão)\n",
    "submission = pd.DataFrame({\n",
    "  'person': X_test.index,\n",
    "  'survived': vfunc(y_pred)\n",
    "})\n",
    "submission.set_index('person', inplace=True)\n",
    "\n",
    "# gerar arquivo CSV para o envio\n",
    "filename = '%s-p-%s-%s.csv' % (prefixo_arquivo, sufixo_arquivo, name.lower())\n",
    "submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Learning Model\n",
    "\n",
    "- https://towardsdatascience.com/automate-stacking-in-python-fc3e7834772e\n",
    "- https://github.com/vecxoz/vecstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier(estimators=[('RF',\n",
      "                              RandomForestClassifier(bootstrap=True,\n",
      "                                                     class_weight=None,\n",
      "                                                     criterion='gini',\n",
      "                                                     max_depth=5,\n",
      "                                                     max_features='auto',\n",
      "                                                     max_leaf_nodes=None,\n",
      "                                                     min_impurity_decrease=0.0,\n",
      "                                                     min_impurity_split=None,\n",
      "                                                     min_samples_leaf=1,\n",
      "                                                     min_samples_split=2,\n",
      "                                                     min_weight_fraction_leaf=0.0,\n",
      "                                                     n_estimators=100,\n",
      "                                                     n_jobs=None,\n",
      "                                                     oob_score=False,\n",
      "                                                     random_state=42, verbose=0,\n",
      "                                                     w...\n",
      "                                                         max_leaf_nodes=None,\n",
      "                                                         min_impurity_decrease=0.0,\n",
      "                                                         min_impurity_split=None,\n",
      "                                                         min_samples_leaf=1,\n",
      "                                                         min_samples_split=2,\n",
      "                                                         min_weight_fraction_leaf=0.0,\n",
      "                                                         n_estimators=100,\n",
      "                                                         n_iter_no_change=None,\n",
      "                                                         presort='auto',\n",
      "                                                         random_state=42,\n",
      "                                                         subsample=0.6,\n",
      "                                                         tol=0.0001,\n",
      "                                                         validation_fraction=0.1,\n",
      "                                                         verbose=0,\n",
      "                                                         warm_start=False))],\n",
      "                 flatten_transform=True, n_jobs=-1, voting='hard',\n",
      "                 weights=(2, 1, 1)) \n",
      "Score: 82.91 (+/- 2.67) [92132 ms]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "estimators =  [\n",
    "    ('RF', RandomForestClassifier(random_state=42, n_estimators=100, max_features='auto', max_depth=5)),\n",
    "    ('BC', BaggingClassifier(random_state=42, n_estimators=100, max_samples=0.25, max_features=0.8)),\n",
    "    ('GB', GradientBoostingClassifier(random_state=42, max_depth=4, max_features=0.75,\n",
    "                                   n_estimators=100, learning_rate=0.1, subsample=0.6)),\n",
    "#    ('XGB', XGBClassifier(max_depth=3, n_estimators=100)),\n",
    "]\n",
    "model = VotingClassifier(estimators, n_jobs=-1, weights=(2,1,1))\n",
    "\n",
    "#estimators, weights=None, n_jobs=None\n",
    "\n",
    "params = dict(\n",
    "    weights=[(1,1,1), (2,1,1), (3,1,1), (3,2,1), (2,2,1), (2,1,2), (5,4,3), (1,2,1), (1,1,2), ]\n",
    ")\n",
    "#fine_tune_model(model, params, X_train, y_train)\n",
    "\n",
    "score, stddev, elapsed = evaluate_classification_model(model, X_train, y_train)\n",
    "add_model_info('VC', model, score, stddev, elapsed)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = SGDClassifier(random_state=42, max_iter=100, tol=0.1)\n",
    "\n",
    "params = {'max_iter':[100, 200, 350, 500, 1000], 'tol':[0.1, 0.01]}\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = Perceptron(random_state=42, max_iter=100, tol=0.01)\n",
    "\n",
    "params = dict(\n",
    "    max_iter=[100, 200, 350, 500, 1000],\n",
    "    tol=[0.1, 0.01, 0.001]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = LinearSVC(random_state=42, max_iter=1000, C=10)\n",
    "\n",
    "params = dict(\n",
    "    C=[0.001, 0.01, 0.1, 1, 10, 100]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliar importância dos atributos no modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alcohol</th>\n",
       "      <td>0.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density</th>\n",
       "      <td>0.134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residual_sugar</th>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chlorides</th>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volatile_acidity</th>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ph</th>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sulphates</th>\n",
       "      <td>0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citric_acid</th>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fixed_acidity</th>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      importance\n",
       "feature                         \n",
       "alcohol                    0.149\n",
       "density                    0.134\n",
       "residual_sugar             0.090\n",
       "chlorides                  0.088\n",
       "volatile_acidity           0.088\n",
       "free_sulfur_dioxide        0.085\n",
       "ph                         0.084\n",
       "total_sulfur_dioxide       0.079\n",
       "sulphates                  0.069\n",
       "citric_acid                0.068\n",
       "fixed_acidity              0.065"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42, max_features='auto', n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "importances = pd.DataFrame({'feature': X_train.columns,\n",
    "                            'importance': np.round(model.feature_importances_, 3)})\n",
    "importances = importances.sort_values('importance', ascending=False).set_index('feature')\n",
    "importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xa2bdcc0c>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação final entre os algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Score</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Time (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BC</td>\n",
       "      <td>84.9933</td>\n",
       "      <td>2.5194</td>\n",
       "      <td>27008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GB</td>\n",
       "      <td>84.4725</td>\n",
       "      <td>2.1765</td>\n",
       "      <td>22950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGB</td>\n",
       "      <td>83.4920</td>\n",
       "      <td>2.9890</td>\n",
       "      <td>14708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>VC</td>\n",
       "      <td>82.9109</td>\n",
       "      <td>2.6722</td>\n",
       "      <td>92132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RF</td>\n",
       "      <td>82.7270</td>\n",
       "      <td>2.7712</td>\n",
       "      <td>21402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ABDT</td>\n",
       "      <td>81.8687</td>\n",
       "      <td>1.3903</td>\n",
       "      <td>1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>80.8284</td>\n",
       "      <td>2.3355</td>\n",
       "      <td>2785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLP</td>\n",
       "      <td>80.6748</td>\n",
       "      <td>2.2327</td>\n",
       "      <td>119693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LDA</td>\n",
       "      <td>80.1232</td>\n",
       "      <td>2.4697</td>\n",
       "      <td>902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DT</td>\n",
       "      <td>79.4797</td>\n",
       "      <td>2.3962</td>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>78.7148</td>\n",
       "      <td>2.1473</td>\n",
       "      <td>1811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>78.7148</td>\n",
       "      <td>2.1473</td>\n",
       "      <td>1708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ET</td>\n",
       "      <td>78.2249</td>\n",
       "      <td>2.0288</td>\n",
       "      <td>11415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM</td>\n",
       "      <td>78.1635</td>\n",
       "      <td>2.0784</td>\n",
       "      <td>17290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NB</td>\n",
       "      <td>71.9436</td>\n",
       "      <td>2.3986</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Algorithm    Score  Std Dev  Time (ms)\n",
       "9         BC  84.9933   2.5194      27008\n",
       "11        GB  84.4725   2.1765      22950\n",
       "13       XGB  83.4920   2.9890      14708\n",
       "14        VC  82.9109   2.6722      92132\n",
       "12        RF  82.7270   2.7712      21402\n",
       "8       ABDT  81.8687   1.3903       1599\n",
       "5        KNN  80.8284   2.3355       2785\n",
       "7        MLP  80.6748   2.2327     119693\n",
       "3        LDA  80.1232   2.4697        902\n",
       "2         DT  79.4797   2.3962        751\n",
       "0         LR  78.7148   2.1473       1811\n",
       "1         LR  78.7148   2.1473       1708\n",
       "10        ET  78.2249   2.0288      11415\n",
       "6        SVM  78.1635   2.0784      17290\n",
       "4         NB  71.9436   2.3986        332"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'Algorithm': names, 'Score': scores, 'Std Dev': stddevs, 'Time (ms)': times})\n",
    "results.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerar arquivos com resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar diretório para os arquivos de envio\n",
    "!test -d submissions || mkdir submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) \n",
      "\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) \n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=0.25,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=42, splitter='best') \n",
      "\n",
      "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
      "                           solver='lsqr', store_covariance=False, tol=0.0001) \n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-08) \n",
      "\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=11, p=2,\n",
      "                     weights='uniform') \n",
      "\n",
      "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
      "    verbose=False) \n",
      "\n",
      "MLPClassifier(activation='logistic', alpha=1, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=42, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False) \n",
      "\n",
      "AdaBoostClassifier(algorithm='SAMME.R',\n",
      "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
      "                                                         criterion='gini',\n",
      "                                                         max_depth=None,\n",
      "                                                         max_features=None,\n",
      "                                                         max_leaf_nodes=None,\n",
      "                                                         min_impurity_decrease=0.0,\n",
      "                                                         min_impurity_split=None,\n",
      "                                                         min_samples_leaf=1,\n",
      "                                                         min_samples_split=2,\n",
      "                                                         min_weight_fraction_leaf=0.0,\n",
      "                                                         presort=False,\n",
      "                                                         random_state=42,\n",
      "                                                         splitter='best'),\n",
      "                   learning_rate=1.0, n_estimators=50, random_state=42) \n",
      "\n",
      "BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
      "                  max_features=0.8, max_samples=0.25, n_estimators=100,\n",
      "                  n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                  warm_start=False) \n",
      "\n",
      "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                     max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=0.25,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                     n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                     warm_start=False) \n",
      "\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=4,\n",
      "                           max_features=0.75, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=42, subsample=0.6, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False) \n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False) \n",
      "\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1) \n",
      "\n",
      "VotingClassifier(estimators=[('RF',\n",
      "                              RandomForestClassifier(bootstrap=True,\n",
      "                                                     class_weight=None,\n",
      "                                                     criterion='gini',\n",
      "                                                     max_depth=5,\n",
      "                                                     max_features='auto',\n",
      "                                                     max_leaf_nodes=None,\n",
      "                                                     min_impurity_decrease=0.0,\n",
      "                                                     min_impurity_split=None,\n",
      "                                                     min_samples_leaf=1,\n",
      "                                                     min_samples_split=2,\n",
      "                                                     min_weight_fraction_leaf=0.0,\n",
      "                                                     n_estimators=100,\n",
      "                                                     n_jobs=None,\n",
      "                                                     oob_score=False,\n",
      "                                                     random_state=42, verbose=0,\n",
      "                                                     w...\n",
      "                                                         max_leaf_nodes=None,\n",
      "                                                         min_impurity_decrease=0.0,\n",
      "                                                         min_impurity_split=None,\n",
      "                                                         min_samples_leaf=1,\n",
      "                                                         min_samples_split=2,\n",
      "                                                         min_weight_fraction_leaf=0.0,\n",
      "                                                         n_estimators=100,\n",
      "                                                         n_iter_no_change=None,\n",
      "                                                         presort='auto',\n",
      "                                                         random_state=42,\n",
      "                                                         subsample=0.6,\n",
      "                                                         tol=0.0001,\n",
      "                                                         validation_fraction=0.1,\n",
      "                                                         verbose=0,\n",
      "                                                         warm_start=False))],\n",
      "                 flatten_transform=True, n_jobs=-1, voting='hard',\n",
      "                 weights=(2, 1, 1)) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prefixo_arquivo = 'submissions/wine-submission'\n",
    "sufixo_arquivo = '31ago'\n",
    "\n",
    "for name, model in models:\n",
    "    print(model, '\\n')\n",
    "    \n",
    "    # treinar o modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # executar previsão usando o modelo\n",
    "    y_pred = model.predict(X_test)\n",
    "    vfunc = np.vectorize(lambda x: 'good' if x > 0 else 'bad')\n",
    "\n",
    "    # gerar dados de envio (submissão)\n",
    "    submission = pd.DataFrame({\n",
    "      'wine': X_test.index,\n",
    "      'quality': vfunc(y_pred)\n",
    "    })\n",
    "    submission.set_index('wine', inplace=True)\n",
    "\n",
    "    # gerar arquivo CSV para o envio\n",
    "    filename = '%s-p-%s-%s.csv' % (prefixo_arquivo, sufixo_arquivo, name.lower())\n",
    "    submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> submissions/wine-submission-p-18ago-abdt.csv <==\n",
      "wine,quality\n",
      "1214,bad\n",
      "727,bad\n",
      "481,bad\n",
      "1308,bad\n",
      "4087,bad\n",
      "619,bad\n",
      "4669,bad\n",
      "874,bad\n",
      "2337,bad\n",
      "\n",
      "==> submissions/wine-submission-p-18ago-bc.csv <==\n",
      "wine,quality\n",
      "1214,bad\n",
      "727,bad\n",
      "481,bad\n",
      "1308,bad\n",
      "4087,bad\n",
      "619,bad\n",
      "4669,bad\n",
      "874,bad\n",
      "2337,bad\n",
      "\n",
      "==> submissions/wine-submission-p-18ago-dt.csv <==\n",
      "wine,quality\n",
      "1214,bad\n",
      "727,bad\n",
      "481,bad\n",
      "1308,bad\n",
      "4087,bad\n",
      "619,bad\n",
      "4669,bad\n",
      "874,bad\n",
      "2337,bad\n",
      "\n",
      "==> submissions/wine-submission-p-18ago-et.csv <==\n",
      "wine,quality\n",
      "1214,bad\n",
      "727,bad\n",
      "481,bad\n",
      "1308,bad\n",
      "4087,bad\n",
      "619,bad\n",
      "4669,bad\n",
      "874,bad\n",
      "2337,bad\n",
      "\n",
      "==> submissions/wine-submission-p-18ago-gb.csv <==\n",
      "wine,quality\n",
      "1214,bad\n",
      "727,bad\n",
      "481,bad\n",
      "1308,bad\n",
      "4087,bad\n",
      "619,bad\n",
      "4669,bad\n",
      "874,bad\n",
      "2337,bad\n",
      "\n",
      "==> submissions/wine-submission-p-18ago-knn.csv <==\n",
      "wine,quality\n",
      "1214,bad\n",
      "727,bad\n",
      "481,bad\n",
      "1308,bad\n",
      "4087,bad\n",
      "619,bad\n",
      "4669,bad\n",
      "874,bad\n",
      "2337,bad\n",
      "\n",
      "==> submissions/wine-submission-p-18ago-lda.csv <==\n",
      "wine,quality\n",
      "1214,bad\n",
      "727,bad\n",
      "481,bad\n",
      "1308,bad\n",
      "4087,bad\n",
      "619,bad\n",
      "4669,bad\n",
      "874,bad\n",
      "2337,bad\n",
      "\n",
      "==> submissions/wine-submission-p-18ago-lr.csv <==\n",
      "wine,quality\n",
      "1214,bad\n",
      "727,bad\n",
      "481,bad\n",
      "1308,bad\n",
      "4087,bad\n",
      "619,bad\n",
      "4669,bad\n",
      "874,bad\n",
      "2337,bad\n",
      "\n",
      "==> submissions/wine-submission-p-18ago-mlp.csv <==\n",
      "wine,quality\n",
      "1214,bad\n",
      "727,bad\n",
      "481,bad\n",
      "1308,bad\n",
      "4087,bad\n",
      "619,bad\n",
      "4669,bad\n",
      "874,bad\n",
      "2337,bad\n",
      "\n",
      "==> submissions/wine-submission-p-18ago-nb.csv <==\n",
      "wine,quality\n",
      "1214,bad\n",
      "727,bad\n",
      "481,good\n",
      "1308,bad\n",
      "4087,bad\n",
      "619,bad\n",
      "4669,good\n",
      "874,bad\n",
      "2337,bad\n",
      "\n",
      "==> submissions/wine-submission-p-18ago-rf.csv <==\n",
      "wine,quality\n",
      "1214,bad\n",
      "727,bad\n",
      "481,bad\n",
      "1308,bad\n",
      "4087,bad\n",
      "619,bad\n",
      "4669,bad\n",
      "874,bad\n",
      "2337,bad\n",
      "\n",
      "==> submissions/wine-submission-p-18ago-svm.csv <==\n",
      "wine,quality\n",
      "1214,bad\n",
      "727,bad\n",
      "481,bad\n",
      "1308,bad\n",
      "4087,bad\n",
      "619,bad\n",
      "4669,bad\n",
      "874,bad\n",
      "2337,bad\n",
      "\n",
      "==> submissions/wine-submission-p-18ago-vc.csv <==\n",
      "wine,quality\n",
      "1214,bad\n",
      "727,bad\n",
      "481,bad\n",
      "1308,bad\n",
      "4087,bad\n",
      "619,bad\n",
      "4669,bad\n",
      "874,bad\n",
      "2337,bad\n",
      "\n",
      "==> submissions/wine-submission-p-18ago-xgb.csv <==\n",
      "wine,quality\n",
      "1214,bad\n",
      "727,bad\n",
      "481,bad\n",
      "1308,bad\n",
      "4087,bad\n",
      "619,bad\n",
      "4669,bad\n",
      "874,bad\n",
      "2337,bad\n",
      "\n",
      "==> submissions/wine-submission-p-31ago-abdt.csv <==\n",
      "wine,quality\n",
      "1271,bad\n",
      "1945,bad\n",
      "4235,bad\n",
      "4779,bad\n",
      "3502,bad\n",
      "4030,bad\n",
      "649,good\n",
      "963,good\n",
      "4514,bad\n",
      "\n",
      "==> submissions/wine-submission-p-31ago-bc.csv <==\n",
      "wine,quality\n",
      "1271,bad\n",
      "1945,bad\n",
      "4235,bad\n",
      "4779,bad\n",
      "3502,bad\n",
      "4030,bad\n",
      "649,good\n",
      "963,bad\n",
      "4514,bad\n",
      "\n",
      "==> submissions/wine-submission-p-31ago-dt.csv <==\n",
      "wine,quality\n",
      "1271,bad\n",
      "1945,bad\n",
      "4235,bad\n",
      "4779,bad\n",
      "3502,bad\n",
      "4030,bad\n",
      "649,bad\n",
      "963,bad\n",
      "4514,bad\n",
      "\n",
      "==> submissions/wine-submission-p-31ago-et.csv <==\n",
      "wine,quality\n",
      "1271,bad\n",
      "1945,bad\n",
      "4235,bad\n",
      "4779,bad\n",
      "3502,bad\n",
      "4030,bad\n",
      "649,bad\n",
      "963,bad\n",
      "4514,bad\n",
      "\n",
      "==> submissions/wine-submission-p-31ago-gb.csv <==\n",
      "wine,quality\n",
      "1271,bad\n",
      "1945,bad\n",
      "4235,bad\n",
      "4779,bad\n",
      "3502,bad\n",
      "4030,bad\n",
      "649,bad\n",
      "963,bad\n",
      "4514,bad\n",
      "\n",
      "==> submissions/wine-submission-p-31ago-knn.csv <==\n",
      "wine,quality\n",
      "1271,bad\n",
      "1945,bad\n",
      "4235,bad\n",
      "4779,bad\n",
      "3502,bad\n",
      "4030,bad\n",
      "649,bad\n",
      "963,bad\n",
      "4514,bad\n",
      "\n",
      "==> submissions/wine-submission-p-31ago-lda.csv <==\n",
      "wine,quality\n",
      "1271,bad\n",
      "1945,bad\n",
      "4235,bad\n",
      "4779,bad\n",
      "3502,bad\n",
      "4030,bad\n",
      "649,bad\n",
      "963,bad\n",
      "4514,bad\n",
      "\n",
      "==> submissions/wine-submission-p-31ago-lr.csv <==\n",
      "wine,quality\n",
      "1271,bad\n",
      "1945,bad\n",
      "4235,bad\n",
      "4779,bad\n",
      "3502,bad\n",
      "4030,bad\n",
      "649,bad\n",
      "963,bad\n",
      "4514,bad\n",
      "\n",
      "==> submissions/wine-submission-p-31ago-mlp.csv <==\n",
      "wine,quality\n",
      "1271,bad\n",
      "1945,bad\n",
      "4235,bad\n",
      "4779,bad\n",
      "3502,bad\n",
      "4030,bad\n",
      "649,bad\n",
      "963,bad\n",
      "4514,bad\n",
      "\n",
      "==> submissions/wine-submission-p-31ago-nb.csv <==\n",
      "wine,quality\n",
      "1271,bad\n",
      "1945,bad\n",
      "4235,bad\n",
      "4779,bad\n",
      "3502,bad\n",
      "4030,good\n",
      "649,bad\n",
      "963,good\n",
      "4514,bad\n",
      "\n",
      "==> submissions/wine-submission-p-31ago-rf.csv <==\n",
      "wine,quality\n",
      "1271,bad\n",
      "1945,bad\n",
      "4235,bad\n",
      "4779,bad\n",
      "3502,bad\n",
      "4030,bad\n",
      "649,bad\n",
      "963,bad\n",
      "4514,bad\n",
      "\n",
      "==> submissions/wine-submission-p-31ago-svm.csv <==\n",
      "wine,quality\n",
      "1271,bad\n",
      "1945,bad\n",
      "4235,bad\n",
      "4779,bad\n",
      "3502,bad\n",
      "4030,bad\n",
      "649,bad\n",
      "963,bad\n",
      "4514,bad\n",
      "\n",
      "==> submissions/wine-submission-p-31ago-vc.csv <==\n",
      "wine,quality\n",
      "1271,bad\n",
      "1945,bad\n",
      "4235,bad\n",
      "4779,bad\n",
      "3502,bad\n",
      "4030,bad\n",
      "649,bad\n",
      "963,bad\n",
      "4514,bad\n",
      "\n",
      "==> submissions/wine-submission-p-31ago-xgb.csv <==\n",
      "wine,quality\n",
      "1271,bad\n",
      "1945,bad\n",
      "4235,bad\n",
      "4779,bad\n",
      "3502,bad\n",
      "4030,bad\n",
      "649,bad\n",
      "963,bad\n",
      "4514,bad\n"
     ]
    }
   ],
   "source": [
    "!head submissions/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
